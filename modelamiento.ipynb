{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbe4654f",
   "metadata": {},
   "source": [
    "# **Implementación de modelos para el análisis de sentimiento**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be89a253",
   "metadata": {},
   "source": [
    "## ***Librerias***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de5b10e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c2ecdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a46e4164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn import utils\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Embedding, Dropout\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e6d1871",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\fonta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.data.path.append('C:\\\\nltk_data')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b463a923",
   "metadata": {},
   "source": [
    "## **Modelo Doc2Vec**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5894338",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('data/processed/to_model.csv')\n",
    "data = data.dropna(subset=['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b82a2d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "clean_text",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "2ab799fb-4946-4403-ac05-e6b76382a801",
       "rows": [
        [
         "0",
         "neg",
         "achanak khawaja saad rafiqu khiyaal aagaya woh bhe peshawar line pai 10 saal train nahe guzri"
        ],
        [
         "1",
         "neg",
         "adha drama to censor hi hojay gaa khaa tor basant singh babrik shah wala part dramon kay naam chang kernay ki tuk banti iss bewaqoofi ki waja samajh main aay mushkil hindi naamon indian movi bhi to pakistan main releas hoti hain jesay katha sangharsh abodh gaman andolan kartavya avtaar satyamev jayat nishaant aakrosh akarshan etc mushkil hindi name to urdu main convert kerta"
        ],
        [
         "2",
         "neg",
         "bekaar fuzool end moti budhi laila jeet gaye laila doosri larkiyon meesni keh jabkay laila sub bari meesni aliya aleena main desi kuri titl win kerti to theek hota"
        ],
        [
         "3",
         "neg",
         "choor kasuri choor jhootay moo kaala"
        ],
        [
         "4",
         "neg",
         "gali gali mein shor gaaanjaaaa shair chor"
        ],
        [
         "5",
         "neg",
         "hum kia hamari logic kia bhonkoon mute bhonk andaza laganay koshish kar rahey jhoot mein kitna dam waisey yeah offshor compani paisa kehan aaaaya"
        ],
        [
         "6",
         "neg",
         "imran khan altaf hussain chachoo haroon sadmey nikal aao futur main jo bhi magar ik sahab ney apney aap key saath buhut hi bura kar dala aney wala waqt hi batayey ga jo agar thori buhut ume woh bhi mutti main"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 7
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>achanak khawaja saad rafiqu khiyaal aagaya woh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>adha drama to censor hi hojay gaa khaa tor bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>bekaar fuzool end moti budhi laila jeet gaye l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>choor kasuri choor jhootay moo kaala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>gali gali mein shor gaaanjaaaa shair chor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>neg</td>\n",
       "      <td>hum kia hamari logic kia bhonkoon mute bhonk a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>neg</td>\n",
       "      <td>imran khan altaf hussain chachoo haroon sadmey...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                         clean_text\n",
       "0   neg  achanak khawaja saad rafiqu khiyaal aagaya woh...\n",
       "1   neg  adha drama to censor hi hojay gaa khaa tor bas...\n",
       "2   neg  bekaar fuzool end moti budhi laila jeet gaye l...\n",
       "3   neg               choor kasuri choor jhootay moo kaala\n",
       "4   neg          gali gali mein shor gaaanjaaaa shair chor\n",
       "5   neg  hum kia hamari logic kia bhonkoon mute bhonk a...\n",
       "6   neg  imran khan altaf hussain chachoo haroon sadmey..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0327e875",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93dab21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño conjunto de entrenamiento (8797, 2)\n",
      "Tamaño conjunto de test (2200, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f'Tamaño conjunto de entrenamiento {train.shape}')\n",
    "print(f'Tamaño conjunto de test {test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4afe198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            if len(word) <= 0:\n",
    "                continue\n",
    "            tokens.append(word.lower())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9811366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tagged = train.apply(lambda r: TaggedDocument(words=tokenize_text(r['clean_text']), tags=[r.label]), axis=1)\n",
    "test_tagged  = test.apply(lambda r: TaggedDocument(words=tokenize_text(r['clean_text']), tags=[r.label]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64e40781",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_model = Doc2Vec(dm=1, dm_mean=1, vector_size=20, window=8, min_count=1, workers=12, alpha=0.065, min_alpha=0.065)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2c97bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8797/8797 [00:00<00:00, 1842101.46it/s]\n"
     ]
    }
   ],
   "source": [
    "d2v_model.build_vocab([x for x in tqdm(train_tagged.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94b3bc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8797/8797 [00:00<00:00, 1382749.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 8797/8797 [00:00<00:00, 2932079.81it/s]\n",
      "100%|██████████| 8797/8797 [00:00<00:00, 2927427.19it/s]\n",
      "100%|██████████| 8797/8797 [00:00<00:00, 3941597.30it/s]\n",
      "100%|██████████| 8797/8797 [00:00<00:00, 4379500.57it/s]\n",
      "100%|██████████| 8797/8797 [00:00<00:00, 2928588.96it/s]\n",
      "100%|██████████| 8797/8797 [00:00<00:00, 3575319.02it/s]\n",
      "100%|██████████| 8797/8797 [00:00<00:00, 2934411.67it/s]\n",
      "100%|██████████| 8797/8797 [00:00<00:00, 4398294.47it/s]\n",
      "100%|██████████| 8797/8797 [00:00<00:00, 2915399.20it/s]\n",
      "100%|██████████| 8797/8797 [00:00<00:00, 4411968.47it/s]\n",
      "100%|██████████| 8797/8797 [00:00<00:00, 4376383.86it/s]\n",
      "100%|██████████| 8797/8797 [00:00<00:00, 2007688.12it/s]\n",
      "100%|██████████| 8797/8797 [00:00<00:00, 2586742.31it/s]\n",
      "100%|██████████| 8797/8797 [00:00<00:00, 2197182.89it/s]\n",
      "100%|██████████| 8797/8797 [00:00<00:00, 2932079.81it/s]\n",
      "100%|██████████| 8797/8797 [00:00<00:00, 2930449.71it/s]\n",
      "100%|██████████| 8797/8797 [00:00<00:00, 4405120.86it/s]\n",
      "100%|██████████| 8797/8797 [00:00<00:00, 4402492.82it/s]\n",
      "100%|██████████| 8797/8797 [00:00<00:00, 2930915.27it/s]\n",
      "100%|██████████| 8797/8797 [00:00<00:00, 2929519.04it/s]\n",
      "100%|██████████| 8797/8797 [00:00<00:00, 4397770.24it/s]\n",
      "100%|██████████| 8797/8797 [00:00<00:00, 1654364.54it/s]\n",
      "100%|██████████| 8797/8797 [00:00<00:00, 2564805.53it/s]\n",
      "100%|██████████| 8797/8797 [00:00<00:00, 1759611.44it/s]\n",
      "100%|██████████| 8797/8797 [00:00<00:00, 4057768.86it/s]\n",
      "100%|██████████| 8797/8797 [00:00<00:00, 2929053.92it/s]\n",
      "100%|██████████| 8797/8797 [00:00<00:00, 4366543.47it/s]\n",
      "100%|██████████| 8797/8797 [00:00<00:00, 4363445.16it/s]\n",
      "100%|██████████| 8797/8797 [00:00<00:00, 2909651.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 40.6 s\n",
      "Wall time: 34.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    d2v_model.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    d2v_model.alpha -= 0.002\n",
    "    d2v_model.min_alpha = d2v_model.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f72e9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec<dm/m,d20,n5,w8,s0.001,t12>\n"
     ]
    }
   ],
   "source": [
    "print(d2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abd61b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(d2v_model.wv.key_to_index)+ 1, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "940d3271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "KeyedVectors<vector_size=20, 2 keys>\n",
      "[-3.3452353  -5.7708135  -2.3312628   1.0419532   1.3956264   0.67657304\n",
      " -3.3297856  -1.5124993  -4.78927    -2.119939    4.6982265   1.3438421\n",
      "  2.9625978  -0.20429188 -2.0186498  -9.938452    0.66440094  3.0071862\n",
      " -2.4732397   0.34946737]\n",
      "1\n",
      "KeyedVectors<vector_size=20, 2 keys>\n",
      "[-1.4290804   3.902337   -3.7871187   1.2919521   1.3462657  -4.392414\n",
      " -2.8556075  -1.506352    4.5453153   0.8441589  -0.5865879   1.241429\n",
      " -4.9059477  -0.28798142 -0.1128182   3.2020414   0.49837062 -2.0157232\n",
      " -4.1349535  -2.3804898 ]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(d2v_model.dv)):\n",
    "    vec = d2v_model.dv[i]\n",
    "    if vec is not None and len(vec) <= 1000:\n",
    "        print(i)\n",
    "        print(d2v_model.dv)\n",
    "        embedding_matrix[i] = vec\n",
    "        print(vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5c5491",
   "metadata": {},
   "source": [
    "## **Preproscesamiento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9aa4f774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de palabras únicas: 26381\n"
     ]
    }
   ],
   "source": [
    "all_words = list(itertools.chain.from_iterable(data['clean_text'].apply(lambda x: x.split())))\n",
    "word_counts = Counter(all_words)\n",
    "print(f\"Total de palabras únicas: {len(word_counts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57f2c885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10997.000000\n",
       "mean        18.492134\n",
       "std         21.542020\n",
       "min          1.000000\n",
       "25%          7.000000\n",
       "50%         12.000000\n",
       "75%         21.000000\n",
       "max        356.000000\n",
       "Name: clean_text, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['clean_text'].apply(lambda x: len(x.split())).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed077351",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 5000\n",
    "MAX_SEQUENCE_LENGTH = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "032a640d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10997 unique tokens.\n",
      "Shape of data tensor: (10997, 75)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features, split=' ', filters='!\"#$%&()*+,-./:;<=>?@[$$^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(data['clean_text'].values)\n",
    "X = tokenizer.texts_to_sequences(data['clean_text'].values)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Found %s unique tokens.' % len(X))\n",
    "print('Shape of data tensor:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c27a85ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b4ab124",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1eca3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño conjunto de entrenamiento (8797, 75)\n",
      "Tamaño conjunto de test (2200, 75)\n"
     ]
    }
   ],
   "source": [
    "print(f'Tamaño conjunto de entrenamiento {X_train.shape}')\n",
    "print(f'Tamaño conjunto de test {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7d3517",
   "metadata": {},
   "source": [
    "## **LSTM**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612ad35b",
   "metadata": {},
   "source": [
    "### **Entrenamiento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd3a2eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(lstm_units=64, num_lstm_layers=1, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(len(d2v_model.wv.key_to_index) + 1, 20, input_length=X.shape[1], weights=[embedding_matrix], trainable=True))\n",
    "    \n",
    "    for i in range(num_lstm_layers):\n",
    "        return_seq = (i < num_lstm_layers - 1)\n",
    "        model.add(LSTM(units=lstm_units, return_sequences=return_seq))\n",
    "\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=learning_rate), metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d888a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model,verbose=0)\n",
    "\n",
    "param_grid = {\n",
    "    'lstm_units': [64],\n",
    "    'num_lstm_layers': [1, 2],\n",
    "    'dropout_rate': [0.2],\n",
    "    'learning_rate': [0.001],\n",
    "    'batch_size': [32, 64],\n",
    "    'epochs': [20, 50],\n",
    "}\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='accuracy',verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f2c5f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Epoch 1/20\n",
      "184/184 [==============================] - 11s 16ms/step - loss: 0.6684 - accuracy: 0.5943\n",
      "Epoch 2/20\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.4644 - accuracy: 0.7892\n",
      "Epoch 3/20\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.3013 - accuracy: 0.8769\n",
      "Epoch 4/20\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.2244 - accuracy: 0.9129\n",
      "Epoch 5/20\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.1688 - accuracy: 0.9389\n",
      "Epoch 6/20\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.1336 - accuracy: 0.9538\n",
      "Epoch 7/20\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.1064 - accuracy: 0.9649\n",
      "Epoch 8/20\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0898 - accuracy: 0.9696\n",
      "Epoch 9/20\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0800 - accuracy: 0.9741\n",
      "Epoch 10/20\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0620 - accuracy: 0.9811\n",
      "Epoch 11/20\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0610 - accuracy: 0.9819\n",
      "Epoch 12/20\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0556 - accuracy: 0.9824\n",
      "Epoch 13/20\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0651 - accuracy: 0.9802\n",
      "Epoch 14/20\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0424 - accuracy: 0.9876\n",
      "Epoch 15/20\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0369 - accuracy: 0.9911\n",
      "Epoch 16/20\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0303 - accuracy: 0.9910\n",
      "Epoch 17/20\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0298 - accuracy: 0.9906\n",
      "Epoch 18/20\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0261 - accuracy: 0.9916\n",
      "Epoch 19/20\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0252 - accuracy: 0.9920\n",
      "Epoch 20/20\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0300 - accuracy: 0.9911\n",
      "92/92 [==============================] - 1s 6ms/step\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=20, learning_rate=0.001, lstm_units=64, num_lstm_layers=1; total time= 1.2min\n",
      "Epoch 1/20\n",
      "184/184 [==============================] - 5s 16ms/step - loss: 0.6656 - accuracy: 0.5961\n",
      "Epoch 2/20\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.4745 - accuracy: 0.7772\n",
      "Epoch 3/20\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.3089 - accuracy: 0.8747\n",
      "Epoch 4/20\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.2196 - accuracy: 0.9176\n",
      "Epoch 5/20\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.1681 - accuracy: 0.9408\n",
      "Epoch 6/20\n",
      "184/184 [==============================] - 3s 17ms/step - loss: 0.1299 - accuracy: 0.9543\n",
      "Epoch 7/20\n",
      "184/184 [==============================] - 3s 17ms/step - loss: 0.1006 - accuracy: 0.9679\n",
      "Epoch 8/20\n",
      "184/184 [==============================] - 3s 17ms/step - loss: 0.0784 - accuracy: 0.9754\n",
      "Epoch 9/20\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0640 - accuracy: 0.9790\n",
      "Epoch 10/20\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0486 - accuracy: 0.9843\n",
      "Epoch 11/20\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0390 - accuracy: 0.9881\n",
      "Epoch 12/20\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0343 - accuracy: 0.9893\n",
      "Epoch 13/20\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0318 - accuracy: 0.9899\n",
      "Epoch 14/20\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0307 - accuracy: 0.9899\n",
      "Epoch 15/20\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0299 - accuracy: 0.9908\n",
      "Epoch 16/20\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0204 - accuracy: 0.9944\n",
      "Epoch 17/20\n",
      "184/184 [==============================] - 3s 17ms/step - loss: 0.0216 - accuracy: 0.9935\n",
      "Epoch 18/20\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0176 - accuracy: 0.9949\n",
      "Epoch 19/20\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0149 - accuracy: 0.9951\n",
      "Epoch 20/20\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0167 - accuracy: 0.9939\n",
      "92/92 [==============================] - 1s 6ms/step\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=20, learning_rate=0.001, lstm_units=64, num_lstm_layers=1; total time= 1.0min\n",
      "Epoch 1/20\n",
      "184/184 [==============================] - 5s 16ms/step - loss: 0.6685 - accuracy: 0.5816\n",
      "Epoch 2/20\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.4866 - accuracy: 0.7743\n",
      "Epoch 3/20\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.3120 - accuracy: 0.8714\n",
      "Epoch 4/20\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.2324 - accuracy: 0.9147\n",
      "Epoch 5/20\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.1779 - accuracy: 0.9384\n",
      "Epoch 6/20\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.1482 - accuracy: 0.9477\n",
      "Epoch 7/20\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.1282 - accuracy: 0.9555\n",
      "Epoch 8/20\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.1009 - accuracy: 0.9669\n",
      "Epoch 9/20\n",
      "184/184 [==============================] - 3s 17ms/step - loss: 0.0788 - accuracy: 0.9754\n",
      "Epoch 10/20\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0759 - accuracy: 0.9768\n",
      "Epoch 11/20\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0644 - accuracy: 0.9804\n",
      "Epoch 12/20\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0539 - accuracy: 0.9836\n",
      "Epoch 13/20\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0435 - accuracy: 0.9870\n",
      "Epoch 14/20\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0378 - accuracy: 0.9896\n",
      "Epoch 15/20\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0411 - accuracy: 0.9869\n",
      "Epoch 16/20\n",
      "184/184 [==============================] - 3s 17ms/step - loss: 0.0327 - accuracy: 0.9910\n",
      "Epoch 17/20\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0226 - accuracy: 0.9939\n",
      "Epoch 18/20\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0325 - accuracy: 0.9906\n",
      "Epoch 19/20\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0201 - accuracy: 0.9947\n",
      "Epoch 20/20\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0193 - accuracy: 0.9954\n",
      "92/92 [==============================] - 1s 7ms/step\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=20, learning_rate=0.001, lstm_units=64, num_lstm_layers=1; total time= 1.0min\n",
      "Epoch 1/20\n",
      "184/184 [==============================] - 8s 26ms/step - loss: 0.6685 - accuracy: 0.5849\n",
      "Epoch 2/20\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.4464 - accuracy: 0.7931\n",
      "Epoch 3/20\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.2979 - accuracy: 0.8747\n",
      "Epoch 4/20\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.2191 - accuracy: 0.9141\n",
      "Epoch 5/20\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.1676 - accuracy: 0.9364\n",
      "Epoch 6/20\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.1254 - accuracy: 0.9543\n",
      "Epoch 7/20\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.1047 - accuracy: 0.9635\n",
      "Epoch 8/20\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0835 - accuracy: 0.9732\n",
      "Epoch 9/20\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0725 - accuracy: 0.9778\n",
      "Epoch 10/20\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0635 - accuracy: 0.9794\n",
      "Epoch 11/20\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0508 - accuracy: 0.9850\n",
      "Epoch 12/20\n",
      "184/184 [==============================] - 4s 24ms/step - loss: 0.0528 - accuracy: 0.9838\n",
      "Epoch 13/20\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0434 - accuracy: 0.9864\n",
      "Epoch 14/20\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0384 - accuracy: 0.9872\n",
      "Epoch 15/20\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0369 - accuracy: 0.9891\n",
      "Epoch 16/20\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0366 - accuracy: 0.9891\n",
      "Epoch 17/20\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0416 - accuracy: 0.9865\n",
      "Epoch 18/20\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0350 - accuracy: 0.9889\n",
      "Epoch 19/20\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0280 - accuracy: 0.9918\n",
      "Epoch 20/20\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0293 - accuracy: 0.9906\n",
      "92/92 [==============================] - 2s 11ms/step\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=20, learning_rate=0.001, lstm_units=64, num_lstm_layers=2; total time= 1.7min\n",
      "Epoch 1/20\n",
      "184/184 [==============================] - 8s 25ms/step - loss: 0.6600 - accuracy: 0.5973\n",
      "Epoch 2/20\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.4261 - accuracy: 0.8094\n",
      "Epoch 3/20\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.2785 - accuracy: 0.8895\n",
      "Epoch 4/20\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.2019 - accuracy: 0.9275\n",
      "Epoch 5/20\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.1610 - accuracy: 0.9448\n",
      "Epoch 6/20\n",
      "184/184 [==============================] - 4s 24ms/step - loss: 0.1304 - accuracy: 0.9587\n",
      "Epoch 7/20\n",
      "184/184 [==============================] - 4s 23ms/step - loss: 0.1046 - accuracy: 0.9656\n",
      "Epoch 8/20\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0989 - accuracy: 0.9676\n",
      "Epoch 9/20\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0822 - accuracy: 0.9753\n",
      "Epoch 10/20\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0728 - accuracy: 0.9766\n",
      "Epoch 11/20\n",
      "184/184 [==============================] - 5s 24ms/step - loss: 0.0696 - accuracy: 0.9775\n",
      "Epoch 12/20\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0589 - accuracy: 0.9816\n",
      "Epoch 13/20\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0456 - accuracy: 0.9884\n",
      "Epoch 14/20\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0487 - accuracy: 0.9876\n",
      "Epoch 15/20\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0460 - accuracy: 0.9853\n",
      "Epoch 16/20\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0417 - accuracy: 0.9886\n",
      "Epoch 17/20\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0396 - accuracy: 0.9896\n",
      "Epoch 18/20\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0445 - accuracy: 0.9876\n",
      "Epoch 19/20\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0426 - accuracy: 0.9877\n",
      "Epoch 20/20\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0332 - accuracy: 0.9908\n",
      "92/92 [==============================] - 2s 10ms/step\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=20, learning_rate=0.001, lstm_units=64, num_lstm_layers=2; total time= 1.6min\n",
      "Epoch 1/20\n",
      "184/184 [==============================] - 9s 26ms/step - loss: 0.6679 - accuracy: 0.5828\n",
      "Epoch 2/20\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.4522 - accuracy: 0.7901\n",
      "Epoch 3/20\n",
      "184/184 [==============================] - 5s 24ms/step - loss: 0.2909 - accuracy: 0.8767\n",
      "Epoch 4/20\n",
      "184/184 [==============================] - 5s 27ms/step - loss: 0.2155 - accuracy: 0.9185\n",
      "Epoch 5/20\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.1618 - accuracy: 0.9390\n",
      "Epoch 6/20\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.1272 - accuracy: 0.9564\n",
      "Epoch 7/20\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0969 - accuracy: 0.9668\n",
      "Epoch 8/20\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0881 - accuracy: 0.9705\n",
      "Epoch 9/20\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0828 - accuracy: 0.9739\n",
      "Epoch 10/20\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0629 - accuracy: 0.9799\n",
      "Epoch 11/20\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0600 - accuracy: 0.9831\n",
      "Epoch 12/20\n",
      "184/184 [==============================] - 5s 27ms/step - loss: 0.0528 - accuracy: 0.9848\n",
      "Epoch 13/20\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0497 - accuracy: 0.9860\n",
      "Epoch 14/20\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0423 - accuracy: 0.9870\n",
      "Epoch 15/20\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0403 - accuracy: 0.9886\n",
      "Epoch 16/20\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0356 - accuracy: 0.9899\n",
      "Epoch 17/20\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0352 - accuracy: 0.9899\n",
      "Epoch 18/20\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0343 - accuracy: 0.9899\n",
      "Epoch 19/20\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0353 - accuracy: 0.9899\n",
      "Epoch 20/20\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0325 - accuracy: 0.9898\n",
      "92/92 [==============================] - 2s 11ms/step\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=20, learning_rate=0.001, lstm_units=64, num_lstm_layers=2; total time= 1.7min\n",
      "Epoch 1/50\n",
      "184/184 [==============================] - 5s 16ms/step - loss: 0.6678 - accuracy: 0.5906\n",
      "Epoch 2/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.4760 - accuracy: 0.7749\n",
      "Epoch 3/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.3076 - accuracy: 0.8764\n",
      "Epoch 4/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.2307 - accuracy: 0.9117\n",
      "Epoch 5/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.1765 - accuracy: 0.9367\n",
      "Epoch 6/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.1360 - accuracy: 0.9538\n",
      "Epoch 7/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.1119 - accuracy: 0.9627\n",
      "Epoch 8/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0906 - accuracy: 0.9676\n",
      "Epoch 9/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0780 - accuracy: 0.9732\n",
      "Epoch 10/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0680 - accuracy: 0.9770\n",
      "Epoch 11/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0555 - accuracy: 0.9835\n",
      "Epoch 12/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0547 - accuracy: 0.9835\n",
      "Epoch 13/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0430 - accuracy: 0.9874\n",
      "Epoch 14/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0427 - accuracy: 0.9869\n",
      "Epoch 15/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0395 - accuracy: 0.9882\n",
      "Epoch 16/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0287 - accuracy: 0.9906\n",
      "Epoch 17/50\n",
      "184/184 [==============================] - 3s 17ms/step - loss: 0.0358 - accuracy: 0.9874\n",
      "Epoch 18/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0286 - accuracy: 0.9910\n",
      "Epoch 19/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0255 - accuracy: 0.9918\n",
      "Epoch 20/50\n",
      "184/184 [==============================] - 3s 17ms/step - loss: 0.0253 - accuracy: 0.9911\n",
      "Epoch 21/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0215 - accuracy: 0.9935\n",
      "Epoch 22/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0233 - accuracy: 0.9925\n",
      "Epoch 23/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0224 - accuracy: 0.9923\n",
      "Epoch 24/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0186 - accuracy: 0.9930\n",
      "Epoch 25/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0235 - accuracy: 0.9925\n",
      "Epoch 26/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0219 - accuracy: 0.9925\n",
      "Epoch 27/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0236 - accuracy: 0.9913\n",
      "Epoch 28/50\n",
      "184/184 [==============================] - 3s 17ms/step - loss: 0.0172 - accuracy: 0.9937\n",
      "Epoch 29/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0147 - accuracy: 0.9940\n",
      "Epoch 30/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0116 - accuracy: 0.9954\n",
      "Epoch 31/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0115 - accuracy: 0.9951\n",
      "Epoch 32/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0120 - accuracy: 0.9951\n",
      "Epoch 33/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0122 - accuracy: 0.9945\n",
      "Epoch 34/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0108 - accuracy: 0.9954\n",
      "Epoch 35/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0111 - accuracy: 0.9951\n",
      "Epoch 36/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0094 - accuracy: 0.9957\n",
      "Epoch 37/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0111 - accuracy: 0.9952\n",
      "Epoch 38/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0110 - accuracy: 0.9956\n",
      "Epoch 39/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0148 - accuracy: 0.9932\n",
      "Epoch 40/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0248 - accuracy: 0.9908\n",
      "Epoch 41/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0253 - accuracy: 0.9901\n",
      "Epoch 42/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0158 - accuracy: 0.9930\n",
      "Epoch 43/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0108 - accuracy: 0.9947\n",
      "Epoch 44/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0101 - accuracy: 0.9954\n",
      "Epoch 45/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0084 - accuracy: 0.9954\n",
      "Epoch 46/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0095 - accuracy: 0.9952\n",
      "Epoch 47/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0088 - accuracy: 0.9957\n",
      "Epoch 48/50\n",
      "184/184 [==============================] - 3s 17ms/step - loss: 0.0086 - accuracy: 0.9961\n",
      "Epoch 49/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0089 - accuracy: 0.9951\n",
      "Epoch 50/50\n",
      "184/184 [==============================] - 3s 17ms/step - loss: 0.0113 - accuracy: 0.9942\n",
      "92/92 [==============================] - 1s 6ms/step\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=50, learning_rate=0.001, lstm_units=64, num_lstm_layers=1; total time= 2.5min\n",
      "Epoch 1/50\n",
      "184/184 [==============================] - 6s 18ms/step - loss: 0.6635 - accuracy: 0.5990\n",
      "Epoch 2/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.4591 - accuracy: 0.7934\n",
      "Epoch 3/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.3006 - accuracy: 0.8832\n",
      "Epoch 4/50\n",
      "184/184 [==============================] - 3s 17ms/step - loss: 0.2181 - accuracy: 0.9161\n",
      "Epoch 5/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.1709 - accuracy: 0.9413\n",
      "Epoch 6/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.1374 - accuracy: 0.9524\n",
      "Epoch 7/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.1116 - accuracy: 0.9639\n",
      "Epoch 8/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0991 - accuracy: 0.9685\n",
      "Epoch 9/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0887 - accuracy: 0.9714\n",
      "Epoch 10/50\n",
      "184/184 [==============================] - 3s 17ms/step - loss: 0.0782 - accuracy: 0.9751\n",
      "Epoch 11/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0700 - accuracy: 0.9772\n",
      "Epoch 12/50\n",
      "184/184 [==============================] - 3s 17ms/step - loss: 0.0598 - accuracy: 0.9821\n",
      "Epoch 13/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0596 - accuracy: 0.9821\n",
      "Epoch 14/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0538 - accuracy: 0.9828\n",
      "Epoch 15/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0469 - accuracy: 0.9826\n",
      "Epoch 16/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0399 - accuracy: 0.9867\n",
      "Epoch 17/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0471 - accuracy: 0.9841\n",
      "Epoch 18/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0353 - accuracy: 0.9889\n",
      "Epoch 19/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0320 - accuracy: 0.9894\n",
      "Epoch 20/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0318 - accuracy: 0.9899\n",
      "Epoch 21/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0363 - accuracy: 0.9877\n",
      "Epoch 22/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0245 - accuracy: 0.9920\n",
      "Epoch 23/50\n",
      "184/184 [==============================] - 3s 18ms/step - loss: 0.0252 - accuracy: 0.9922\n",
      "Epoch 24/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0343 - accuracy: 0.9881\n",
      "Epoch 25/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0218 - accuracy: 0.9937\n",
      "Epoch 26/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0189 - accuracy: 0.9942\n",
      "Epoch 27/50\n",
      "184/184 [==============================] - 3s 17ms/step - loss: 0.0142 - accuracy: 0.9964\n",
      "Epoch 28/50\n",
      "184/184 [==============================] - 3s 17ms/step - loss: 0.0143 - accuracy: 0.9959\n",
      "Epoch 29/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0115 - accuracy: 0.9961\n",
      "Epoch 30/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0126 - accuracy: 0.9959\n",
      "Epoch 31/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0209 - accuracy: 0.9939\n",
      "Epoch 32/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0157 - accuracy: 0.9949\n",
      "Epoch 33/50\n",
      "184/184 [==============================] - 2s 12ms/step - loss: 0.0317 - accuracy: 0.9899\n",
      "Epoch 34/50\n",
      "184/184 [==============================] - 2s 13ms/step - loss: 0.0275 - accuracy: 0.9906\n",
      "Epoch 35/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0178 - accuracy: 0.9944\n",
      "Epoch 36/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0141 - accuracy: 0.9951\n",
      "Epoch 37/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0098 - accuracy: 0.9968\n",
      "Epoch 38/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0102 - accuracy: 0.9968\n",
      "Epoch 39/50\n",
      "184/184 [==============================] - 3s 17ms/step - loss: 0.0094 - accuracy: 0.9968\n",
      "Epoch 40/50\n",
      "184/184 [==============================] - 3s 17ms/step - loss: 0.0083 - accuracy: 0.9969\n",
      "Epoch 41/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0078 - accuracy: 0.9976\n",
      "Epoch 42/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0123 - accuracy: 0.9954\n",
      "Epoch 43/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0155 - accuracy: 0.9949\n",
      "Epoch 44/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0134 - accuracy: 0.9951\n",
      "Epoch 45/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0105 - accuracy: 0.9961\n",
      "Epoch 46/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0103 - accuracy: 0.9962\n",
      "Epoch 47/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0117 - accuracy: 0.9961\n",
      "Epoch 48/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0077 - accuracy: 0.9974\n",
      "Epoch 49/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0078 - accuracy: 0.9966\n",
      "Epoch 50/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0076 - accuracy: 0.9968\n",
      "92/92 [==============================] - 1s 7ms/step\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=50, learning_rate=0.001, lstm_units=64, num_lstm_layers=1; total time= 2.5min\n",
      "Epoch 1/50\n",
      "184/184 [==============================] - 5s 17ms/step - loss: 0.6688 - accuracy: 0.5833\n",
      "Epoch 2/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.4801 - accuracy: 0.7782\n",
      "Epoch 3/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.3109 - accuracy: 0.8718\n",
      "Epoch 4/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.2308 - accuracy: 0.9130\n",
      "Epoch 5/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.1796 - accuracy: 0.9364\n",
      "Epoch 6/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.1373 - accuracy: 0.9504\n",
      "Epoch 7/50\n",
      "184/184 [==============================] - 3s 17ms/step - loss: 0.1154 - accuracy: 0.9589\n",
      "Epoch 8/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0961 - accuracy: 0.9683\n",
      "Epoch 9/50\n",
      "184/184 [==============================] - 3s 17ms/step - loss: 0.0731 - accuracy: 0.9765\n",
      "Epoch 10/50\n",
      "184/184 [==============================] - 3s 17ms/step - loss: 0.0705 - accuracy: 0.9761\n",
      "Epoch 11/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0652 - accuracy: 0.9778\n",
      "Epoch 12/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0444 - accuracy: 0.9869\n",
      "Epoch 13/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0381 - accuracy: 0.9889\n",
      "Epoch 14/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0362 - accuracy: 0.9887\n",
      "Epoch 15/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0465 - accuracy: 0.9847\n",
      "Epoch 16/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0334 - accuracy: 0.9901\n",
      "Epoch 17/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0328 - accuracy: 0.9908\n",
      "Epoch 18/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0221 - accuracy: 0.9937\n",
      "Epoch 19/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0190 - accuracy: 0.9947\n",
      "Epoch 20/50\n",
      "184/184 [==============================] - 3s 17ms/step - loss: 0.0183 - accuracy: 0.9937\n",
      "Epoch 21/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0202 - accuracy: 0.9944\n",
      "Epoch 22/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0190 - accuracy: 0.9942\n",
      "Epoch 23/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0152 - accuracy: 0.9956\n",
      "Epoch 24/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0124 - accuracy: 0.9957\n",
      "Epoch 25/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0116 - accuracy: 0.9957\n",
      "Epoch 26/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0097 - accuracy: 0.9966\n",
      "Epoch 27/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0182 - accuracy: 0.9934\n",
      "Epoch 28/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0205 - accuracy: 0.9927\n",
      "Epoch 29/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0199 - accuracy: 0.9937\n",
      "Epoch 30/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0122 - accuracy: 0.9959\n",
      "Epoch 31/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0165 - accuracy: 0.9952\n",
      "Epoch 32/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0114 - accuracy: 0.9962\n",
      "Epoch 33/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0085 - accuracy: 0.9968\n",
      "Epoch 34/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0091 - accuracy: 0.9968\n",
      "Epoch 35/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0092 - accuracy: 0.9966\n",
      "Epoch 36/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0076 - accuracy: 0.9973\n",
      "Epoch 37/50\n",
      "184/184 [==============================] - 3s 17ms/step - loss: 0.0085 - accuracy: 0.9968\n",
      "Epoch 38/50\n",
      "184/184 [==============================] - 3s 17ms/step - loss: 0.0070 - accuracy: 0.9968\n",
      "Epoch 39/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0074 - accuracy: 0.9971\n",
      "Epoch 40/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0075 - accuracy: 0.9973\n",
      "Epoch 41/50\n",
      "184/184 [==============================] - 3s 17ms/step - loss: 0.0271 - accuracy: 0.9915\n",
      "Epoch 42/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0317 - accuracy: 0.9913\n",
      "Epoch 43/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0128 - accuracy: 0.9959\n",
      "Epoch 44/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0083 - accuracy: 0.9971\n",
      "Epoch 45/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0078 - accuracy: 0.9971\n",
      "Epoch 46/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0081 - accuracy: 0.9971\n",
      "Epoch 47/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0069 - accuracy: 0.9976\n",
      "Epoch 48/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0064 - accuracy: 0.9973\n",
      "Epoch 49/50\n",
      "184/184 [==============================] - 3s 15ms/step - loss: 0.0061 - accuracy: 0.9973\n",
      "Epoch 50/50\n",
      "184/184 [==============================] - 3s 16ms/step - loss: 0.0061 - accuracy: 0.9976\n",
      "92/92 [==============================] - 1s 7ms/step\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=50, learning_rate=0.001, lstm_units=64, num_lstm_layers=1; total time= 2.5min\n",
      "Epoch 1/50\n",
      "184/184 [==============================] - 8s 25ms/step - loss: 0.6665 - accuracy: 0.5936\n",
      "Epoch 2/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.4601 - accuracy: 0.7894\n",
      "Epoch 3/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.2992 - accuracy: 0.8813\n",
      "Epoch 4/50\n",
      "184/184 [==============================] - 4s 24ms/step - loss: 0.2239 - accuracy: 0.9115\n",
      "Epoch 5/50\n",
      "184/184 [==============================] - 4s 24ms/step - loss: 0.1708 - accuracy: 0.9374\n",
      "Epoch 6/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.1296 - accuracy: 0.9546\n",
      "Epoch 7/50\n",
      "184/184 [==============================] - 5s 24ms/step - loss: 0.1069 - accuracy: 0.9627\n",
      "Epoch 8/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0875 - accuracy: 0.9714\n",
      "Epoch 9/50\n",
      "184/184 [==============================] - 4s 24ms/step - loss: 0.0713 - accuracy: 0.9754\n",
      "Epoch 10/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0645 - accuracy: 0.9802\n",
      "Epoch 11/50\n",
      "184/184 [==============================] - 5s 27ms/step - loss: 0.0597 - accuracy: 0.9809\n",
      "Epoch 12/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0556 - accuracy: 0.9840\n",
      "Epoch 13/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0564 - accuracy: 0.9812\n",
      "Epoch 14/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0432 - accuracy: 0.9862\n",
      "Epoch 15/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0439 - accuracy: 0.9860\n",
      "Epoch 16/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0377 - accuracy: 0.9889\n",
      "Epoch 17/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0362 - accuracy: 0.9891\n",
      "Epoch 18/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0296 - accuracy: 0.9913\n",
      "Epoch 19/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0263 - accuracy: 0.9920\n",
      "Epoch 20/50\n",
      "184/184 [==============================] - 5s 27ms/step - loss: 0.0279 - accuracy: 0.9922\n",
      "Epoch 21/50\n",
      "184/184 [==============================] - 4s 24ms/step - loss: 0.0253 - accuracy: 0.9928\n",
      "Epoch 22/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0290 - accuracy: 0.9908\n",
      "Epoch 23/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0350 - accuracy: 0.9893\n",
      "Epoch 24/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0259 - accuracy: 0.9911\n",
      "Epoch 25/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0351 - accuracy: 0.9881\n",
      "Epoch 26/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0271 - accuracy: 0.9913\n",
      "Epoch 27/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0224 - accuracy: 0.9927\n",
      "Epoch 28/50\n",
      "184/184 [==============================] - 4s 21ms/step - loss: 0.0209 - accuracy: 0.9923\n",
      "Epoch 29/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0181 - accuracy: 0.9933\n",
      "Epoch 30/50\n",
      "184/184 [==============================] - 5s 27ms/step - loss: 0.0189 - accuracy: 0.9937\n",
      "Epoch 31/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0147 - accuracy: 0.9949\n",
      "Epoch 32/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0139 - accuracy: 0.9939\n",
      "Epoch 33/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0154 - accuracy: 0.9939\n",
      "Epoch 34/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0145 - accuracy: 0.9944\n",
      "Epoch 35/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0126 - accuracy: 0.9951\n",
      "Epoch 36/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0136 - accuracy: 0.9945\n",
      "Epoch 37/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0124 - accuracy: 0.9944\n",
      "Epoch 38/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0145 - accuracy: 0.9933\n",
      "Epoch 39/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0146 - accuracy: 0.9937\n",
      "Epoch 40/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0107 - accuracy: 0.9949\n",
      "Epoch 41/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0105 - accuracy: 0.9956\n",
      "Epoch 42/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0087 - accuracy: 0.9964\n",
      "Epoch 43/50\n",
      "184/184 [==============================] - 4s 24ms/step - loss: 0.0088 - accuracy: 0.9954\n",
      "Epoch 44/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0135 - accuracy: 0.9947\n",
      "Epoch 45/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0139 - accuracy: 0.9944\n",
      "Epoch 46/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0176 - accuracy: 0.9920\n",
      "Epoch 47/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0132 - accuracy: 0.9937\n",
      "Epoch 48/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0137 - accuracy: 0.9940\n",
      "Epoch 49/50\n",
      "184/184 [==============================] - 4s 24ms/step - loss: 0.0091 - accuracy: 0.9951\n",
      "Epoch 50/50\n",
      "184/184 [==============================] - 5s 27ms/step - loss: 0.0080 - accuracy: 0.9962\n",
      "92/92 [==============================] - 2s 11ms/step\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=50, learning_rate=0.001, lstm_units=64, num_lstm_layers=2; total time= 4.0min\n",
      "Epoch 1/50\n",
      "184/184 [==============================] - 8s 26ms/step - loss: 0.6687 - accuracy: 0.5823\n",
      "Epoch 2/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.4956 - accuracy: 0.7541\n",
      "Epoch 3/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.3073 - accuracy: 0.8759\n",
      "Epoch 4/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.2171 - accuracy: 0.9158\n",
      "Epoch 5/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.1573 - accuracy: 0.9410\n",
      "Epoch 6/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.1068 - accuracy: 0.9635\n",
      "Epoch 7/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0751 - accuracy: 0.9744\n",
      "Epoch 8/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0579 - accuracy: 0.9799\n",
      "Epoch 9/50\n",
      "184/184 [==============================] - 4s 24ms/step - loss: 0.0473 - accuracy: 0.9855\n",
      "Epoch 10/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0346 - accuracy: 0.9896\n",
      "Epoch 11/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0270 - accuracy: 0.9922\n",
      "Epoch 12/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0290 - accuracy: 0.9915\n",
      "Epoch 13/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0287 - accuracy: 0.9916\n",
      "Epoch 14/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0233 - accuracy: 0.9935\n",
      "Epoch 15/50\n",
      "184/184 [==============================] - 4s 24ms/step - loss: 0.0201 - accuracy: 0.9937\n",
      "Epoch 16/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0176 - accuracy: 0.9942\n",
      "Epoch 17/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0141 - accuracy: 0.9962\n",
      "Epoch 18/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0127 - accuracy: 0.9961\n",
      "Epoch 19/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0105 - accuracy: 0.9964\n",
      "Epoch 20/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0103 - accuracy: 0.9966\n",
      "Epoch 21/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0183 - accuracy: 0.9932\n",
      "Epoch 22/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0160 - accuracy: 0.9940\n",
      "Epoch 23/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0116 - accuracy: 0.9959\n",
      "Epoch 24/50\n",
      "184/184 [==============================] - 4s 24ms/step - loss: 0.0144 - accuracy: 0.9945\n",
      "Epoch 25/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0165 - accuracy: 0.9939\n",
      "Epoch 26/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0164 - accuracy: 0.9939\n",
      "Epoch 27/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0117 - accuracy: 0.9949\n",
      "Epoch 28/50\n",
      "184/184 [==============================] - 4s 24ms/step - loss: 0.0124 - accuracy: 0.9952\n",
      "Epoch 29/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0105 - accuracy: 0.9957\n",
      "Epoch 30/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0148 - accuracy: 0.9945\n",
      "Epoch 31/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0099 - accuracy: 0.9964\n",
      "Epoch 32/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0085 - accuracy: 0.9969\n",
      "Epoch 33/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0064 - accuracy: 0.9974\n",
      "Epoch 34/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0066 - accuracy: 0.9973\n",
      "Epoch 35/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0062 - accuracy: 0.9973\n",
      "Epoch 36/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0070 - accuracy: 0.9969\n",
      "Epoch 37/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0073 - accuracy: 0.9966\n",
      "Epoch 38/50\n",
      "184/184 [==============================] - 5s 28ms/step - loss: 0.0063 - accuracy: 0.9973\n",
      "Epoch 39/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0058 - accuracy: 0.9973\n",
      "Epoch 40/50\n",
      "184/184 [==============================] - 5s 30ms/step - loss: 0.0141 - accuracy: 0.9939\n",
      "Epoch 41/50\n",
      "184/184 [==============================] - 5s 28ms/step - loss: 0.0190 - accuracy: 0.9930\n",
      "Epoch 42/50\n",
      "184/184 [==============================] - 5s 27ms/step - loss: 0.0102 - accuracy: 0.9964\n",
      "Epoch 43/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0071 - accuracy: 0.9969\n",
      "Epoch 44/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0060 - accuracy: 0.9973\n",
      "Epoch 45/50\n",
      "184/184 [==============================] - 5s 27ms/step - loss: 0.0061 - accuracy: 0.9971\n",
      "Epoch 46/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0057 - accuracy: 0.9971\n",
      "Epoch 47/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0069 - accuracy: 0.9969\n",
      "Epoch 48/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0058 - accuracy: 0.9973\n",
      "Epoch 49/50\n",
      "184/184 [==============================] - 5s 24ms/step - loss: 0.0058 - accuracy: 0.9973\n",
      "Epoch 50/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0061 - accuracy: 0.9973\n",
      "92/92 [==============================] - 2s 10ms/step\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=50, learning_rate=0.001, lstm_units=64, num_lstm_layers=2; total time= 4.0min\n",
      "Epoch 1/50\n",
      "184/184 [==============================] - 8s 26ms/step - loss: 0.6678 - accuracy: 0.5881\n",
      "Epoch 2/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.4488 - accuracy: 0.7949\n",
      "Epoch 3/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.2989 - accuracy: 0.8762\n",
      "Epoch 4/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.2216 - accuracy: 0.9168\n",
      "Epoch 5/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.1674 - accuracy: 0.9413\n",
      "Epoch 6/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.1327 - accuracy: 0.9524\n",
      "Epoch 7/50\n",
      "184/184 [==============================] - 4s 24ms/step - loss: 0.1144 - accuracy: 0.9608\n",
      "Epoch 8/50\n",
      "184/184 [==============================] - 4s 23ms/step - loss: 0.0935 - accuracy: 0.9698\n",
      "Epoch 9/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0801 - accuracy: 0.9763\n",
      "Epoch 10/50\n",
      "184/184 [==============================] - 4s 24ms/step - loss: 0.0675 - accuracy: 0.9794\n",
      "Epoch 11/50\n",
      "184/184 [==============================] - 5s 24ms/step - loss: 0.0609 - accuracy: 0.9812\n",
      "Epoch 12/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0575 - accuracy: 0.9838\n",
      "Epoch 13/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0492 - accuracy: 0.9855\n",
      "Epoch 14/50\n",
      "184/184 [==============================] - 5s 27ms/step - loss: 0.0416 - accuracy: 0.9898\n",
      "Epoch 15/50\n",
      "184/184 [==============================] - 5s 27ms/step - loss: 0.0339 - accuracy: 0.9920\n",
      "Epoch 16/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0349 - accuracy: 0.9911\n",
      "Epoch 17/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0412 - accuracy: 0.9879\n",
      "Epoch 18/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0349 - accuracy: 0.9899\n",
      "Epoch 19/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0360 - accuracy: 0.9903\n",
      "Epoch 20/50\n",
      "184/184 [==============================] - 5s 24ms/step - loss: 0.0289 - accuracy: 0.9918\n",
      "Epoch 21/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0337 - accuracy: 0.9894\n",
      "Epoch 22/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0277 - accuracy: 0.9908\n",
      "Epoch 23/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0201 - accuracy: 0.9951\n",
      "Epoch 24/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0164 - accuracy: 0.9956\n",
      "Epoch 25/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0160 - accuracy: 0.9956\n",
      "Epoch 26/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0153 - accuracy: 0.9956\n",
      "Epoch 27/50\n",
      "184/184 [==============================] - 5s 27ms/step - loss: 0.0337 - accuracy: 0.9899\n",
      "Epoch 28/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0267 - accuracy: 0.9913\n",
      "Epoch 29/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0151 - accuracy: 0.9951\n",
      "Epoch 30/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0123 - accuracy: 0.9962\n",
      "Epoch 31/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0116 - accuracy: 0.9962\n",
      "Epoch 32/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0128 - accuracy: 0.9949\n",
      "Epoch 33/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0252 - accuracy: 0.9910\n",
      "Epoch 34/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0153 - accuracy: 0.9944\n",
      "Epoch 35/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0121 - accuracy: 0.9959\n",
      "Epoch 36/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0098 - accuracy: 0.9968\n",
      "Epoch 37/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0100 - accuracy: 0.9968\n",
      "Epoch 38/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0076 - accuracy: 0.9971\n",
      "Epoch 39/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0066 - accuracy: 0.9974\n",
      "Epoch 40/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0079 - accuracy: 0.9969\n",
      "Epoch 41/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0069 - accuracy: 0.9974\n",
      "Epoch 42/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0066 - accuracy: 0.9976\n",
      "Epoch 43/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0064 - accuracy: 0.9974\n",
      "Epoch 44/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0068 - accuracy: 0.9968\n",
      "Epoch 45/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0075 - accuracy: 0.9973\n",
      "Epoch 46/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0225 - accuracy: 0.9918\n",
      "Epoch 47/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0337 - accuracy: 0.9893\n",
      "Epoch 48/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0160 - accuracy: 0.9928\n",
      "Epoch 49/50\n",
      "184/184 [==============================] - 5s 26ms/step - loss: 0.0104 - accuracy: 0.9961\n",
      "Epoch 50/50\n",
      "184/184 [==============================] - 5s 25ms/step - loss: 0.0069 - accuracy: 0.9973\n",
      "92/92 [==============================] - 2s 12ms/step\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=50, learning_rate=0.001, lstm_units=64, num_lstm_layers=2; total time= 4.0min\n",
      "Epoch 1/20\n",
      "92/92 [==============================] - 4s 18ms/step - loss: 0.6720 - accuracy: 0.5853\n",
      "Epoch 2/20\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.5772 - accuracy: 0.7072\n",
      "Epoch 3/20\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.3744 - accuracy: 0.8406\n",
      "Epoch 4/20\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.2726 - accuracy: 0.8907\n",
      "Epoch 5/20\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.2105 - accuracy: 0.9209\n",
      "Epoch 6/20\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.1647 - accuracy: 0.9391\n",
      "Epoch 7/20\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.1323 - accuracy: 0.9531\n",
      "Epoch 8/20\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.1068 - accuracy: 0.9667\n",
      "Epoch 9/20\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0857 - accuracy: 0.9714\n",
      "Epoch 10/20\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0773 - accuracy: 0.9729\n",
      "Epoch 11/20\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0654 - accuracy: 0.9797\n",
      "Epoch 12/20\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0568 - accuracy: 0.9824\n",
      "Epoch 13/20\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0505 - accuracy: 0.9843\n",
      "Epoch 14/20\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0463 - accuracy: 0.9860\n",
      "Epoch 15/20\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0417 - accuracy: 0.9867\n",
      "Epoch 16/20\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.0477 - accuracy: 0.9845\n",
      "Epoch 17/20\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.0470 - accuracy: 0.9845\n",
      "Epoch 18/20\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.0329 - accuracy: 0.9910\n",
      "Epoch 19/20\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0310 - accuracy: 0.9906\n",
      "Epoch 20/20\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0285 - accuracy: 0.9916\n",
      "92/92 [==============================] - 1s 7ms/step\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=20, learning_rate=0.001, lstm_units=64, num_lstm_layers=1; total time=  34.8s\n",
      "Epoch 1/20\n",
      "92/92 [==============================] - 4s 18ms/step - loss: 0.6700 - accuracy: 0.5727\n",
      "Epoch 2/20\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.6083 - accuracy: 0.6847\n",
      "Epoch 3/20\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.4002 - accuracy: 0.8251\n",
      "Epoch 4/20\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.2843 - accuracy: 0.8856\n",
      "Epoch 5/20\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.2128 - accuracy: 0.9175\n",
      "Epoch 6/20\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.1675 - accuracy: 0.9379\n",
      "Epoch 7/20\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.1365 - accuracy: 0.9512\n",
      "Epoch 8/20\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.1065 - accuracy: 0.9645\n",
      "Epoch 9/20\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0964 - accuracy: 0.9668\n",
      "Epoch 10/20\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.0823 - accuracy: 0.9729\n",
      "Epoch 11/20\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0691 - accuracy: 0.9768\n",
      "Epoch 12/20\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0660 - accuracy: 0.9772\n",
      "Epoch 13/20\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0647 - accuracy: 0.9787\n",
      "Epoch 14/20\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0517 - accuracy: 0.9823\n",
      "Epoch 15/20\n",
      "92/92 [==============================] - 1s 15ms/step - loss: 0.0404 - accuracy: 0.9872\n",
      "Epoch 16/20\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0413 - accuracy: 0.9877\n",
      "Epoch 17/20\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0326 - accuracy: 0.9889\n",
      "Epoch 18/20\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0414 - accuracy: 0.9876\n",
      "Epoch 19/20\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0307 - accuracy: 0.9905\n",
      "Epoch 20/20\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0281 - accuracy: 0.9920\n",
      "92/92 [==============================] - 1s 7ms/step\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=20, learning_rate=0.001, lstm_units=64, num_lstm_layers=1; total time=  33.7s\n",
      "Epoch 1/20\n",
      "92/92 [==============================] - 4s 18ms/step - loss: 0.6746 - accuracy: 0.5746\n",
      "Epoch 2/20\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.5878 - accuracy: 0.6960\n",
      "Epoch 3/20\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.3738 - accuracy: 0.8397\n",
      "Epoch 4/20\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.2739 - accuracy: 0.8900\n",
      "Epoch 5/20\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.2081 - accuracy: 0.9214\n",
      "Epoch 6/20\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.1608 - accuracy: 0.9408\n",
      "Epoch 7/20\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.1313 - accuracy: 0.9546\n",
      "Epoch 8/20\n",
      "92/92 [==============================] - 1s 15ms/step - loss: 0.1114 - accuracy: 0.9598\n",
      "Epoch 9/20\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.0885 - accuracy: 0.9715\n",
      "Epoch 10/20\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0702 - accuracy: 0.9790\n",
      "Epoch 11/20\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0639 - accuracy: 0.9804\n",
      "Epoch 12/20\n",
      "92/92 [==============================] - 1s 15ms/step - loss: 0.0540 - accuracy: 0.9818\n",
      "Epoch 13/20\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0445 - accuracy: 0.9860\n",
      "Epoch 14/20\n",
      "92/92 [==============================] - 1s 15ms/step - loss: 0.0397 - accuracy: 0.9881\n",
      "Epoch 15/20\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0348 - accuracy: 0.9887\n",
      "Epoch 16/20\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0358 - accuracy: 0.9886\n",
      "Epoch 17/20\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0319 - accuracy: 0.9896\n",
      "Epoch 18/20\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0265 - accuracy: 0.9928\n",
      "Epoch 19/20\n",
      "92/92 [==============================] - 1s 15ms/step - loss: 0.0205 - accuracy: 0.9937\n",
      "Epoch 20/20\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0229 - accuracy: 0.9930\n",
      "92/92 [==============================] - 1s 7ms/step\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=20, learning_rate=0.001, lstm_units=64, num_lstm_layers=1; total time=  33.8s\n",
      "Epoch 1/20\n",
      "92/92 [==============================] - 6s 29ms/step - loss: 0.6714 - accuracy: 0.5836\n",
      "Epoch 2/20\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5447 - accuracy: 0.7225\n",
      "Epoch 3/20\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3450 - accuracy: 0.8479\n",
      "Epoch 4/20\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.2472 - accuracy: 0.9014\n",
      "Epoch 5/20\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.1860 - accuracy: 0.9277\n",
      "Epoch 6/20\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.1476 - accuracy: 0.9470\n",
      "Epoch 7/20\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.1176 - accuracy: 0.9565\n",
      "Epoch 8/20\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.0873 - accuracy: 0.9685\n",
      "Epoch 9/20\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.0706 - accuracy: 0.9761\n",
      "Epoch 10/20\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0625 - accuracy: 0.9795\n",
      "Epoch 11/20\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.0622 - accuracy: 0.9826\n",
      "Epoch 12/20\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.0475 - accuracy: 0.9864\n",
      "Epoch 13/20\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0464 - accuracy: 0.9858\n",
      "Epoch 14/20\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0455 - accuracy: 0.9855\n",
      "Epoch 15/20\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.0402 - accuracy: 0.9872\n",
      "Epoch 16/20\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0400 - accuracy: 0.9874\n",
      "Epoch 17/20\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0331 - accuracy: 0.9901\n",
      "Epoch 18/20\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.0303 - accuracy: 0.9910\n",
      "Epoch 19/20\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.0291 - accuracy: 0.9913\n",
      "Epoch 20/20\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.0257 - accuracy: 0.9928\n",
      "92/92 [==============================] - 2s 11ms/step\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=20, learning_rate=0.001, lstm_units=64, num_lstm_layers=2; total time=  54.1s\n",
      "Epoch 1/20\n",
      "92/92 [==============================] - 6s 30ms/step - loss: 0.6725 - accuracy: 0.5754\n",
      "Epoch 2/20\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5892 - accuracy: 0.6791\n",
      "Epoch 3/20\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3556 - accuracy: 0.8479\n",
      "Epoch 4/20\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.2480 - accuracy: 0.9047\n",
      "Epoch 5/20\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.1860 - accuracy: 0.9325\n",
      "Epoch 6/20\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.1455 - accuracy: 0.9509\n",
      "Epoch 7/20\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.1188 - accuracy: 0.9615\n",
      "Epoch 8/20\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.0995 - accuracy: 0.9673\n",
      "Epoch 9/20\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.0851 - accuracy: 0.9731\n",
      "Epoch 10/20\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.0734 - accuracy: 0.9785\n",
      "Epoch 11/20\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.0634 - accuracy: 0.9818\n",
      "Epoch 12/20\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.0607 - accuracy: 0.9797\n",
      "Epoch 13/20\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0595 - accuracy: 0.9812\n",
      "Epoch 14/20\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.0481 - accuracy: 0.9855\n",
      "Epoch 15/20\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0459 - accuracy: 0.9841\n",
      "Epoch 16/20\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.0399 - accuracy: 0.9879\n",
      "Epoch 17/20\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0363 - accuracy: 0.9899\n",
      "Epoch 18/20\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.0334 - accuracy: 0.9906\n",
      "Epoch 19/20\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0386 - accuracy: 0.9881\n",
      "Epoch 20/20\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0442 - accuracy: 0.9850\n",
      "92/92 [==============================] - 2s 11ms/step\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=20, learning_rate=0.001, lstm_units=64, num_lstm_layers=2; total time=  55.7s\n",
      "Epoch 1/20\n",
      "92/92 [==============================] - 6s 28ms/step - loss: 0.6757 - accuracy: 0.5693\n",
      "Epoch 2/20\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5930 - accuracy: 0.6691\n",
      "Epoch 3/20\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3652 - accuracy: 0.8396\n",
      "Epoch 4/20\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.2529 - accuracy: 0.8968\n",
      "Epoch 5/20\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.1922 - accuracy: 0.9306\n",
      "Epoch 6/20\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.1503 - accuracy: 0.9477\n",
      "Epoch 7/20\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.1212 - accuracy: 0.9574\n",
      "Epoch 8/20\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0938 - accuracy: 0.9690\n",
      "Epoch 9/20\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.0887 - accuracy: 0.9690\n",
      "Epoch 10/20\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0702 - accuracy: 0.9782\n",
      "Epoch 11/20\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0628 - accuracy: 0.9789\n",
      "Epoch 12/20\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.0535 - accuracy: 0.9843\n",
      "Epoch 13/20\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0471 - accuracy: 0.9862\n",
      "Epoch 14/20\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0431 - accuracy: 0.9876\n",
      "Epoch 15/20\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0383 - accuracy: 0.9896\n",
      "Epoch 16/20\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.0396 - accuracy: 0.9879\n",
      "Epoch 17/20\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.0345 - accuracy: 0.9893\n",
      "Epoch 18/20\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0313 - accuracy: 0.9913\n",
      "Epoch 19/20\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.0323 - accuracy: 0.9910\n",
      "Epoch 20/20\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.0312 - accuracy: 0.9910\n",
      "92/92 [==============================] - 2s 11ms/step\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=20, learning_rate=0.001, lstm_units=64, num_lstm_layers=2; total time=  55.0s\n",
      "Epoch 1/50\n",
      "92/92 [==============================] - 4s 19ms/step - loss: 0.6740 - accuracy: 0.5805\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.5891 - accuracy: 0.6861\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.3865 - accuracy: 0.8366\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.2806 - accuracy: 0.8897\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.2188 - accuracy: 0.9187\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.1698 - accuracy: 0.9388\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.1351 - accuracy: 0.9526\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.1107 - accuracy: 0.9640\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.1010 - accuracy: 0.9647\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0847 - accuracy: 0.9727\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.0670 - accuracy: 0.9783\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0616 - accuracy: 0.9785\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.0534 - accuracy: 0.9843\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0562 - accuracy: 0.9831\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0470 - accuracy: 0.9865\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0464 - accuracy: 0.9862\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.0372 - accuracy: 0.9886\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.0310 - accuracy: 0.9901\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0325 - accuracy: 0.9898\n",
      "Epoch 20/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0291 - accuracy: 0.9899\n",
      "Epoch 21/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0321 - accuracy: 0.9903\n",
      "Epoch 22/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0313 - accuracy: 0.9910\n",
      "Epoch 23/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0304 - accuracy: 0.9899\n",
      "Epoch 24/50\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.0279 - accuracy: 0.9916\n",
      "Epoch 25/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0242 - accuracy: 0.9925\n",
      "Epoch 26/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0239 - accuracy: 0.9922\n",
      "Epoch 27/50\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.0189 - accuracy: 0.9939\n",
      "Epoch 28/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0269 - accuracy: 0.9901\n",
      "Epoch 29/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0213 - accuracy: 0.9928\n",
      "Epoch 30/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0202 - accuracy: 0.9930\n",
      "Epoch 31/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0175 - accuracy: 0.9940\n",
      "Epoch 32/50\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.0171 - accuracy: 0.9928\n",
      "Epoch 33/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0208 - accuracy: 0.9927\n",
      "Epoch 34/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0183 - accuracy: 0.9939\n",
      "Epoch 35/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0162 - accuracy: 0.9940\n",
      "Epoch 36/50\n",
      "92/92 [==============================] - 1s 15ms/step - loss: 0.0160 - accuracy: 0.9942\n",
      "Epoch 37/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0205 - accuracy: 0.9928\n",
      "Epoch 38/50\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.0196 - accuracy: 0.9922\n",
      "Epoch 39/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0197 - accuracy: 0.9927\n",
      "Epoch 40/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0196 - accuracy: 0.9925\n",
      "Epoch 41/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0170 - accuracy: 0.9930\n",
      "Epoch 42/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0143 - accuracy: 0.9945\n",
      "Epoch 43/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0119 - accuracy: 0.9944\n",
      "Epoch 44/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0140 - accuracy: 0.9944\n",
      "Epoch 45/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0129 - accuracy: 0.9942\n",
      "Epoch 46/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0170 - accuracy: 0.9939\n",
      "Epoch 47/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0178 - accuracy: 0.9933\n",
      "Epoch 48/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0140 - accuracy: 0.9947\n",
      "Epoch 49/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0147 - accuracy: 0.9940\n",
      "Epoch 50/50\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.0182 - accuracy: 0.9935\n",
      "92/92 [==============================] - 1s 7ms/step\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=50, learning_rate=0.001, lstm_units=64, num_lstm_layers=1; total time= 1.3min\n",
      "Epoch 1/50\n",
      "92/92 [==============================] - 4s 17ms/step - loss: 0.6685 - accuracy: 0.5826\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.5934 - accuracy: 0.6887\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.3803 - accuracy: 0.8310\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.2676 - accuracy: 0.8926\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.2011 - accuracy: 0.9228\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.1575 - accuracy: 0.9432\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - 1s 15ms/step - loss: 0.1303 - accuracy: 0.9570\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.1044 - accuracy: 0.9659\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.0876 - accuracy: 0.9734\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.0732 - accuracy: 0.9770\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0693 - accuracy: 0.9770\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.0652 - accuracy: 0.9775\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0584 - accuracy: 0.9821\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0471 - accuracy: 0.9845\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0380 - accuracy: 0.9882\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0347 - accuracy: 0.9887\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0366 - accuracy: 0.9881\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0372 - accuracy: 0.9869\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0356 - accuracy: 0.9882\n",
      "Epoch 20/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0285 - accuracy: 0.9910\n",
      "Epoch 21/50\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.0241 - accuracy: 0.9923\n",
      "Epoch 22/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0203 - accuracy: 0.9935\n",
      "Epoch 23/50\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.0178 - accuracy: 0.9952\n",
      "Epoch 24/50\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.0205 - accuracy: 0.9940\n",
      "Epoch 25/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0223 - accuracy: 0.9934\n",
      "Epoch 26/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0217 - accuracy: 0.9925\n",
      "Epoch 27/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0213 - accuracy: 0.9937\n",
      "Epoch 28/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0311 - accuracy: 0.9910\n",
      "Epoch 29/50\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.0280 - accuracy: 0.9908\n",
      "Epoch 30/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0182 - accuracy: 0.9945\n",
      "Epoch 31/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0155 - accuracy: 0.9954\n",
      "Epoch 32/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0129 - accuracy: 0.9956\n",
      "Epoch 33/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0128 - accuracy: 0.9962\n",
      "Epoch 34/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0097 - accuracy: 0.9964\n",
      "Epoch 35/50\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.0097 - accuracy: 0.9973\n",
      "Epoch 36/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0103 - accuracy: 0.9964\n",
      "Epoch 37/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0230 - accuracy: 0.9913\n",
      "Epoch 38/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0221 - accuracy: 0.9923\n",
      "Epoch 39/50\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.0179 - accuracy: 0.9945\n",
      "Epoch 40/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0129 - accuracy: 0.9959\n",
      "Epoch 41/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0111 - accuracy: 0.9961\n",
      "Epoch 42/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0091 - accuracy: 0.9968\n",
      "Epoch 43/50\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.0083 - accuracy: 0.9969\n",
      "Epoch 44/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0084 - accuracy: 0.9971\n",
      "Epoch 45/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0083 - accuracy: 0.9973\n",
      "Epoch 46/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0080 - accuracy: 0.9971\n",
      "Epoch 47/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0087 - accuracy: 0.9971\n",
      "Epoch 48/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0086 - accuracy: 0.9969\n",
      "Epoch 49/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0079 - accuracy: 0.9973\n",
      "Epoch 50/50\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.0076 - accuracy: 0.9971\n",
      "92/92 [==============================] - 1s 6ms/step\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=50, learning_rate=0.001, lstm_units=64, num_lstm_layers=1; total time= 1.3min\n",
      "Epoch 1/50\n",
      "92/92 [==============================] - 4s 18ms/step - loss: 0.6731 - accuracy: 0.5746\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.5875 - accuracy: 0.6962\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3791 - accuracy: 0.8338\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.2691 - accuracy: 0.8919\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2072 - accuracy: 0.9223\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.1630 - accuracy: 0.9437\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.1323 - accuracy: 0.9536\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.1049 - accuracy: 0.9639\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0874 - accuracy: 0.9700\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.0796 - accuracy: 0.9717\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0674 - accuracy: 0.9792\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.0565 - accuracy: 0.9816\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.0523 - accuracy: 0.9831\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0418 - accuracy: 0.9877\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0377 - accuracy: 0.9874\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0376 - accuracy: 0.9884\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0356 - accuracy: 0.9889\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.0385 - accuracy: 0.9870\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.0301 - accuracy: 0.9920\n",
      "Epoch 20/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0266 - accuracy: 0.9928\n",
      "Epoch 21/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0215 - accuracy: 0.9940\n",
      "Epoch 22/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0293 - accuracy: 0.9911\n",
      "Epoch 23/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0294 - accuracy: 0.9911\n",
      "Epoch 24/50\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.0219 - accuracy: 0.9925\n",
      "Epoch 25/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0218 - accuracy: 0.9930\n",
      "Epoch 26/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0200 - accuracy: 0.9942\n",
      "Epoch 27/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0210 - accuracy: 0.9949\n",
      "Epoch 28/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0227 - accuracy: 0.9916\n",
      "Epoch 29/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0251 - accuracy: 0.9908\n",
      "Epoch 30/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0212 - accuracy: 0.9942\n",
      "Epoch 31/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0137 - accuracy: 0.9962\n",
      "Epoch 32/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0147 - accuracy: 0.9945\n",
      "Epoch 33/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0123 - accuracy: 0.9961\n",
      "Epoch 34/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0102 - accuracy: 0.9966\n",
      "Epoch 35/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0102 - accuracy: 0.9968\n",
      "Epoch 36/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0097 - accuracy: 0.9969\n",
      "Epoch 37/50\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.0104 - accuracy: 0.9968\n",
      "Epoch 38/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0087 - accuracy: 0.9968\n",
      "Epoch 39/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0086 - accuracy: 0.9968\n",
      "Epoch 40/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0091 - accuracy: 0.9971\n",
      "Epoch 41/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0122 - accuracy: 0.9959\n",
      "Epoch 42/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0158 - accuracy: 0.9947\n",
      "Epoch 43/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0157 - accuracy: 0.9951\n",
      "Epoch 44/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0234 - accuracy: 0.9920\n",
      "Epoch 45/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0202 - accuracy: 0.9930\n",
      "Epoch 46/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0113 - accuracy: 0.9968\n",
      "Epoch 47/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0169 - accuracy: 0.9944\n",
      "Epoch 48/50\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.0125 - accuracy: 0.9964\n",
      "Epoch 49/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0091 - accuracy: 0.9971\n",
      "Epoch 50/50\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0083 - accuracy: 0.9968\n",
      "92/92 [==============================] - 1s 7ms/step\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=50, learning_rate=0.001, lstm_units=64, num_lstm_layers=1; total time= 1.4min\n",
      "Epoch 1/50\n",
      "92/92 [==============================] - 6s 27ms/step - loss: 0.6753 - accuracy: 0.5773\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5893 - accuracy: 0.6797\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.3663 - accuracy: 0.8404\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.2614 - accuracy: 0.8989\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.1941 - accuracy: 0.9282\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.1423 - accuracy: 0.9511\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.1163 - accuracy: 0.9609\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.0920 - accuracy: 0.9685\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.0891 - accuracy: 0.9705\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.0638 - accuracy: 0.9789\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.0515 - accuracy: 0.9838\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.0454 - accuracy: 0.9884\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0441 - accuracy: 0.9864\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0414 - accuracy: 0.9877\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.0354 - accuracy: 0.9893\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.0341 - accuracy: 0.9903\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.0345 - accuracy: 0.9894\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0278 - accuracy: 0.9911\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.0263 - accuracy: 0.9918\n",
      "Epoch 20/50\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.0258 - accuracy: 0.9918\n",
      "Epoch 21/50\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.0283 - accuracy: 0.9913\n",
      "Epoch 22/50\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.0206 - accuracy: 0.9927\n",
      "Epoch 23/50\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.0191 - accuracy: 0.9932\n",
      "Epoch 24/50\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.0231 - accuracy: 0.9939\n",
      "Epoch 25/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0183 - accuracy: 0.9942\n",
      "Epoch 26/50\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.0183 - accuracy: 0.9937\n",
      "Epoch 27/50\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.0236 - accuracy: 0.9935\n",
      "Epoch 28/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0241 - accuracy: 0.9913\n",
      "Epoch 29/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0311 - accuracy: 0.9884\n",
      "Epoch 30/50\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.0249 - accuracy: 0.9908\n",
      "Epoch 31/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0245 - accuracy: 0.9922\n",
      "Epoch 32/50\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.0186 - accuracy: 0.9940\n",
      "Epoch 33/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0169 - accuracy: 0.9942\n",
      "Epoch 34/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0205 - accuracy: 0.9923\n",
      "Epoch 35/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0157 - accuracy: 0.9945\n",
      "Epoch 36/50\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.0213 - accuracy: 0.9930\n",
      "Epoch 37/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0146 - accuracy: 0.9944\n",
      "Epoch 38/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0140 - accuracy: 0.9947\n",
      "Epoch 39/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0133 - accuracy: 0.9945\n",
      "Epoch 40/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0140 - accuracy: 0.9947\n",
      "Epoch 41/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0127 - accuracy: 0.9939\n",
      "Epoch 42/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0127 - accuracy: 0.9954\n",
      "Epoch 43/50\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.0106 - accuracy: 0.9959\n",
      "Epoch 44/50\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.0109 - accuracy: 0.9951\n",
      "Epoch 45/50\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.0102 - accuracy: 0.9957\n",
      "Epoch 46/50\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.0093 - accuracy: 0.9962\n",
      "Epoch 47/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0106 - accuracy: 0.9951\n",
      "Epoch 48/50\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.0092 - accuracy: 0.9964\n",
      "Epoch 49/50\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.0117 - accuracy: 0.9952\n",
      "Epoch 50/50\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.0095 - accuracy: 0.9954\n",
      "92/92 [==============================] - 2s 11ms/step\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=50, learning_rate=0.001, lstm_units=64, num_lstm_layers=2; total time= 2.1min\n",
      "Epoch 1/50\n",
      "92/92 [==============================] - 7s 29ms/step - loss: 0.6703 - accuracy: 0.5714\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6024 - accuracy: 0.6658\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3675 - accuracy: 0.8389\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.2533 - accuracy: 0.9006\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.1964 - accuracy: 0.9286\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.1472 - accuracy: 0.9483\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.1138 - accuracy: 0.9615\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.0955 - accuracy: 0.9688\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.0788 - accuracy: 0.9744\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0690 - accuracy: 0.9773\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.0673 - accuracy: 0.9790\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.0592 - accuracy: 0.9801\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0476 - accuracy: 0.9865\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.0433 - accuracy: 0.9858\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.0456 - accuracy: 0.9857\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0347 - accuracy: 0.9893\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.0376 - accuracy: 0.9887\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0263 - accuracy: 0.9925\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.0229 - accuracy: 0.9937\n",
      "Epoch 20/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0249 - accuracy: 0.9930\n",
      "Epoch 21/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0202 - accuracy: 0.9942\n",
      "Epoch 22/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0162 - accuracy: 0.9954\n",
      "Epoch 23/50\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.0140 - accuracy: 0.9962\n",
      "Epoch 24/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0143 - accuracy: 0.9945\n",
      "Epoch 25/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0127 - accuracy: 0.9961\n",
      "Epoch 26/50\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.0148 - accuracy: 0.9957\n",
      "Epoch 27/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0222 - accuracy: 0.9928\n",
      "Epoch 28/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0291 - accuracy: 0.9896\n",
      "Epoch 29/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0213 - accuracy: 0.9927\n",
      "Epoch 30/50\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.0233 - accuracy: 0.9922\n",
      "Epoch 31/50\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.0162 - accuracy: 0.9945\n",
      "Epoch 32/50\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.0144 - accuracy: 0.9957\n",
      "Epoch 33/50\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.0150 - accuracy: 0.9952\n",
      "Epoch 34/50\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.0119 - accuracy: 0.9961\n",
      "Epoch 35/50\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.0113 - accuracy: 0.9964\n",
      "Epoch 36/50\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.0110 - accuracy: 0.9962\n",
      "Epoch 37/50\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.0105 - accuracy: 0.9961\n",
      "Epoch 38/50\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.0091 - accuracy: 0.9968\n",
      "Epoch 39/50\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.0087 - accuracy: 0.9968\n",
      "Epoch 40/50\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.0074 - accuracy: 0.9971\n",
      "Epoch 41/50\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.0074 - accuracy: 0.9971\n",
      "Epoch 42/50\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.0074 - accuracy: 0.9973\n",
      "Epoch 43/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0073 - accuracy: 0.9971\n",
      "Epoch 44/50\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.0064 - accuracy: 0.9971\n",
      "Epoch 45/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0073 - accuracy: 0.9969\n",
      "Epoch 46/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0073 - accuracy: 0.9971\n",
      "Epoch 47/50\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.0067 - accuracy: 0.9974\n",
      "Epoch 48/50\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.0064 - accuracy: 0.9973\n",
      "Epoch 49/50\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.0068 - accuracy: 0.9971\n",
      "Epoch 50/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0071 - accuracy: 0.9971\n",
      "92/92 [==============================] - 2s 11ms/step\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=50, learning_rate=0.001, lstm_units=64, num_lstm_layers=2; total time= 2.2min\n",
      "Epoch 1/50\n",
      "92/92 [==============================] - 6s 27ms/step - loss: 0.6720 - accuracy: 0.5777\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5883 - accuracy: 0.6864\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.3656 - accuracy: 0.8406\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.2607 - accuracy: 0.8965\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.1909 - accuracy: 0.9308\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.1487 - accuracy: 0.9460\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.1169 - accuracy: 0.9596\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.0919 - accuracy: 0.9698\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.0731 - accuracy: 0.9756\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0593 - accuracy: 0.9816\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.0534 - accuracy: 0.9840\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0513 - accuracy: 0.9835\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.0501 - accuracy: 0.9835\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.0467 - accuracy: 0.9848\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0402 - accuracy: 0.9877\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0350 - accuracy: 0.9901\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.0300 - accuracy: 0.9908\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.0335 - accuracy: 0.9899\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.0253 - accuracy: 0.9932\n",
      "Epoch 20/50\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.0283 - accuracy: 0.9918\n",
      "Epoch 21/50\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.0309 - accuracy: 0.9913\n",
      "Epoch 22/50\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.0244 - accuracy: 0.9935\n",
      "Epoch 23/50\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.0219 - accuracy: 0.9944\n",
      "Epoch 24/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0207 - accuracy: 0.9942\n",
      "Epoch 25/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0193 - accuracy: 0.9951\n",
      "Epoch 26/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0176 - accuracy: 0.9951\n",
      "Epoch 27/50\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.0170 - accuracy: 0.9956\n",
      "Epoch 28/50\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.0189 - accuracy: 0.9952\n",
      "Epoch 29/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0143 - accuracy: 0.9956\n",
      "Epoch 30/50\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.0157 - accuracy: 0.9961\n",
      "Epoch 31/50\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.0181 - accuracy: 0.9949\n",
      "Epoch 32/50\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.0194 - accuracy: 0.9923\n",
      "Epoch 33/50\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.0156 - accuracy: 0.9951\n",
      "Epoch 34/50\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.0203 - accuracy: 0.9934\n",
      "Epoch 35/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0168 - accuracy: 0.9944\n",
      "Epoch 36/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0132 - accuracy: 0.9956\n",
      "Epoch 37/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0102 - accuracy: 0.9968\n",
      "Epoch 38/50\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.0132 - accuracy: 0.9951\n",
      "Epoch 39/50\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.0207 - accuracy: 0.9935\n",
      "Epoch 40/50\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.0155 - accuracy: 0.9942\n",
      "Epoch 41/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0097 - accuracy: 0.9961\n",
      "Epoch 42/50\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.0090 - accuracy: 0.9966\n",
      "Epoch 43/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0088 - accuracy: 0.9969\n",
      "Epoch 44/50\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.0077 - accuracy: 0.9971\n",
      "Epoch 45/50\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.0084 - accuracy: 0.9973\n",
      "Epoch 46/50\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.0074 - accuracy: 0.9971\n",
      "Epoch 47/50\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.0074 - accuracy: 0.9973\n",
      "Epoch 48/50\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.0085 - accuracy: 0.9964\n",
      "Epoch 49/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0075 - accuracy: 0.9971\n",
      "Epoch 50/50\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.0080 - accuracy: 0.9973\n",
      "92/92 [==============================] - 2s 11ms/step\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=50, learning_rate=0.001, lstm_units=64, num_lstm_layers=2; total time= 2.1min\n",
      "Epoch 1/20\n",
      "138/138 [==============================] - 8s 27ms/step - loss: 0.6701 - accuracy: 0.5816\n",
      "Epoch 2/20\n",
      "138/138 [==============================] - 4s 29ms/step - loss: 0.4963 - accuracy: 0.7595\n",
      "Epoch 3/20\n",
      "138/138 [==============================] - 4s 26ms/step - loss: 0.3297 - accuracy: 0.8611\n",
      "Epoch 4/20\n",
      "138/138 [==============================] - 4s 27ms/step - loss: 0.2613 - accuracy: 0.9008\n",
      "Epoch 5/20\n",
      "138/138 [==============================] - 4s 28ms/step - loss: 0.2175 - accuracy: 0.9186\n",
      "Epoch 6/20\n",
      "138/138 [==============================] - 4s 27ms/step - loss: 0.1854 - accuracy: 0.9324\n",
      "Epoch 7/20\n",
      "138/138 [==============================] - 4s 27ms/step - loss: 0.1634 - accuracy: 0.9432\n",
      "Epoch 8/20\n",
      "138/138 [==============================] - 4s 26ms/step - loss: 0.1430 - accuracy: 0.9498\n",
      "Epoch 9/20\n",
      "138/138 [==============================] - 4s 27ms/step - loss: 0.1237 - accuracy: 0.9590\n",
      "Epoch 10/20\n",
      "138/138 [==============================] - 4s 27ms/step - loss: 0.1039 - accuracy: 0.9674\n",
      "Epoch 11/20\n",
      "138/138 [==============================] - 4s 27ms/step - loss: 0.0882 - accuracy: 0.9736\n",
      "Epoch 12/20\n",
      "138/138 [==============================] - 4s 28ms/step - loss: 0.0772 - accuracy: 0.9787\n",
      "Epoch 13/20\n",
      "138/138 [==============================] - 4s 27ms/step - loss: 0.0636 - accuracy: 0.9829\n",
      "Epoch 14/20\n",
      "138/138 [==============================] - 4s 26ms/step - loss: 0.0566 - accuracy: 0.9844\n",
      "Epoch 15/20\n",
      "138/138 [==============================] - 4s 26ms/step - loss: 0.0496 - accuracy: 0.9866\n",
      "Epoch 16/20\n",
      "138/138 [==============================] - 4s 26ms/step - loss: 0.0442 - accuracy: 0.9885\n",
      "Epoch 17/20\n",
      "138/138 [==============================] - 4s 27ms/step - loss: 0.0431 - accuracy: 0.9876\n",
      "Epoch 18/20\n",
      "138/138 [==============================] - 4s 25ms/step - loss: 0.0432 - accuracy: 0.9881\n",
      "Epoch 19/20\n",
      "138/138 [==============================] - 4s 26ms/step - loss: 0.0338 - accuracy: 0.9907\n",
      "Epoch 20/20\n",
      "138/138 [==============================] - 4s 26ms/step - loss: 0.0314 - accuracy: 0.9918\n"
     ]
    }
   ],
   "source": [
    "grid_result = grid.fit(X_train, Y_train, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "40a60795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏆 Mejores parámetros: {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 20, 'learning_rate': 0.001, 'lstm_units': 64, 'num_lstm_layers': 1}\n",
      "✅ Mejor accuracy en CV: 0.7516184168888099\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "params",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "mean_test_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "std_test_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rank_test_score",
         "rawType": "int32",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "a93b0106-4510-4637-8afe-35979a4b4d90",
       "rows": [
        [
         "4",
         "{'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 20, 'learning_rate': 0.001, 'lstm_units': 64, 'num_lstm_layers': 1}",
         "0.7516184168888099",
         "0.011759369162055843",
         "1"
        ],
        [
         "1",
         "{'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 20, 'learning_rate': 0.001, 'lstm_units': 64, 'num_lstm_layers': 2}",
         "0.748436740997636",
         "0.0056095689116910895",
         "2"
        ],
        [
         "5",
         "{'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 20, 'learning_rate': 0.001, 'lstm_units': 64, 'num_lstm_layers': 2}",
         "0.7474137424459278",
         "0.003601694543499691",
         "3"
        ],
        [
         "0",
         "{'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 20, 'learning_rate': 0.001, 'lstm_units': 64, 'num_lstm_layers': 1}",
         "0.7452535534005089",
         "0.004133064863154346",
         "4"
        ],
        [
         "7",
         "{'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'learning_rate': 0.001, 'lstm_units': 64, 'num_lstm_layers': 2}",
         "0.744798723717054",
         "0.007422516878113838",
         "5"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'batch_size': 64, 'dropout_rate': 0.2, 'epoch...</td>\n",
       "      <td>0.751618</td>\n",
       "      <td>0.011759</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'batch_size': 32, 'dropout_rate': 0.2, 'epoch...</td>\n",
       "      <td>0.748437</td>\n",
       "      <td>0.005610</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'batch_size': 64, 'dropout_rate': 0.2, 'epoch...</td>\n",
       "      <td>0.747414</td>\n",
       "      <td>0.003602</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'batch_size': 32, 'dropout_rate': 0.2, 'epoch...</td>\n",
       "      <td>0.745254</td>\n",
       "      <td>0.004133</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'batch_size': 64, 'dropout_rate': 0.2, 'epoch...</td>\n",
       "      <td>0.744799</td>\n",
       "      <td>0.007423</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params  mean_test_score  \\\n",
       "4  {'batch_size': 64, 'dropout_rate': 0.2, 'epoch...         0.751618   \n",
       "1  {'batch_size': 32, 'dropout_rate': 0.2, 'epoch...         0.748437   \n",
       "5  {'batch_size': 64, 'dropout_rate': 0.2, 'epoch...         0.747414   \n",
       "0  {'batch_size': 32, 'dropout_rate': 0.2, 'epoch...         0.745254   \n",
       "7  {'batch_size': 64, 'dropout_rate': 0.2, 'epoch...         0.744799   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "4        0.011759                1  \n",
       "1        0.005610                2  \n",
       "5        0.003602                3  \n",
       "0        0.004133                4  \n",
       "7        0.007423                5  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"🏆 Mejores parámetros:\", grid_result.best_params_)\n",
    "print(\"✅ Mejor accuracy en CV:\", grid_result.best_score_)\n",
    "\n",
    "results = pd.DataFrame(grid_result.cv_results_)\n",
    "results[['params', 'mean_test_score', 'std_test_score', 'rank_test_score']].sort_values('rank_test_score').head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e70afe56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 1s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "yhat_probs_lstm = grid_result.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e366527",
   "metadata": {},
   "source": [
    "### **Resultados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "72733513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lstm_val = confusion_matrix(Y_test, yhat_probs_lstm)\n",
    "f, ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(lstm_val, annot=True, linewidth=0.7, linecolor='cyan', fmt='g', ax=ax, cmap=\"Blues\")\n",
    "plt.title('LSTM Classification Confusion Matrix')\n",
    "plt.xlabel('Y predict')\n",
    "plt.ylabel('Y test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5d06bc27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Modelo",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Recall",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F1 Score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Accuracy",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "5dbfde34-5869-4a18-82f7-9b57bba93e33",
       "rows": [
        [
         "0",
         "LSTM",
         "0.761",
         "0.7919",
         "0.7761",
         "0.7645"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.7919</td>\n",
       "      <td>0.7761</td>\n",
       "      <td>0.7645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Modelo  Precision  Recall  F1 Score  Accuracy\n",
       "0   LSTM      0.761  0.7919    0.7761    0.7645"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_lstm=[]\n",
    "precision = precision_score(Y_test, yhat_probs_lstm)\n",
    "recall = recall_score(Y_test, yhat_probs_lstm)\n",
    "f1 = f1_score(Y_test, yhat_probs_lstm)\n",
    "accuracy = accuracy_score(Y_test, yhat_probs_lstm)\n",
    "\n",
    "metrics_lstm = [{\n",
    "    'Modelo': 'LSTM',\n",
    "    'Precision': round(precision, 4),\n",
    "    'Recall': round(recall, 4),\n",
    "    'F1 Score': round(f1, 4),\n",
    "    'Accuracy': round(accuracy, 4)\n",
    "}]\n",
    "\n",
    "# Convertir en DataFrame y mostrarlo\n",
    "df_metrics = pd.DataFrame(metrics_lstm)\n",
    "df_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "282bed8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(Y_test, yhat_probs_lstm)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Graficar la curva ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Línea diagonal\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea93d359",
   "metadata": {},
   "source": [
    "## **RNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce8efbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "718bdab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rnn_model(rnn_units=64, num_rnn_layers=1, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(len(d2v_model.wv.key_to_index) + 1, 20, input_length=X.shape[1], weights=[embedding_matrix], trainable=True))\n",
    "    \n",
    "    for i in range(num_rnn_layers):\n",
    "        return_seq = (i < num_rnn_layers - 1)\n",
    "        model.add(SimpleRNN(units=rnn_units, return_sequences=return_seq))\n",
    "\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=learning_rate), metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80a7ddad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rnn = KerasClassifier(build_fn=create_rnn_model, verbose=0)\n",
    "\n",
    "param_grid_rnn = {\n",
    "    'rnn_units': [64, 128],\n",
    "    'num_rnn_layers': [1],\n",
    "    'dropout_rate': [0.2, 0.5],\n",
    "    'learning_rate': [0.001],\n",
    "    'batch_size': [32, 64],\n",
    "    'epochs': [20, 50]\n",
    "}\n",
    "\n",
    "grid_rnn = GridSearchCV(estimator=model_rnn, param_grid=param_grid_rnn, cv=3, scoring='accuracy',verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba692535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Epoch 1/20\n",
      "184/184 [==============================] - 23s 108ms/step - loss: 0.6775 - accuracy: 0.5812\n",
      "Epoch 2/20\n",
      "184/184 [==============================] - 20s 108ms/step - loss: 0.5431 - accuracy: 0.7271\n",
      "Epoch 3/20\n",
      "184/184 [==============================] - 19s 104ms/step - loss: 0.3536 - accuracy: 0.8530\n",
      "Epoch 4/20\n",
      "184/184 [==============================] - 21s 113ms/step - loss: 0.2324 - accuracy: 0.9096\n",
      "Epoch 5/20\n",
      "184/184 [==============================] - 20s 107ms/step - loss: 0.1579 - accuracy: 0.9405\n",
      "Epoch 6/20\n",
      "184/184 [==============================] - 20s 108ms/step - loss: 0.1101 - accuracy: 0.9627\n",
      "Epoch 7/20\n",
      "184/184 [==============================] - 20s 108ms/step - loss: 0.0761 - accuracy: 0.9749\n",
      "Epoch 8/20\n",
      "184/184 [==============================] - 21s 112ms/step - loss: 0.0594 - accuracy: 0.9823\n",
      "Epoch 9/20\n",
      "184/184 [==============================] - 21s 113ms/step - loss: 0.0408 - accuracy: 0.9881\n",
      "Epoch 10/20\n",
      "184/184 [==============================] - 21s 113ms/step - loss: 0.0397 - accuracy: 0.9869\n",
      "Epoch 11/20\n",
      "184/184 [==============================] - 23s 125ms/step - loss: 0.0310 - accuracy: 0.9906\n",
      "Epoch 12/20\n",
      "184/184 [==============================] - 21s 114ms/step - loss: 0.0328 - accuracy: 0.9901\n",
      "Epoch 13/20\n",
      "184/184 [==============================] - 21s 113ms/step - loss: 0.0262 - accuracy: 0.9928\n",
      "Epoch 14/20\n",
      "184/184 [==============================] - 20s 109ms/step - loss: 0.0244 - accuracy: 0.9923\n",
      "Epoch 15/20\n",
      "184/184 [==============================] - 20s 108ms/step - loss: 0.0291 - accuracy: 0.9908\n",
      "Epoch 16/20\n",
      "184/184 [==============================] - 21s 114ms/step - loss: 0.0444 - accuracy: 0.9869\n",
      "Epoch 17/20\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.0377 - accuracy: 0.9891\n",
      "Epoch 18/20\n",
      "184/184 [==============================] - 20s 110ms/step - loss: 0.0208 - accuracy: 0.9937\n",
      "Epoch 19/20\n",
      "184/184 [==============================] - 20s 109ms/step - loss: 0.0175 - accuracy: 0.9937\n",
      "Epoch 20/20\n",
      "184/184 [==============================] - 20s 110ms/step - loss: 0.0187 - accuracy: 0.9933\n",
      "92/92 [==============================] - 2s 16ms/step\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=20, learning_rate=0.001, num_rnn_layers=1, rnn_units=64; total time= 6.9min\n",
      "Epoch 1/20\n",
      "184/184 [==============================] - 22s 109ms/step - loss: 0.6591 - accuracy: 0.5962\n",
      "Epoch 2/20\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.4511 - accuracy: 0.7981\n",
      "Epoch 3/20\n",
      "184/184 [==============================] - 20s 106ms/step - loss: 0.3161 - accuracy: 0.8713\n",
      "Epoch 4/20\n",
      "184/184 [==============================] - 19s 106ms/step - loss: 0.2227 - accuracy: 0.9151\n",
      "Epoch 5/20\n",
      "184/184 [==============================] - 20s 110ms/step - loss: 0.1723 - accuracy: 0.9388\n",
      "Epoch 6/20\n",
      "184/184 [==============================] - 20s 106ms/step - loss: 0.1652 - accuracy: 0.9383\n",
      "Epoch 7/20\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.1185 - accuracy: 0.9572\n",
      "Epoch 8/20\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.0914 - accuracy: 0.9678\n",
      "Epoch 9/20\n",
      "184/184 [==============================] - 20s 107ms/step - loss: 0.0786 - accuracy: 0.9719\n",
      "Epoch 10/20\n",
      "184/184 [==============================] - 21s 112ms/step - loss: 0.0559 - accuracy: 0.9829\n",
      "Epoch 11/20\n",
      "184/184 [==============================] - 21s 111ms/step - loss: 0.0455 - accuracy: 0.9855\n",
      "Epoch 12/20\n",
      "184/184 [==============================] - 21s 112ms/step - loss: 0.0308 - accuracy: 0.9922\n",
      "Epoch 13/20\n",
      "184/184 [==============================] - 19s 106ms/step - loss: 0.0303 - accuracy: 0.9915\n",
      "Epoch 14/20\n",
      "184/184 [==============================] - 20s 107ms/step - loss: 0.0298 - accuracy: 0.9922\n",
      "Epoch 15/20\n",
      "184/184 [==============================] - 20s 106ms/step - loss: 0.0279 - accuracy: 0.9910\n",
      "Epoch 16/20\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.0208 - accuracy: 0.9930\n",
      "Epoch 17/20\n",
      "184/184 [==============================] - 19s 106ms/step - loss: 0.0198 - accuracy: 0.9928\n",
      "Epoch 18/20\n",
      "184/184 [==============================] - 20s 106ms/step - loss: 0.0440 - accuracy: 0.9845\n",
      "Epoch 19/20\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.0251 - accuracy: 0.9915\n",
      "Epoch 20/20\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.0205 - accuracy: 0.9942\n",
      "92/92 [==============================] - 2s 15ms/step\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=20, learning_rate=0.001, num_rnn_layers=1, rnn_units=64; total time= 6.6min\n",
      "Epoch 1/20\n",
      "184/184 [==============================] - 20s 102ms/step - loss: 0.6643 - accuracy: 0.5957\n",
      "Epoch 2/20\n",
      "184/184 [==============================] - 20s 106ms/step - loss: 0.4728 - accuracy: 0.7836\n",
      "Epoch 3/20\n",
      "184/184 [==============================] - 20s 108ms/step - loss: 0.3138 - accuracy: 0.8716\n",
      "Epoch 4/20\n",
      "184/184 [==============================] - 20s 110ms/step - loss: 0.2163 - accuracy: 0.9163\n",
      "Epoch 5/20\n",
      "184/184 [==============================] - 20s 107ms/step - loss: 0.1633 - accuracy: 0.9395\n",
      "Epoch 6/20\n",
      "184/184 [==============================] - 20s 108ms/step - loss: 0.1089 - accuracy: 0.9628\n",
      "Epoch 7/20\n",
      "184/184 [==============================] - 19s 103ms/step - loss: 0.0827 - accuracy: 0.9739\n",
      "Epoch 8/20\n",
      "184/184 [==============================] - 19s 104ms/step - loss: 0.0543 - accuracy: 0.9819\n",
      "Epoch 9/20\n",
      "184/184 [==============================] - 19s 102ms/step - loss: 0.0362 - accuracy: 0.9882\n",
      "Epoch 10/20\n",
      "184/184 [==============================] - 19s 102ms/step - loss: 0.0309 - accuracy: 0.9910\n",
      "Epoch 11/20\n",
      "184/184 [==============================] - 19s 101ms/step - loss: 0.0348 - accuracy: 0.9889\n",
      "Epoch 12/20\n",
      "184/184 [==============================] - 19s 101ms/step - loss: 0.0323 - accuracy: 0.9889\n",
      "Epoch 13/20\n",
      "184/184 [==============================] - 18s 100ms/step - loss: 0.0283 - accuracy: 0.9911\n",
      "Epoch 14/20\n",
      "184/184 [==============================] - 20s 106ms/step - loss: 0.0303 - accuracy: 0.9908\n",
      "Epoch 15/20\n",
      "184/184 [==============================] - 20s 107ms/step - loss: 0.0192 - accuracy: 0.9939\n",
      "Epoch 16/20\n",
      "184/184 [==============================] - 19s 106ms/step - loss: 0.0137 - accuracy: 0.9959\n",
      "Epoch 17/20\n",
      "184/184 [==============================] - 20s 109ms/step - loss: 0.0173 - accuracy: 0.9945\n",
      "Epoch 18/20\n",
      "184/184 [==============================] - 19s 103ms/step - loss: 0.0221 - accuracy: 0.9916\n",
      "Epoch 19/20\n",
      "184/184 [==============================] - 19s 106ms/step - loss: 0.0289 - accuracy: 0.9908\n",
      "Epoch 20/20\n",
      "184/184 [==============================] - 19s 104ms/step - loss: 0.0193 - accuracy: 0.9940\n",
      "92/92 [==============================] - 2s 16ms/step\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=20, learning_rate=0.001, num_rnn_layers=1, rnn_units=64; total time= 6.5min\n",
      "Epoch 1/20\n",
      "184/184 [==============================] - 21s 107ms/step - loss: 0.6891 - accuracy: 0.5636\n",
      "Epoch 2/20\n",
      "184/184 [==============================] - 20s 106ms/step - loss: 0.6215 - accuracy: 0.6516\n",
      "Epoch 3/20\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.4327 - accuracy: 0.8085\n",
      "Epoch 4/20\n",
      "184/184 [==============================] - 19s 104ms/step - loss: 0.3034 - accuracy: 0.8707\n",
      "Epoch 5/20\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.2008 - accuracy: 0.9231\n",
      "Epoch 6/20\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.1286 - accuracy: 0.9541\n",
      "Epoch 7/20\n",
      "184/184 [==============================] - 21s 113ms/step - loss: 0.0856 - accuracy: 0.9725\n",
      "Epoch 8/20\n",
      "184/184 [==============================] - 21s 111ms/step - loss: 0.1051 - accuracy: 0.9601\n",
      "Epoch 9/20\n",
      "184/184 [==============================] - 20s 108ms/step - loss: 0.0616 - accuracy: 0.9792\n",
      "Epoch 10/20\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.0423 - accuracy: 0.9874\n",
      "Epoch 11/20\n",
      "184/184 [==============================] - 19s 106ms/step - loss: 0.0421 - accuracy: 0.9874\n",
      "Epoch 12/20\n",
      "184/184 [==============================] - 20s 110ms/step - loss: 0.0371 - accuracy: 0.9876\n",
      "Epoch 13/20\n",
      "184/184 [==============================] - 19s 106ms/step - loss: 0.0290 - accuracy: 0.9906\n",
      "Epoch 14/20\n",
      "184/184 [==============================] - 19s 104ms/step - loss: 0.0265 - accuracy: 0.9925\n",
      "Epoch 15/20\n",
      "184/184 [==============================] - 20s 108ms/step - loss: 0.0308 - accuracy: 0.9887\n",
      "Epoch 16/20\n",
      "184/184 [==============================] - 20s 106ms/step - loss: 0.0247 - accuracy: 0.9915\n",
      "Epoch 17/20\n",
      "184/184 [==============================] - 19s 104ms/step - loss: 0.0251 - accuracy: 0.9927\n",
      "Epoch 18/20\n",
      "184/184 [==============================] - 20s 106ms/step - loss: 0.0200 - accuracy: 0.9928\n",
      "Epoch 19/20\n",
      "184/184 [==============================] - 20s 109ms/step - loss: 0.0179 - accuracy: 0.9951\n",
      "Epoch 20/20\n",
      "184/184 [==============================] - 20s 109ms/step - loss: 0.0201 - accuracy: 0.9932\n",
      "92/92 [==============================] - 2s 15ms/step\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=20, learning_rate=0.001, num_rnn_layers=1, rnn_units=128; total time= 6.6min\n",
      "Epoch 1/20\n",
      "184/184 [==============================] - 21s 109ms/step - loss: 0.6894 - accuracy: 0.5620\n",
      "Epoch 2/20\n",
      "184/184 [==============================] - 19s 102ms/step - loss: 0.6199 - accuracy: 0.6498\n",
      "Epoch 3/20\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.4343 - accuracy: 0.8075\n",
      "Epoch 4/20\n",
      "184/184 [==============================] - 19s 104ms/step - loss: 0.2929 - accuracy: 0.8820\n",
      "Epoch 5/20\n",
      "184/184 [==============================] - 19s 104ms/step - loss: 0.2528 - accuracy: 0.8992\n",
      "Epoch 6/20\n",
      "184/184 [==============================] - 20s 108ms/step - loss: 0.1580 - accuracy: 0.9400\n",
      "Epoch 7/20\n",
      "184/184 [==============================] - 19s 102ms/step - loss: 0.1124 - accuracy: 0.9606\n",
      "Epoch 8/20\n",
      "184/184 [==============================] - 20s 108ms/step - loss: 0.0718 - accuracy: 0.9761\n",
      "Epoch 9/20\n",
      "184/184 [==============================] - 31s 167ms/step - loss: 0.0640 - accuracy: 0.9772\n",
      "Epoch 10/20\n",
      "184/184 [==============================] - 31s 169ms/step - loss: 0.0502 - accuracy: 0.9835\n",
      "Epoch 11/20\n",
      "184/184 [==============================] - 29s 156ms/step - loss: 0.0362 - accuracy: 0.9884\n",
      "Epoch 12/20\n",
      "184/184 [==============================] - 20s 107ms/step - loss: 0.0343 - accuracy: 0.9879\n",
      "Epoch 13/20\n",
      "184/184 [==============================] - 19s 101ms/step - loss: 0.0314 - accuracy: 0.9898\n",
      "Epoch 14/20\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.0288 - accuracy: 0.9903\n",
      "Epoch 15/20\n",
      "184/184 [==============================] - 19s 103ms/step - loss: 0.0236 - accuracy: 0.9922\n",
      "Epoch 16/20\n",
      "184/184 [==============================] - 19s 106ms/step - loss: 0.0311 - accuracy: 0.9906\n",
      "Epoch 17/20\n",
      "184/184 [==============================] - 19s 104ms/step - loss: 0.0268 - accuracy: 0.9915\n",
      "Epoch 18/20\n",
      "184/184 [==============================] - 19s 104ms/step - loss: 0.0347 - accuracy: 0.9889\n",
      "Epoch 19/20\n",
      "184/184 [==============================] - 19s 102ms/step - loss: 0.0550 - accuracy: 0.9811\n",
      "Epoch 20/20\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.0400 - accuracy: 0.9864\n",
      "92/92 [==============================] - 2s 16ms/step\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=20, learning_rate=0.001, num_rnn_layers=1, rnn_units=128; total time= 7.0min\n",
      "Epoch 1/20\n",
      "184/184 [==============================] - 21s 108ms/step - loss: 0.6886 - accuracy: 0.5517\n",
      "Epoch 2/20\n",
      "184/184 [==============================] - 20s 110ms/step - loss: 0.5744 - accuracy: 0.7035\n",
      "Epoch 3/20\n",
      "184/184 [==============================] - 20s 111ms/step - loss: 0.3794 - accuracy: 0.8361\n",
      "Epoch 4/20\n",
      "184/184 [==============================] - 20s 110ms/step - loss: 0.2610 - accuracy: 0.8936\n",
      "Epoch 5/20\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.1999 - accuracy: 0.9243\n",
      "Epoch 6/20\n",
      "184/184 [==============================] - 20s 108ms/step - loss: 0.1569 - accuracy: 0.9415\n",
      "Epoch 7/20\n",
      "184/184 [==============================] - 20s 111ms/step - loss: 0.1232 - accuracy: 0.9570\n",
      "Epoch 8/20\n",
      "184/184 [==============================] - 20s 107ms/step - loss: 0.0978 - accuracy: 0.9659\n",
      "Epoch 9/20\n",
      "184/184 [==============================] - 19s 102ms/step - loss: 0.0730 - accuracy: 0.9766\n",
      "Epoch 10/20\n",
      "184/184 [==============================] - 21s 112ms/step - loss: 0.0766 - accuracy: 0.9700\n",
      "Epoch 11/20\n",
      "184/184 [==============================] - 20s 106ms/step - loss: 0.1182 - accuracy: 0.9538\n",
      "Epoch 12/20\n",
      "184/184 [==============================] - 20s 108ms/step - loss: 0.1985 - accuracy: 0.9359\n",
      "Epoch 13/20\n",
      "184/184 [==============================] - 20s 108ms/step - loss: 0.0629 - accuracy: 0.9794\n",
      "Epoch 14/20\n",
      "184/184 [==============================] - 20s 107ms/step - loss: 0.0378 - accuracy: 0.9893\n",
      "Epoch 15/20\n",
      "184/184 [==============================] - 21s 112ms/step - loss: 0.0293 - accuracy: 0.9916\n",
      "Epoch 16/20\n",
      "184/184 [==============================] - 21s 112ms/step - loss: 0.0502 - accuracy: 0.9840\n",
      "Epoch 17/20\n",
      "184/184 [==============================] - 20s 109ms/step - loss: 0.0285 - accuracy: 0.9918\n",
      "Epoch 18/20\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.0232 - accuracy: 0.9920\n",
      "Epoch 19/20\n",
      "184/184 [==============================] - 19s 104ms/step - loss: 0.0242 - accuracy: 0.9923\n",
      "Epoch 20/20\n",
      "184/184 [==============================] - 20s 110ms/step - loss: 0.0233 - accuracy: 0.9928\n",
      "92/92 [==============================] - 2s 17ms/step\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=20, learning_rate=0.001, num_rnn_layers=1, rnn_units=128; total time= 6.7min\n",
      "Epoch 1/50\n",
      "184/184 [==============================] - 21s 108ms/step - loss: 0.6711 - accuracy: 0.5766\n",
      "Epoch 2/50\n",
      "184/184 [==============================] - 19s 101ms/step - loss: 0.5209 - accuracy: 0.7510\n",
      "Epoch 3/50\n",
      "184/184 [==============================] - 18s 97ms/step - loss: 0.3319 - accuracy: 0.8591\n",
      "Epoch 4/50\n",
      "184/184 [==============================] - 19s 101ms/step - loss: 0.2371 - accuracy: 0.9069\n",
      "Epoch 5/50\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.1712 - accuracy: 0.9357\n",
      "Epoch 6/50\n",
      "184/184 [==============================] - 20s 108ms/step - loss: 0.1169 - accuracy: 0.9570\n",
      "Epoch 7/50\n",
      "184/184 [==============================] - 20s 108ms/step - loss: 0.0805 - accuracy: 0.9722\n",
      "Epoch 8/50\n",
      "184/184 [==============================] - 20s 108ms/step - loss: 0.0635 - accuracy: 0.9792\n",
      "Epoch 9/50\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.0438 - accuracy: 0.9857\n",
      "Epoch 10/50\n",
      "184/184 [==============================] - 18s 100ms/step - loss: 0.0407 - accuracy: 0.9867\n",
      "Epoch 11/50\n",
      "184/184 [==============================] - 19s 101ms/step - loss: 0.0310 - accuracy: 0.9920\n",
      "Epoch 12/50\n",
      "184/184 [==============================] - 19s 104ms/step - loss: 0.0514 - accuracy: 0.9823\n",
      "Epoch 13/50\n",
      "184/184 [==============================] - 19s 104ms/step - loss: 0.0317 - accuracy: 0.9905\n",
      "Epoch 14/50\n",
      "184/184 [==============================] - 19s 103ms/step - loss: 0.0244 - accuracy: 0.9928\n",
      "Epoch 15/50\n",
      "184/184 [==============================] - 18s 99ms/step - loss: 0.0247 - accuracy: 0.9923\n",
      "Epoch 16/50\n",
      "184/184 [==============================] - 18s 98ms/step - loss: 0.0296 - accuracy: 0.9901\n",
      "Epoch 17/50\n",
      "184/184 [==============================] - 18s 98ms/step - loss: 0.0437 - accuracy: 0.9845\n",
      "Epoch 18/50\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.0213 - accuracy: 0.9933\n",
      "Epoch 19/50\n",
      "184/184 [==============================] - 19s 104ms/step - loss: 0.0236 - accuracy: 0.9922\n",
      "Epoch 20/50\n",
      "184/184 [==============================] - 20s 108ms/step - loss: 0.0239 - accuracy: 0.9916\n",
      "Epoch 21/50\n",
      "184/184 [==============================] - 19s 102ms/step - loss: 0.0164 - accuracy: 0.9933\n",
      "Epoch 22/50\n",
      "184/184 [==============================] - 18s 99ms/step - loss: 0.0175 - accuracy: 0.9944\n",
      "Epoch 23/50\n",
      "184/184 [==============================] - 18s 99ms/step - loss: 0.0167 - accuracy: 0.9945\n",
      "Epoch 24/50\n",
      "184/184 [==============================] - 20s 106ms/step - loss: 0.0171 - accuracy: 0.9942\n",
      "Epoch 25/50\n",
      "184/184 [==============================] - 20s 109ms/step - loss: 0.0229 - accuracy: 0.9915\n",
      "Epoch 26/50\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.0158 - accuracy: 0.9944\n",
      "Epoch 27/50\n",
      "184/184 [==============================] - 18s 100ms/step - loss: 0.0155 - accuracy: 0.9945\n",
      "Epoch 28/50\n",
      "184/184 [==============================] - 20s 108ms/step - loss: 0.0155 - accuracy: 0.9940\n",
      "Epoch 29/50\n",
      "184/184 [==============================] - 18s 99ms/step - loss: 0.0181 - accuracy: 0.9933\n",
      "Epoch 30/50\n",
      "184/184 [==============================] - 18s 99ms/step - loss: 0.0173 - accuracy: 0.9933\n",
      "Epoch 31/50\n",
      "184/184 [==============================] - 20s 108ms/step - loss: 0.0229 - accuracy: 0.9908\n",
      "Epoch 32/50\n",
      "184/184 [==============================] - 20s 107ms/step - loss: 0.0240 - accuracy: 0.9908\n",
      "Epoch 33/50\n",
      "184/184 [==============================] - 20s 107ms/step - loss: 0.0217 - accuracy: 0.9923\n",
      "Epoch 34/50\n",
      "184/184 [==============================] - 19s 101ms/step - loss: 0.0167 - accuracy: 0.9933\n",
      "Epoch 35/50\n",
      "184/184 [==============================] - 19s 102ms/step - loss: 0.0156 - accuracy: 0.9945\n",
      "Epoch 36/50\n",
      "184/184 [==============================] - 19s 101ms/step - loss: 0.0133 - accuracy: 0.9947\n",
      "Epoch 37/50\n",
      "184/184 [==============================] - 19s 103ms/step - loss: 0.0146 - accuracy: 0.9944\n",
      "Epoch 38/50\n",
      "184/184 [==============================] - 20s 108ms/step - loss: 0.0124 - accuracy: 0.9945\n",
      "Epoch 39/50\n",
      "184/184 [==============================] - 19s 101ms/step - loss: 0.0121 - accuracy: 0.9954\n",
      "Epoch 40/50\n",
      "184/184 [==============================] - 19s 101ms/step - loss: 0.0123 - accuracy: 0.9945\n",
      "Epoch 41/50\n",
      "184/184 [==============================] - 19s 102ms/step - loss: 0.0131 - accuracy: 0.9947\n",
      "Epoch 42/50\n",
      "184/184 [==============================] - 18s 99ms/step - loss: 0.0149 - accuracy: 0.9937\n",
      "Epoch 43/50\n",
      "184/184 [==============================] - 18s 99ms/step - loss: 0.0174 - accuracy: 0.9923\n",
      "Epoch 44/50\n",
      "184/184 [==============================] - 20s 106ms/step - loss: 0.0124 - accuracy: 0.9945\n",
      "Epoch 45/50\n",
      "184/184 [==============================] - 20s 106ms/step - loss: 0.0128 - accuracy: 0.9949\n",
      "Epoch 46/50\n",
      "184/184 [==============================] - 19s 103ms/step - loss: 0.0124 - accuracy: 0.9947\n",
      "Epoch 47/50\n",
      "184/184 [==============================] - 20s 106ms/step - loss: 0.0094 - accuracy: 0.9962\n",
      "Epoch 48/50\n",
      "184/184 [==============================] - 19s 103ms/step - loss: 0.0115 - accuracy: 0.9947\n",
      "Epoch 49/50\n",
      "184/184 [==============================] - 18s 99ms/step - loss: 0.0119 - accuracy: 0.9947\n",
      "Epoch 50/50\n",
      "184/184 [==============================] - 18s 100ms/step - loss: 0.0104 - accuracy: 0.9957\n",
      "92/92 [==============================] - 2s 16ms/step\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=50, learning_rate=0.001, num_rnn_layers=1, rnn_units=64; total time=15.9min\n",
      "Epoch 1/50\n",
      "184/184 [==============================] - 21s 103ms/step - loss: 0.6737 - accuracy: 0.5741\n",
      "Epoch 2/50\n",
      "184/184 [==============================] - 19s 103ms/step - loss: 0.5078 - accuracy: 0.7587\n",
      "Epoch 3/50\n",
      "184/184 [==============================] - 19s 102ms/step - loss: 0.3508 - accuracy: 0.8525\n",
      "Epoch 4/50\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.2189 - accuracy: 0.9170\n",
      "Epoch 5/50\n",
      "184/184 [==============================] - 18s 100ms/step - loss: 0.1410 - accuracy: 0.9482\n",
      "Epoch 6/50\n",
      "184/184 [==============================] - 20s 107ms/step - loss: 0.0915 - accuracy: 0.9708\n",
      "Epoch 7/50\n",
      "184/184 [==============================] - 20s 108ms/step - loss: 0.1039 - accuracy: 0.9639\n",
      "Epoch 8/50\n",
      "184/184 [==============================] - 20s 110ms/step - loss: 0.0572 - accuracy: 0.9819\n",
      "Epoch 9/50\n",
      "184/184 [==============================] - 18s 98ms/step - loss: 0.0422 - accuracy: 0.9865\n",
      "Epoch 10/50\n",
      "184/184 [==============================] - 20s 109ms/step - loss: 0.0361 - accuracy: 0.9893\n",
      "Epoch 11/50\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.0311 - accuracy: 0.9906\n",
      "Epoch 12/50\n",
      "184/184 [==============================] - 19s 101ms/step - loss: 0.0238 - accuracy: 0.9925\n",
      "Epoch 13/50\n",
      "184/184 [==============================] - 18s 99ms/step - loss: 0.0184 - accuracy: 0.9945\n",
      "Epoch 14/50\n",
      "184/184 [==============================] - 19s 101ms/step - loss: 0.0175 - accuracy: 0.9952\n",
      "Epoch 15/50\n",
      "184/184 [==============================] - 19s 104ms/step - loss: 0.0171 - accuracy: 0.9944\n",
      "Epoch 16/50\n",
      "184/184 [==============================] - 19s 101ms/step - loss: 0.0229 - accuracy: 0.9930\n",
      "Epoch 17/50\n",
      "184/184 [==============================] - 19s 104ms/step - loss: 0.0244 - accuracy: 0.9925\n",
      "Epoch 18/50\n",
      "184/184 [==============================] - 19s 103ms/step - loss: 0.0249 - accuracy: 0.9915\n",
      "Epoch 19/50\n",
      "184/184 [==============================] - 20s 107ms/step - loss: 0.0291 - accuracy: 0.9889\n",
      "Epoch 20/50\n",
      "184/184 [==============================] - 20s 107ms/step - loss: 0.0171 - accuracy: 0.9949\n",
      "Epoch 21/50\n",
      "184/184 [==============================] - 20s 107ms/step - loss: 0.0146 - accuracy: 0.9954\n",
      "Epoch 22/50\n",
      "184/184 [==============================] - 19s 103ms/step - loss: 0.0141 - accuracy: 0.9954\n",
      "Epoch 23/50\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.0138 - accuracy: 0.9956\n",
      "Epoch 24/50\n",
      "184/184 [==============================] - 19s 103ms/step - loss: 0.0205 - accuracy: 0.9932\n",
      "Epoch 25/50\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.0127 - accuracy: 0.9961\n",
      "Epoch 26/50\n",
      "184/184 [==============================] - 19s 104ms/step - loss: 0.0379 - accuracy: 0.9870\n",
      "Epoch 27/50\n",
      "184/184 [==============================] - 19s 106ms/step - loss: 0.0181 - accuracy: 0.9945\n",
      "Epoch 28/50\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.0196 - accuracy: 0.9937\n",
      "Epoch 29/50\n",
      "184/184 [==============================] - 16s 88ms/step - loss: 0.0144 - accuracy: 0.9952\n",
      "Epoch 30/50\n",
      "184/184 [==============================] - 15s 79ms/step - loss: 0.0118 - accuracy: 0.9957\n",
      "Epoch 31/50\n",
      "184/184 [==============================] - 14s 78ms/step - loss: 0.0102 - accuracy: 0.9964\n",
      "Epoch 32/50\n",
      "184/184 [==============================] - 14s 75ms/step - loss: 0.0115 - accuracy: 0.9961\n",
      "Epoch 33/50\n",
      "184/184 [==============================] - 15s 80ms/step - loss: 0.0122 - accuracy: 0.9964\n",
      "Epoch 34/50\n",
      "184/184 [==============================] - 15s 83ms/step - loss: 0.0113 - accuracy: 0.9954\n",
      "Epoch 35/50\n",
      "184/184 [==============================] - 15s 79ms/step - loss: 0.0212 - accuracy: 0.9937\n",
      "Epoch 36/50\n",
      "184/184 [==============================] - 14s 77ms/step - loss: 0.0169 - accuracy: 0.9945\n",
      "Epoch 37/50\n",
      "184/184 [==============================] - 14s 78ms/step - loss: 0.0121 - accuracy: 0.9956\n",
      "Epoch 38/50\n",
      "184/184 [==============================] - 15s 79ms/step - loss: 0.0136 - accuracy: 0.9951\n",
      "Epoch 39/50\n",
      "184/184 [==============================] - 15s 79ms/step - loss: 0.0113 - accuracy: 0.9957\n",
      "Epoch 40/50\n",
      "184/184 [==============================] - 16s 85ms/step - loss: 0.0096 - accuracy: 0.9964\n",
      "Epoch 41/50\n",
      "184/184 [==============================] - 16s 85ms/step - loss: 0.0083 - accuracy: 0.9971\n",
      "Epoch 42/50\n",
      "184/184 [==============================] - 16s 87ms/step - loss: 0.0088 - accuracy: 0.9961\n",
      "Epoch 43/50\n",
      "184/184 [==============================] - 16s 88ms/step - loss: 0.0110 - accuracy: 0.9957\n",
      "Epoch 44/50\n",
      "184/184 [==============================] - 16s 88ms/step - loss: 0.0077 - accuracy: 0.9971\n",
      "Epoch 45/50\n",
      "184/184 [==============================] - 16s 88ms/step - loss: 0.0099 - accuracy: 0.9966\n",
      "Epoch 46/50\n",
      "184/184 [==============================] - 16s 89ms/step - loss: 0.0100 - accuracy: 0.9959\n",
      "Epoch 47/50\n",
      "184/184 [==============================] - 16s 86ms/step - loss: 0.0086 - accuracy: 0.9968\n",
      "Epoch 48/50\n",
      "184/184 [==============================] - 16s 85ms/step - loss: 0.0184 - accuracy: 0.9939\n",
      "Epoch 49/50\n",
      "184/184 [==============================] - 16s 86ms/step - loss: 0.0177 - accuracy: 0.9935\n",
      "Epoch 50/50\n",
      "184/184 [==============================] - 16s 87ms/step - loss: 0.0199 - accuracy: 0.9922\n",
      "92/92 [==============================] - 1s 10ms/step\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=50, learning_rate=0.001, num_rnn_layers=1, rnn_units=64; total time=14.6min\n",
      "Epoch 1/50\n",
      "184/184 [==============================] - 15s 79ms/step - loss: 0.6754 - accuracy: 0.5792\n",
      "Epoch 2/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.5273 - accuracy: 0.7427\n",
      "Epoch 3/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.3302 - accuracy: 0.8597\n",
      "Epoch 4/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.2114 - accuracy: 0.9204\n",
      "Epoch 5/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.1288 - accuracy: 0.9521\n",
      "Epoch 6/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0726 - accuracy: 0.9732\n",
      "Epoch 7/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0458 - accuracy: 0.9852\n",
      "Epoch 8/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0343 - accuracy: 0.9894\n",
      "Epoch 9/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0466 - accuracy: 0.9857\n",
      "Epoch 10/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0284 - accuracy: 0.9918\n",
      "Epoch 11/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0227 - accuracy: 0.9930\n",
      "Epoch 12/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0232 - accuracy: 0.9927\n",
      "Epoch 13/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0181 - accuracy: 0.9945\n",
      "Epoch 14/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0207 - accuracy: 0.9940\n",
      "Epoch 15/50\n",
      "184/184 [==============================] - 9s 52ms/step - loss: 0.0218 - accuracy: 0.9928\n",
      "Epoch 16/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0156 - accuracy: 0.9949\n",
      "Epoch 17/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0155 - accuracy: 0.9949\n",
      "Epoch 18/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0151 - accuracy: 0.9947\n",
      "Epoch 19/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0577 - accuracy: 0.9812\n",
      "Epoch 20/50\n",
      "184/184 [==============================] - 9s 51ms/step - loss: 0.0381 - accuracy: 0.9864\n",
      "Epoch 21/50\n",
      "184/184 [==============================] - 9s 51ms/step - loss: 0.0197 - accuracy: 0.9942\n",
      "Epoch 22/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0109 - accuracy: 0.9969\n",
      "Epoch 23/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0099 - accuracy: 0.9966\n",
      "Epoch 24/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0100 - accuracy: 0.9969\n",
      "Epoch 25/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0099 - accuracy: 0.9969\n",
      "Epoch 26/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0107 - accuracy: 0.9959\n",
      "Epoch 27/50\n",
      "184/184 [==============================] - 11s 58ms/step - loss: 0.0152 - accuracy: 0.9945\n",
      "Epoch 28/50\n",
      "184/184 [==============================] - 12s 63ms/step - loss: 0.0213 - accuracy: 0.9945\n",
      "Epoch 29/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0172 - accuracy: 0.9945\n",
      "Epoch 30/50\n",
      "184/184 [==============================] - 9s 51ms/step - loss: 0.0120 - accuracy: 0.9961\n",
      "Epoch 31/50\n",
      "184/184 [==============================] - 9s 52ms/step - loss: 0.0126 - accuracy: 0.9962\n",
      "Epoch 32/50\n",
      "184/184 [==============================] - 9s 52ms/step - loss: 0.0109 - accuracy: 0.9966\n",
      "Epoch 33/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0094 - accuracy: 0.9968\n",
      "Epoch 34/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0104 - accuracy: 0.9966\n",
      "Epoch 35/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0093 - accuracy: 0.9964\n",
      "Epoch 36/50\n",
      "184/184 [==============================] - 9s 51ms/step - loss: 0.0089 - accuracy: 0.9964\n",
      "Epoch 37/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0223 - accuracy: 0.9918\n",
      "Epoch 38/50\n",
      "184/184 [==============================] - 9s 51ms/step - loss: 0.0147 - accuracy: 0.9957\n",
      "Epoch 39/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0117 - accuracy: 0.9961\n",
      "Epoch 40/50\n",
      "184/184 [==============================] - 9s 51ms/step - loss: 0.0095 - accuracy: 0.9956\n",
      "Epoch 41/50\n",
      "184/184 [==============================] - 9s 51ms/step - loss: 0.0102 - accuracy: 0.9969\n",
      "Epoch 42/50\n",
      "184/184 [==============================] - 9s 52ms/step - loss: 0.0075 - accuracy: 0.9969\n",
      "Epoch 43/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0113 - accuracy: 0.9971\n",
      "Epoch 44/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0098 - accuracy: 0.9968\n",
      "Epoch 45/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0085 - accuracy: 0.9969\n",
      "Epoch 46/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0073 - accuracy: 0.9976\n",
      "Epoch 47/50\n",
      "184/184 [==============================] - 9s 51ms/step - loss: 0.0097 - accuracy: 0.9969\n",
      "Epoch 48/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0075 - accuracy: 0.9968\n",
      "Epoch 49/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0220 - accuracy: 0.9918\n",
      "Epoch 50/50\n",
      "184/184 [==============================] - 9s 51ms/step - loss: 0.0164 - accuracy: 0.9944\n",
      "92/92 [==============================] - 1s 7ms/step\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=50, learning_rate=0.001, num_rnn_layers=1, rnn_units=64; total time= 8.2min\n",
      "Epoch 1/50\n",
      "184/184 [==============================] - 11s 57ms/step - loss: 0.6898 - accuracy: 0.5600\n",
      "Epoch 2/50\n",
      "184/184 [==============================] - 11s 57ms/step - loss: 0.5554 - accuracy: 0.7111\n",
      "Epoch 3/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.3540 - accuracy: 0.8479\n",
      "Epoch 4/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.2651 - accuracy: 0.8939\n",
      "Epoch 5/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.1890 - accuracy: 0.9263\n",
      "Epoch 6/50\n",
      "184/184 [==============================] - 11s 59ms/step - loss: 0.1355 - accuracy: 0.9509\n",
      "Epoch 7/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.1014 - accuracy: 0.9638\n",
      "Epoch 8/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0833 - accuracy: 0.9719\n",
      "Epoch 9/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0680 - accuracy: 0.9777\n",
      "Epoch 10/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0639 - accuracy: 0.9775\n",
      "Epoch 11/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0490 - accuracy: 0.9826\n",
      "Epoch 12/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0476 - accuracy: 0.9840\n",
      "Epoch 13/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0379 - accuracy: 0.9881\n",
      "Epoch 14/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0413 - accuracy: 0.9848\n",
      "Epoch 15/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0352 - accuracy: 0.9894\n",
      "Epoch 16/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0863 - accuracy: 0.9683\n",
      "Epoch 17/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0506 - accuracy: 0.9836\n",
      "Epoch 18/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0336 - accuracy: 0.9901\n",
      "Epoch 19/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0343 - accuracy: 0.9867\n",
      "Epoch 20/50\n",
      "184/184 [==============================] - 9s 51ms/step - loss: 0.0281 - accuracy: 0.9911\n",
      "Epoch 21/50\n",
      "184/184 [==============================] - 9s 51ms/step - loss: 0.0234 - accuracy: 0.9916\n",
      "Epoch 22/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0200 - accuracy: 0.9940\n",
      "Epoch 23/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0235 - accuracy: 0.9928\n",
      "Epoch 24/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0509 - accuracy: 0.9836\n",
      "Epoch 25/50\n",
      "184/184 [==============================] - 9s 51ms/step - loss: 0.0497 - accuracy: 0.9804\n",
      "Epoch 26/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0245 - accuracy: 0.9923\n",
      "Epoch 27/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0262 - accuracy: 0.9906\n",
      "Epoch 28/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0965 - accuracy: 0.9640\n",
      "Epoch 29/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0367 - accuracy: 0.9879\n",
      "Epoch 30/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0323 - accuracy: 0.9903\n",
      "Epoch 31/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0268 - accuracy: 0.9913\n",
      "Epoch 32/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0271 - accuracy: 0.9886\n",
      "Epoch 33/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0234 - accuracy: 0.9928\n",
      "Epoch 34/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0184 - accuracy: 0.9933\n",
      "Epoch 35/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0161 - accuracy: 0.9944\n",
      "Epoch 36/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0177 - accuracy: 0.9947\n",
      "Epoch 37/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0153 - accuracy: 0.9956\n",
      "Epoch 38/50\n",
      "184/184 [==============================] - 9s 51ms/step - loss: 0.0156 - accuracy: 0.9942\n",
      "Epoch 39/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0607 - accuracy: 0.9782\n",
      "Epoch 40/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0214 - accuracy: 0.9928\n",
      "Epoch 41/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0160 - accuracy: 0.9935\n",
      "Epoch 42/50\n",
      "184/184 [==============================] - 9s 52ms/step - loss: 0.0210 - accuracy: 0.9930\n",
      "Epoch 43/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0249 - accuracy: 0.9916\n",
      "Epoch 44/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0270 - accuracy: 0.9911\n",
      "Epoch 45/50\n",
      "184/184 [==============================] - 9s 50ms/step - loss: 0.0192 - accuracy: 0.9932\n",
      "Epoch 46/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0123 - accuracy: 0.9954\n",
      "Epoch 47/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0241 - accuracy: 0.9911\n",
      "Epoch 48/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0190 - accuracy: 0.9927\n",
      "Epoch 49/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0341 - accuracy: 0.9886\n",
      "Epoch 50/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0132 - accuracy: 0.9951\n",
      "92/92 [==============================] - 1s 7ms/step\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=50, learning_rate=0.001, num_rnn_layers=1, rnn_units=128; total time= 8.1min\n",
      "Epoch 1/50\n",
      "184/184 [==============================] - 11s 55ms/step - loss: 0.6859 - accuracy: 0.5628\n",
      "Epoch 2/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.5954 - accuracy: 0.6805\n",
      "Epoch 3/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.3964 - accuracy: 0.8210\n",
      "Epoch 4/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.2707 - accuracy: 0.8931\n",
      "Epoch 5/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.1942 - accuracy: 0.9265\n",
      "Epoch 6/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.1388 - accuracy: 0.9504\n",
      "Epoch 7/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.1070 - accuracy: 0.9608\n",
      "Epoch 8/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0796 - accuracy: 0.9731\n",
      "Epoch 9/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0580 - accuracy: 0.9809\n",
      "Epoch 10/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0397 - accuracy: 0.9879\n",
      "Epoch 11/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0425 - accuracy: 0.9852\n",
      "Epoch 12/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0606 - accuracy: 0.9790\n",
      "Epoch 13/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0504 - accuracy: 0.9824\n",
      "Epoch 14/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0316 - accuracy: 0.9905\n",
      "Epoch 15/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0225 - accuracy: 0.9934\n",
      "Epoch 16/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0212 - accuracy: 0.9922\n",
      "Epoch 17/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0222 - accuracy: 0.9934\n",
      "Epoch 18/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0274 - accuracy: 0.9913\n",
      "Epoch 19/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0305 - accuracy: 0.9893\n",
      "Epoch 20/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0179 - accuracy: 0.9945\n",
      "Epoch 21/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0162 - accuracy: 0.9951\n",
      "Epoch 22/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0151 - accuracy: 0.9944\n",
      "Epoch 23/50\n",
      "184/184 [==============================] - 9s 52ms/step - loss: 0.0468 - accuracy: 0.9840\n",
      "Epoch 24/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0263 - accuracy: 0.9910\n",
      "Epoch 25/50\n",
      "184/184 [==============================] - 9s 52ms/step - loss: 0.0226 - accuracy: 0.9925\n",
      "Epoch 26/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0232 - accuracy: 0.9925\n",
      "Epoch 27/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0394 - accuracy: 0.9847\n",
      "Epoch 28/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0251 - accuracy: 0.9925\n",
      "Epoch 29/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0884 - accuracy: 0.9688\n",
      "Epoch 30/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0238 - accuracy: 0.9922\n",
      "Epoch 31/50\n",
      "184/184 [==============================] - 9s 51ms/step - loss: 0.0173 - accuracy: 0.9934\n",
      "Epoch 32/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0142 - accuracy: 0.9951\n",
      "Epoch 33/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0119 - accuracy: 0.9968\n",
      "Epoch 34/50\n",
      "184/184 [==============================] - 10s 56ms/step - loss: 0.0100 - accuracy: 0.9962\n",
      "Epoch 35/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0124 - accuracy: 0.9961\n",
      "Epoch 36/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0102 - accuracy: 0.9959\n",
      "Epoch 37/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0123 - accuracy: 0.9956\n",
      "Epoch 38/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0162 - accuracy: 0.9939\n",
      "Epoch 39/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0165 - accuracy: 0.9951\n",
      "Epoch 40/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0125 - accuracy: 0.9951\n",
      "Epoch 41/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0147 - accuracy: 0.9947\n",
      "Epoch 42/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0183 - accuracy: 0.9952\n",
      "Epoch 43/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0199 - accuracy: 0.9932\n",
      "Epoch 44/50\n",
      "184/184 [==============================] - 10s 56ms/step - loss: 0.0175 - accuracy: 0.9925\n",
      "Epoch 45/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0207 - accuracy: 0.9928\n",
      "Epoch 46/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0163 - accuracy: 0.9944\n",
      "Epoch 47/50\n",
      "184/184 [==============================] - 10s 56ms/step - loss: 0.0298 - accuracy: 0.9882\n",
      "Epoch 48/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0258 - accuracy: 0.9913\n",
      "Epoch 49/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0153 - accuracy: 0.9956\n",
      "Epoch 50/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0190 - accuracy: 0.9947\n",
      "92/92 [==============================] - 1s 7ms/step\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=50, learning_rate=0.001, num_rnn_layers=1, rnn_units=128; total time= 8.2min\n",
      "Epoch 1/50\n",
      "184/184 [==============================] - 10s 51ms/step - loss: 0.6897 - accuracy: 0.5635\n",
      "Epoch 2/50\n",
      "184/184 [==============================] - 9s 51ms/step - loss: 0.5962 - accuracy: 0.6702\n",
      "Epoch 3/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.3912 - accuracy: 0.8285\n",
      "Epoch 4/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.2704 - accuracy: 0.8919\n",
      "Epoch 5/50\n",
      "184/184 [==============================] - 9s 51ms/step - loss: 0.1963 - accuracy: 0.9245\n",
      "Epoch 6/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.1620 - accuracy: 0.9405\n",
      "Epoch 7/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.1125 - accuracy: 0.9579\n",
      "Epoch 8/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0792 - accuracy: 0.9751\n",
      "Epoch 9/50\n",
      "184/184 [==============================] - 9s 50ms/step - loss: 0.0560 - accuracy: 0.9794\n",
      "Epoch 10/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0506 - accuracy: 0.9819\n",
      "Epoch 11/50\n",
      "184/184 [==============================] - 13s 70ms/step - loss: 0.0315 - accuracy: 0.9910\n",
      "Epoch 12/50\n",
      "184/184 [==============================] - 21s 114ms/step - loss: 0.0239 - accuracy: 0.9922\n",
      "Epoch 13/50\n",
      "184/184 [==============================] - 19s 106ms/step - loss: 0.0295 - accuracy: 0.9903\n",
      "Epoch 14/50\n",
      "184/184 [==============================] - 20s 109ms/step - loss: 0.0313 - accuracy: 0.9906\n",
      "Epoch 15/50\n",
      "184/184 [==============================] - 20s 111ms/step - loss: 0.0453 - accuracy: 0.9850\n",
      "Epoch 16/50\n",
      "184/184 [==============================] - 20s 110ms/step - loss: 0.0291 - accuracy: 0.9903\n",
      "Epoch 17/50\n",
      "184/184 [==============================] - 20s 109ms/step - loss: 0.0211 - accuracy: 0.9939\n",
      "Epoch 18/50\n",
      "184/184 [==============================] - 21s 112ms/step - loss: 0.0148 - accuracy: 0.9942\n",
      "Epoch 19/50\n",
      "184/184 [==============================] - 20s 110ms/step - loss: 0.0263 - accuracy: 0.9922\n",
      "Epoch 20/50\n",
      "184/184 [==============================] - 20s 108ms/step - loss: 0.0424 - accuracy: 0.9860\n",
      "Epoch 21/50\n",
      "184/184 [==============================] - 22s 117ms/step - loss: 0.0323 - accuracy: 0.9884\n",
      "Epoch 22/50\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.0200 - accuracy: 0.9920\n",
      "Epoch 23/50\n",
      "184/184 [==============================] - 20s 107ms/step - loss: 0.0244 - accuracy: 0.9910\n",
      "Epoch 24/50\n",
      "184/184 [==============================] - 20s 108ms/step - loss: 0.0174 - accuracy: 0.9944\n",
      "Epoch 25/50\n",
      "184/184 [==============================] - 19s 103ms/step - loss: 0.0149 - accuracy: 0.9951\n",
      "Epoch 26/50\n",
      "184/184 [==============================] - 20s 110ms/step - loss: 0.0260 - accuracy: 0.9908\n",
      "Epoch 27/50\n",
      "184/184 [==============================] - 20s 110ms/step - loss: 0.0221 - accuracy: 0.9930\n",
      "Epoch 28/50\n",
      "184/184 [==============================] - 21s 115ms/step - loss: 0.0131 - accuracy: 0.9951\n",
      "Epoch 29/50\n",
      "184/184 [==============================] - 21s 116ms/step - loss: 0.0142 - accuracy: 0.9957\n",
      "Epoch 30/50\n",
      "184/184 [==============================] - 22s 118ms/step - loss: 0.0115 - accuracy: 0.9964\n",
      "Epoch 31/50\n",
      "184/184 [==============================] - 22s 121ms/step - loss: 0.0092 - accuracy: 0.9968\n",
      "Epoch 32/50\n",
      "184/184 [==============================] - 20s 109ms/step - loss: 0.0135 - accuracy: 0.9954\n",
      "Epoch 33/50\n",
      "184/184 [==============================] - 19s 104ms/step - loss: 0.0116 - accuracy: 0.9964\n",
      "Epoch 34/50\n",
      "184/184 [==============================] - 21s 113ms/step - loss: 0.0236 - accuracy: 0.9916\n",
      "Epoch 35/50\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.0298 - accuracy: 0.9908\n",
      "Epoch 36/50\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.0168 - accuracy: 0.9954\n",
      "Epoch 37/50\n",
      "184/184 [==============================] - 20s 110ms/step - loss: 0.0142 - accuracy: 0.9947\n",
      "Epoch 38/50\n",
      "184/184 [==============================] - 20s 110ms/step - loss: 0.0127 - accuracy: 0.9966\n",
      "Epoch 39/50\n",
      "184/184 [==============================] - 21s 113ms/step - loss: 0.0100 - accuracy: 0.9962\n",
      "Epoch 40/50\n",
      "184/184 [==============================] - 20s 109ms/step - loss: 0.0084 - accuracy: 0.9971\n",
      "Epoch 41/50\n",
      "184/184 [==============================] - 20s 106ms/step - loss: 0.0111 - accuracy: 0.9966\n",
      "Epoch 42/50\n",
      "184/184 [==============================] - 20s 108ms/step - loss: 0.0100 - accuracy: 0.9966\n",
      "Epoch 43/50\n",
      "184/184 [==============================] - 20s 108ms/step - loss: 0.0085 - accuracy: 0.9969\n",
      "Epoch 44/50\n",
      "184/184 [==============================] - 20s 108ms/step - loss: 0.0096 - accuracy: 0.9961\n",
      "Epoch 45/50\n",
      "184/184 [==============================] - 20s 109ms/step - loss: 0.0085 - accuracy: 0.9976\n",
      "Epoch 46/50\n",
      "184/184 [==============================] - 20s 108ms/step - loss: 0.0090 - accuracy: 0.9966\n",
      "Epoch 47/50\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.0393 - accuracy: 0.9869\n",
      "Epoch 48/50\n",
      "184/184 [==============================] - 19s 101ms/step - loss: 0.0669 - accuracy: 0.9766\n",
      "Epoch 49/50\n",
      "184/184 [==============================] - 19s 104ms/step - loss: 0.0356 - accuracy: 0.9872\n",
      "Epoch 50/50\n",
      "184/184 [==============================] - 20s 111ms/step - loss: 0.0123 - accuracy: 0.9954\n",
      "92/92 [==============================] - 2s 18ms/step\n",
      "[CV] END batch_size=32, dropout_rate=0.2, epochs=50, learning_rate=0.001, num_rnn_layers=1, rnn_units=128; total time=15.0min\n",
      "Epoch 1/20\n",
      "184/184 [==============================] - 21s 109ms/step - loss: 0.6998 - accuracy: 0.5513\n",
      "Epoch 2/20\n",
      "184/184 [==============================] - 20s 111ms/step - loss: 0.5720 - accuracy: 0.7052\n",
      "Epoch 3/20\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.3793 - accuracy: 0.8342\n",
      "Epoch 4/20\n",
      "184/184 [==============================] - 19s 104ms/step - loss: 0.2767 - accuracy: 0.8902\n",
      "Epoch 5/20\n",
      "184/184 [==============================] - 19s 104ms/step - loss: 0.2032 - accuracy: 0.9226\n",
      "Epoch 6/20\n",
      "184/184 [==============================] - 20s 106ms/step - loss: 0.1577 - accuracy: 0.9400\n",
      "Epoch 7/20\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.1189 - accuracy: 0.9606\n",
      "Epoch 8/20\n",
      "184/184 [==============================] - 19s 101ms/step - loss: 0.0864 - accuracy: 0.9695\n",
      "Epoch 9/20\n",
      "184/184 [==============================] - 18s 98ms/step - loss: 0.0643 - accuracy: 0.9802\n",
      "Epoch 10/20\n",
      "184/184 [==============================] - 18s 99ms/step - loss: 0.0496 - accuracy: 0.9850\n",
      "Epoch 11/20\n",
      "184/184 [==============================] - 19s 104ms/step - loss: 0.0482 - accuracy: 0.9840\n",
      "Epoch 12/20\n",
      "184/184 [==============================] - 20s 108ms/step - loss: 0.0427 - accuracy: 0.9865\n",
      "Epoch 13/20\n",
      "184/184 [==============================] - 20s 106ms/step - loss: 0.0376 - accuracy: 0.9874\n",
      "Epoch 14/20\n",
      "184/184 [==============================] - 19s 106ms/step - loss: 0.0783 - accuracy: 0.9734\n",
      "Epoch 15/20\n",
      "184/184 [==============================] - 20s 108ms/step - loss: 0.0374 - accuracy: 0.9877\n",
      "Epoch 16/20\n",
      "184/184 [==============================] - 20s 107ms/step - loss: 0.0254 - accuracy: 0.9922\n",
      "Epoch 17/20\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.0270 - accuracy: 0.9916\n",
      "Epoch 18/20\n",
      "184/184 [==============================] - 19s 103ms/step - loss: 0.0227 - accuracy: 0.9927\n",
      "Epoch 19/20\n",
      "184/184 [==============================] - 19s 102ms/step - loss: 0.0257 - accuracy: 0.9922\n",
      "Epoch 20/20\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.0305 - accuracy: 0.9899\n",
      "92/92 [==============================] - 2s 17ms/step\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=20, learning_rate=0.001, num_rnn_layers=1, rnn_units=64; total time= 6.5min\n",
      "Epoch 1/20\n",
      "184/184 [==============================] - 21s 105ms/step - loss: 0.6940 - accuracy: 0.5659\n",
      "Epoch 2/20\n",
      "184/184 [==============================] - 18s 99ms/step - loss: 0.6122 - accuracy: 0.6752\n",
      "Epoch 3/20\n",
      "184/184 [==============================] - 18s 99ms/step - loss: 0.4137 - accuracy: 0.8257\n",
      "Epoch 4/20\n",
      "184/184 [==============================] - 19s 104ms/step - loss: 0.2695 - accuracy: 0.8895\n",
      "Epoch 5/20\n",
      "184/184 [==============================] - 20s 107ms/step - loss: 0.1686 - accuracy: 0.9415\n",
      "Epoch 6/20\n",
      "184/184 [==============================] - 20s 107ms/step - loss: 0.1042 - accuracy: 0.9674\n",
      "Epoch 7/20\n",
      "184/184 [==============================] - 20s 109ms/step - loss: 0.0740 - accuracy: 0.9756\n",
      "Epoch 8/20\n",
      "184/184 [==============================] - 19s 102ms/step - loss: 0.0480 - accuracy: 0.9874\n",
      "Epoch 9/20\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.0429 - accuracy: 0.9879\n",
      "Epoch 10/20\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.0537 - accuracy: 0.9811\n",
      "Epoch 11/20\n",
      "184/184 [==============================] - 18s 99ms/step - loss: 0.0368 - accuracy: 0.9893\n",
      "Epoch 12/20\n",
      "184/184 [==============================] - 20s 107ms/step - loss: 0.0511 - accuracy: 0.9824\n",
      "Epoch 13/20\n",
      "184/184 [==============================] - 19s 102ms/step - loss: 0.0304 - accuracy: 0.9913\n",
      "Epoch 14/20\n",
      "184/184 [==============================] - 18s 100ms/step - loss: 0.0226 - accuracy: 0.9945\n",
      "Epoch 15/20\n",
      "184/184 [==============================] - 18s 96ms/step - loss: 0.0464 - accuracy: 0.9853\n",
      "Epoch 16/20\n",
      "184/184 [==============================] - 18s 98ms/step - loss: 0.0236 - accuracy: 0.9935\n",
      "Epoch 17/20\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.0178 - accuracy: 0.9952\n",
      "Epoch 18/20\n",
      "184/184 [==============================] - 20s 108ms/step - loss: 0.0183 - accuracy: 0.9949\n",
      "Epoch 19/20\n",
      "184/184 [==============================] - 20s 107ms/step - loss: 0.0177 - accuracy: 0.9945\n",
      "Epoch 20/20\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.0177 - accuracy: 0.9945\n",
      "92/92 [==============================] - 2s 18ms/step\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=20, learning_rate=0.001, num_rnn_layers=1, rnn_units=64; total time= 6.4min\n",
      "Epoch 1/20\n",
      "184/184 [==============================] - 22s 112ms/step - loss: 0.6893 - accuracy: 0.5708\n",
      "Epoch 2/20\n",
      "184/184 [==============================] - 21s 112ms/step - loss: 0.5109 - accuracy: 0.7581\n",
      "Epoch 3/20\n",
      "184/184 [==============================] - 21s 113ms/step - loss: 0.3455 - accuracy: 0.8566\n",
      "Epoch 4/20\n",
      "184/184 [==============================] - 20s 110ms/step - loss: 0.2484 - accuracy: 0.9006\n",
      "Epoch 5/20\n",
      "184/184 [==============================] - 20s 107ms/step - loss: 0.1959 - accuracy: 0.9250\n",
      "Epoch 6/20\n",
      "184/184 [==============================] - 20s 110ms/step - loss: 0.1371 - accuracy: 0.9509\n",
      "Epoch 7/20\n",
      "184/184 [==============================] - 20s 109ms/step - loss: 0.0990 - accuracy: 0.9693\n",
      "Epoch 8/20\n",
      "184/184 [==============================] - 20s 107ms/step - loss: 0.0788 - accuracy: 0.9736\n",
      "Epoch 9/20\n",
      "184/184 [==============================] - 20s 111ms/step - loss: 0.0610 - accuracy: 0.9795\n",
      "Epoch 10/20\n",
      "184/184 [==============================] - 21s 112ms/step - loss: 0.0504 - accuracy: 0.9812\n",
      "Epoch 11/20\n",
      "184/184 [==============================] - 20s 111ms/step - loss: 0.0382 - accuracy: 0.9894\n",
      "Epoch 12/20\n",
      "184/184 [==============================] - 20s 107ms/step - loss: 0.0294 - accuracy: 0.9911\n",
      "Epoch 13/20\n",
      "184/184 [==============================] - 20s 106ms/step - loss: 0.0249 - accuracy: 0.9923\n",
      "Epoch 14/20\n",
      "184/184 [==============================] - 20s 109ms/step - loss: 0.0239 - accuracy: 0.9930\n",
      "Epoch 15/20\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.0231 - accuracy: 0.9925\n",
      "Epoch 16/20\n",
      "184/184 [==============================] - 20s 111ms/step - loss: 0.0191 - accuracy: 0.9935\n",
      "Epoch 17/20\n",
      "184/184 [==============================] - 20s 109ms/step - loss: 0.0158 - accuracy: 0.9947\n",
      "Epoch 18/20\n",
      "184/184 [==============================] - 20s 108ms/step - loss: 0.0358 - accuracy: 0.9898\n",
      "Epoch 19/20\n",
      "184/184 [==============================] - 20s 108ms/step - loss: 0.0349 - accuracy: 0.9889\n",
      "Epoch 20/20\n",
      "184/184 [==============================] - 20s 109ms/step - loss: 0.0296 - accuracy: 0.9894\n",
      "92/92 [==============================] - 2s 17ms/step\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=20, learning_rate=0.001, num_rnn_layers=1, rnn_units=64; total time= 6.8min\n",
      "Epoch 1/20\n",
      "184/184 [==============================] - 21s 108ms/step - loss: 0.7071 - accuracy: 0.5452\n",
      "Epoch 2/20\n",
      "184/184 [==============================] - 20s 107ms/step - loss: 0.6394 - accuracy: 0.6385\n",
      "Epoch 3/20\n",
      "184/184 [==============================] - 19s 104ms/step - loss: 0.4521 - accuracy: 0.7943\n",
      "Epoch 4/20\n",
      "184/184 [==============================] - 19s 101ms/step - loss: 0.3251 - accuracy: 0.8678\n",
      "Epoch 5/20\n",
      "184/184 [==============================] - 19s 103ms/step - loss: 0.2465 - accuracy: 0.9035\n",
      "Epoch 6/20\n",
      "184/184 [==============================] - 19s 102ms/step - loss: 0.1999 - accuracy: 0.9229\n",
      "Epoch 7/20\n",
      "184/184 [==============================] - 19s 103ms/step - loss: 0.1517 - accuracy: 0.9463\n",
      "Epoch 8/20\n",
      "184/184 [==============================] - 21s 115ms/step - loss: 0.1287 - accuracy: 0.9504\n",
      "Epoch 9/20\n",
      "184/184 [==============================] - 19s 103ms/step - loss: 0.0988 - accuracy: 0.9642\n",
      "Epoch 10/20\n",
      "184/184 [==============================] - 18s 99ms/step - loss: 0.0750 - accuracy: 0.9736\n",
      "Epoch 11/20\n",
      "184/184 [==============================] - 18s 99ms/step - loss: 0.1188 - accuracy: 0.9589\n",
      "Epoch 12/20\n",
      "184/184 [==============================] - 19s 101ms/step - loss: 0.0547 - accuracy: 0.9845\n",
      "Epoch 13/20\n",
      "184/184 [==============================] - 19s 104ms/step - loss: 0.0469 - accuracy: 0.9850\n",
      "Epoch 14/20\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.0419 - accuracy: 0.9877\n",
      "Epoch 15/20\n",
      "184/184 [==============================] - 20s 107ms/step - loss: 0.0375 - accuracy: 0.9884\n",
      "Epoch 16/20\n",
      "184/184 [==============================] - 19s 106ms/step - loss: 0.0386 - accuracy: 0.9884\n",
      "Epoch 17/20\n",
      "184/184 [==============================] - 18s 99ms/step - loss: 0.0296 - accuracy: 0.9913\n",
      "Epoch 18/20\n",
      "184/184 [==============================] - 18s 100ms/step - loss: 0.0308 - accuracy: 0.9906\n",
      "Epoch 19/20\n",
      "184/184 [==============================] - 19s 104ms/step - loss: 0.0253 - accuracy: 0.9923\n",
      "Epoch 20/20\n",
      "184/184 [==============================] - 19s 103ms/step - loss: 0.0714 - accuracy: 0.9754\n",
      "92/92 [==============================] - 2s 18ms/step\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=20, learning_rate=0.001, num_rnn_layers=1, rnn_units=128; total time= 6.4min\n",
      "Epoch 1/20\n",
      "184/184 [==============================] - 22s 111ms/step - loss: 0.7021 - accuracy: 0.5517\n",
      "Epoch 2/20\n",
      "184/184 [==============================] - 21s 114ms/step - loss: 0.5749 - accuracy: 0.6914\n",
      "Epoch 3/20\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.3886 - accuracy: 0.8324\n",
      "Epoch 4/20\n",
      "184/184 [==============================] - 20s 111ms/step - loss: 0.2773 - accuracy: 0.8864\n",
      "Epoch 5/20\n",
      "184/184 [==============================] - 20s 109ms/step - loss: 0.2195 - accuracy: 0.9134\n",
      "Epoch 6/20\n",
      "184/184 [==============================] - 20s 111ms/step - loss: 0.1731 - accuracy: 0.9403\n",
      "Epoch 7/20\n",
      "184/184 [==============================] - 20s 109ms/step - loss: 0.1565 - accuracy: 0.9437\n",
      "Epoch 8/20\n",
      "184/184 [==============================] - 19s 104ms/step - loss: 0.1186 - accuracy: 0.9572\n",
      "Epoch 9/20\n",
      "184/184 [==============================] - 19s 103ms/step - loss: 0.0953 - accuracy: 0.9678\n",
      "Epoch 10/20\n",
      "184/184 [==============================] - 20s 108ms/step - loss: 0.0857 - accuracy: 0.9700\n",
      "Epoch 11/20\n",
      "184/184 [==============================] - 21s 111ms/step - loss: 0.0584 - accuracy: 0.9807\n",
      "Epoch 12/20\n",
      "184/184 [==============================] - 21s 116ms/step - loss: 0.0545 - accuracy: 0.9812\n",
      "Epoch 13/20\n",
      "184/184 [==============================] - 21s 116ms/step - loss: 0.0805 - accuracy: 0.9707\n",
      "Epoch 14/20\n",
      "184/184 [==============================] - 22s 120ms/step - loss: 0.0545 - accuracy: 0.9802\n",
      "Epoch 15/20\n",
      "184/184 [==============================] - 22s 119ms/step - loss: 0.0434 - accuracy: 0.9857\n",
      "Epoch 16/20\n",
      "184/184 [==============================] - 21s 114ms/step - loss: 0.0331 - accuracy: 0.9893\n",
      "Epoch 17/20\n",
      "184/184 [==============================] - 21s 116ms/step - loss: 0.0288 - accuracy: 0.9905\n",
      "Epoch 18/20\n",
      "184/184 [==============================] - 21s 116ms/step - loss: 0.0334 - accuracy: 0.9882\n",
      "Epoch 19/20\n",
      "184/184 [==============================] - 22s 120ms/step - loss: 0.1321 - accuracy: 0.9487\n",
      "Epoch 20/20\n",
      "184/184 [==============================] - 21s 115ms/step - loss: 0.0916 - accuracy: 0.9686\n",
      "92/92 [==============================] - 2s 15ms/step\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=20, learning_rate=0.001, num_rnn_layers=1, rnn_units=128; total time= 6.9min\n",
      "Epoch 1/20\n",
      "184/184 [==============================] - 22s 115ms/step - loss: 0.7088 - accuracy: 0.5487\n",
      "Epoch 2/20\n",
      "184/184 [==============================] - 22s 121ms/step - loss: 0.6637 - accuracy: 0.5957\n",
      "Epoch 3/20\n",
      "184/184 [==============================] - 22s 122ms/step - loss: 0.4932 - accuracy: 0.7666\n",
      "Epoch 4/20\n",
      "184/184 [==============================] - 20s 109ms/step - loss: 0.3371 - accuracy: 0.8568\n",
      "Epoch 5/20\n",
      "184/184 [==============================] - 19s 104ms/step - loss: 0.2444 - accuracy: 0.9026\n",
      "Epoch 6/20\n",
      "184/184 [==============================] - 20s 111ms/step - loss: 0.1717 - accuracy: 0.9374\n",
      "Epoch 7/20\n",
      "184/184 [==============================] - 22s 117ms/step - loss: 0.1256 - accuracy: 0.9524\n",
      "Epoch 8/20\n",
      "184/184 [==============================] - 21s 117ms/step - loss: 0.0881 - accuracy: 0.9700\n",
      "Epoch 9/20\n",
      "184/184 [==============================] - 22s 117ms/step - loss: 0.0596 - accuracy: 0.9807\n",
      "Epoch 10/20\n",
      "184/184 [==============================] - 22s 118ms/step - loss: 0.0821 - accuracy: 0.9683\n",
      "Epoch 11/20\n",
      "184/184 [==============================] - 21s 116ms/step - loss: 0.0530 - accuracy: 0.9816\n",
      "Epoch 12/20\n",
      "184/184 [==============================] - 22s 117ms/step - loss: 0.0412 - accuracy: 0.9850\n",
      "Epoch 13/20\n",
      "184/184 [==============================] - 21s 116ms/step - loss: 0.0307 - accuracy: 0.9913\n",
      "Epoch 14/20\n",
      "184/184 [==============================] - 22s 121ms/step - loss: 0.0270 - accuracy: 0.9913\n",
      "Epoch 15/20\n",
      "184/184 [==============================] - 19s 104ms/step - loss: 0.0231 - accuracy: 0.9927\n",
      "Epoch 16/20\n",
      "184/184 [==============================] - 16s 88ms/step - loss: 0.0246 - accuracy: 0.9923\n",
      "Epoch 17/20\n",
      "184/184 [==============================] - 15s 84ms/step - loss: 0.0362 - accuracy: 0.9899\n",
      "Epoch 18/20\n",
      "184/184 [==============================] - 16s 88ms/step - loss: 0.0283 - accuracy: 0.9910\n",
      "Epoch 19/20\n",
      "184/184 [==============================] - 17s 90ms/step - loss: 0.0355 - accuracy: 0.9882\n",
      "Epoch 20/20\n",
      "184/184 [==============================] - 16s 88ms/step - loss: 0.0231 - accuracy: 0.9928\n",
      "92/92 [==============================] - 1s 10ms/step\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=20, learning_rate=0.001, num_rnn_layers=1, rnn_units=128; total time= 6.7min\n",
      "Epoch 1/50\n",
      "184/184 [==============================] - 17s 86ms/step - loss: 0.6928 - accuracy: 0.5663\n",
      "Epoch 2/50\n",
      "184/184 [==============================] - 16s 84ms/step - loss: 0.5659 - accuracy: 0.7133\n",
      "Epoch 3/50\n",
      "184/184 [==============================] - 16s 84ms/step - loss: 0.3774 - accuracy: 0.8324\n",
      "Epoch 4/50\n",
      "184/184 [==============================] - 16s 89ms/step - loss: 0.2681 - accuracy: 0.8927\n",
      "Epoch 5/50\n",
      "184/184 [==============================] - 18s 97ms/step - loss: 0.1977 - accuracy: 0.9274\n",
      "Epoch 6/50\n",
      "184/184 [==============================] - 17s 92ms/step - loss: 0.1557 - accuracy: 0.9395\n",
      "Epoch 7/50\n",
      "184/184 [==============================] - 17s 90ms/step - loss: 0.1079 - accuracy: 0.9630\n",
      "Epoch 8/50\n",
      "184/184 [==============================] - 16s 87ms/step - loss: 0.0793 - accuracy: 0.9739\n",
      "Epoch 9/50\n",
      "184/184 [==============================] - 16s 84ms/step - loss: 0.0649 - accuracy: 0.9778\n",
      "Epoch 10/50\n",
      "184/184 [==============================] - 17s 90ms/step - loss: 0.0717 - accuracy: 0.9744\n",
      "Epoch 11/50\n",
      "184/184 [==============================] - 16s 86ms/step - loss: 0.0526 - accuracy: 0.9843\n",
      "Epoch 12/50\n",
      "184/184 [==============================] - 16s 89ms/step - loss: 0.0441 - accuracy: 0.9870\n",
      "Epoch 13/50\n",
      "184/184 [==============================] - 17s 92ms/step - loss: 0.0449 - accuracy: 0.9869\n",
      "Epoch 14/50\n",
      "184/184 [==============================] - 14s 76ms/step - loss: 0.0370 - accuracy: 0.9893\n",
      "Epoch 15/50\n",
      "184/184 [==============================] - 9s 51ms/step - loss: 0.0277 - accuracy: 0.9920\n",
      "Epoch 16/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0262 - accuracy: 0.9922\n",
      "Epoch 17/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0466 - accuracy: 0.9831\n",
      "Epoch 18/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0302 - accuracy: 0.9915\n",
      "Epoch 19/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0313 - accuracy: 0.9908\n",
      "Epoch 20/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0253 - accuracy: 0.9920\n",
      "Epoch 21/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0240 - accuracy: 0.9922\n",
      "Epoch 22/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0205 - accuracy: 0.9935\n",
      "Epoch 23/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0171 - accuracy: 0.9932\n",
      "Epoch 24/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0192 - accuracy: 0.9940\n",
      "Epoch 25/50\n",
      "184/184 [==============================] - 9s 51ms/step - loss: 0.0225 - accuracy: 0.9940\n",
      "Epoch 26/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0312 - accuracy: 0.9911\n",
      "Epoch 27/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0201 - accuracy: 0.9927\n",
      "Epoch 28/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0253 - accuracy: 0.9920\n",
      "Epoch 29/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0277 - accuracy: 0.9899\n",
      "Epoch 30/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0189 - accuracy: 0.9942\n",
      "Epoch 31/50\n",
      "184/184 [==============================] - 10s 56ms/step - loss: 0.0157 - accuracy: 0.9949\n",
      "Epoch 32/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0218 - accuracy: 0.9930\n",
      "Epoch 33/50\n",
      "184/184 [==============================] - 10s 56ms/step - loss: 0.0225 - accuracy: 0.9932\n",
      "Epoch 34/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0229 - accuracy: 0.9906\n",
      "Epoch 35/50\n",
      "184/184 [==============================] - 10s 57ms/step - loss: 0.0402 - accuracy: 0.9848\n",
      "Epoch 36/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0222 - accuracy: 0.9930\n",
      "Epoch 37/50\n",
      "184/184 [==============================] - 10s 56ms/step - loss: 0.0175 - accuracy: 0.9930\n",
      "Epoch 38/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0170 - accuracy: 0.9945\n",
      "Epoch 39/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0142 - accuracy: 0.9951\n",
      "Epoch 40/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0156 - accuracy: 0.9949\n",
      "Epoch 41/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0136 - accuracy: 0.9956\n",
      "Epoch 42/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0132 - accuracy: 0.9952\n",
      "Epoch 43/50\n",
      "184/184 [==============================] - 10s 56ms/step - loss: 0.0296 - accuracy: 0.9920\n",
      "Epoch 44/50\n",
      "184/184 [==============================] - 10s 56ms/step - loss: 0.0634 - accuracy: 0.9790\n",
      "Epoch 45/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0300 - accuracy: 0.9905\n",
      "Epoch 46/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0181 - accuracy: 0.9932\n",
      "Epoch 47/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0142 - accuracy: 0.9954\n",
      "Epoch 48/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0152 - accuracy: 0.9945\n",
      "Epoch 49/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0150 - accuracy: 0.9944\n",
      "Epoch 50/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0127 - accuracy: 0.9956\n",
      "92/92 [==============================] - 1s 7ms/step\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=50, learning_rate=0.001, num_rnn_layers=1, rnn_units=64; total time= 9.8min\n",
      "Epoch 1/50\n",
      "184/184 [==============================] - 11s 55ms/step - loss: 0.6877 - accuracy: 0.5710\n",
      "Epoch 2/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.5385 - accuracy: 0.7367\n",
      "Epoch 3/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.3550 - accuracy: 0.8540\n",
      "Epoch 4/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.2495 - accuracy: 0.9049\n",
      "Epoch 5/50\n",
      "184/184 [==============================] - 9s 51ms/step - loss: 0.1865 - accuracy: 0.9328\n",
      "Epoch 6/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.1286 - accuracy: 0.9557\n",
      "Epoch 7/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0915 - accuracy: 0.9674\n",
      "Epoch 8/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0655 - accuracy: 0.9804\n",
      "Epoch 9/50\n",
      "184/184 [==============================] - 11s 62ms/step - loss: 0.0540 - accuracy: 0.9816\n",
      "Epoch 10/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0425 - accuracy: 0.9869\n",
      "Epoch 11/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0385 - accuracy: 0.9876\n",
      "Epoch 12/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0381 - accuracy: 0.9877\n",
      "Epoch 13/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0322 - accuracy: 0.9898\n",
      "Epoch 14/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0405 - accuracy: 0.9870\n",
      "Epoch 15/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0321 - accuracy: 0.9891\n",
      "Epoch 16/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0226 - accuracy: 0.9925\n",
      "Epoch 17/50\n",
      "184/184 [==============================] - 10s 56ms/step - loss: 0.0210 - accuracy: 0.9934\n",
      "Epoch 18/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0234 - accuracy: 0.9923\n",
      "Epoch 19/50\n",
      "184/184 [==============================] - 11s 61ms/step - loss: 0.0185 - accuracy: 0.9939\n",
      "Epoch 20/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0197 - accuracy: 0.9942\n",
      "Epoch 21/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0155 - accuracy: 0.9947\n",
      "Epoch 22/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0166 - accuracy: 0.9947\n",
      "Epoch 23/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0148 - accuracy: 0.9964\n",
      "Epoch 24/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0127 - accuracy: 0.9957\n",
      "Epoch 25/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0148 - accuracy: 0.9944\n",
      "Epoch 26/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0296 - accuracy: 0.9915\n",
      "Epoch 27/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0340 - accuracy: 0.9887\n",
      "Epoch 28/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0213 - accuracy: 0.9942\n",
      "Epoch 29/50\n",
      "184/184 [==============================] - 10s 56ms/step - loss: 0.0151 - accuracy: 0.9961\n",
      "Epoch 30/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0110 - accuracy: 0.9968\n",
      "Epoch 31/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0150 - accuracy: 0.9959\n",
      "Epoch 32/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0128 - accuracy: 0.9961\n",
      "Epoch 33/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0108 - accuracy: 0.9968\n",
      "Epoch 34/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0130 - accuracy: 0.9961\n",
      "Epoch 35/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0168 - accuracy: 0.9945\n",
      "Epoch 36/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0578 - accuracy: 0.9809\n",
      "Epoch 37/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0283 - accuracy: 0.9908\n",
      "Epoch 38/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0149 - accuracy: 0.9956\n",
      "Epoch 39/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0115 - accuracy: 0.9966\n",
      "Epoch 40/50\n",
      "184/184 [==============================] - 9s 51ms/step - loss: 0.0117 - accuracy: 0.9969\n",
      "Epoch 41/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0126 - accuracy: 0.9956\n",
      "Epoch 42/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0082 - accuracy: 0.9974\n",
      "Epoch 43/50\n",
      "184/184 [==============================] - 9s 52ms/step - loss: 0.0141 - accuracy: 0.9961\n",
      "Epoch 44/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0129 - accuracy: 0.9959\n",
      "Epoch 45/50\n",
      "184/184 [==============================] - 10s 56ms/step - loss: 0.0105 - accuracy: 0.9968\n",
      "Epoch 46/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0141 - accuracy: 0.9959\n",
      "Epoch 47/50\n",
      "184/184 [==============================] - 10s 56ms/step - loss: 0.0100 - accuracy: 0.9966\n",
      "Epoch 48/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0111 - accuracy: 0.9971\n",
      "Epoch 49/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0088 - accuracy: 0.9964\n",
      "Epoch 50/50\n",
      "184/184 [==============================] - 9s 51ms/step - loss: 0.0090 - accuracy: 0.9964\n",
      "92/92 [==============================] - 1s 7ms/step\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=50, learning_rate=0.001, num_rnn_layers=1, rnn_units=64; total time= 8.3min\n",
      "Epoch 1/50\n",
      "184/184 [==============================] - 13s 69ms/step - loss: 0.6991 - accuracy: 0.5553\n",
      "Epoch 2/50\n",
      "184/184 [==============================] - 21s 115ms/step - loss: 0.5421 - accuracy: 0.7332\n",
      "Epoch 3/50\n",
      "184/184 [==============================] - 22s 120ms/step - loss: 0.3955 - accuracy: 0.8336\n",
      "Epoch 4/50\n",
      "184/184 [==============================] - 22s 119ms/step - loss: 0.2752 - accuracy: 0.8895\n",
      "Epoch 5/50\n",
      "184/184 [==============================] - 21s 114ms/step - loss: 0.2117 - accuracy: 0.9219\n",
      "Epoch 6/50\n",
      "184/184 [==============================] - 22s 117ms/step - loss: 0.1519 - accuracy: 0.9451\n",
      "Epoch 7/50\n",
      "184/184 [==============================] - 22s 121ms/step - loss: 0.1409 - accuracy: 0.9495\n",
      "Epoch 8/50\n",
      "184/184 [==============================] - 21s 116ms/step - loss: 0.0789 - accuracy: 0.9736\n",
      "Epoch 9/50\n",
      "184/184 [==============================] - 21s 115ms/step - loss: 0.0550 - accuracy: 0.9816\n",
      "Epoch 10/50\n",
      "184/184 [==============================] - 21s 116ms/step - loss: 0.0469 - accuracy: 0.9855\n",
      "Epoch 11/50\n",
      "184/184 [==============================] - 22s 119ms/step - loss: 0.0520 - accuracy: 0.9852\n",
      "Epoch 12/50\n",
      "184/184 [==============================] - 22s 121ms/step - loss: 0.0415 - accuracy: 0.9860\n",
      "Epoch 13/50\n",
      "184/184 [==============================] - 22s 119ms/step - loss: 0.0279 - accuracy: 0.9901\n",
      "Epoch 14/50\n",
      "184/184 [==============================] - 21s 117ms/step - loss: 0.0225 - accuracy: 0.9940\n",
      "Epoch 15/50\n",
      "184/184 [==============================] - 22s 119ms/step - loss: 0.0195 - accuracy: 0.9939\n",
      "Epoch 16/50\n",
      "184/184 [==============================] - 23s 125ms/step - loss: 0.0339 - accuracy: 0.9893\n",
      "Epoch 17/50\n",
      "184/184 [==============================] - 22s 117ms/step - loss: 0.0212 - accuracy: 0.9942\n",
      "Epoch 18/50\n",
      "184/184 [==============================] - 21s 117ms/step - loss: 0.0165 - accuracy: 0.9949\n",
      "Epoch 19/50\n",
      "184/184 [==============================] - 22s 119ms/step - loss: 0.0229 - accuracy: 0.9944\n",
      "Epoch 20/50\n",
      "184/184 [==============================] - 22s 118ms/step - loss: 0.0937 - accuracy: 0.9668\n",
      "Epoch 21/50\n",
      "184/184 [==============================] - 32s 176ms/step - loss: 0.0367 - accuracy: 0.9896\n",
      "Epoch 22/50\n",
      "184/184 [==============================] - 32s 172ms/step - loss: 0.0217 - accuracy: 0.9939\n",
      "Epoch 23/50\n",
      "184/184 [==============================] - 31s 169ms/step - loss: 0.0157 - accuracy: 0.9961\n",
      "Epoch 24/50\n",
      "184/184 [==============================] - 33s 178ms/step - loss: 0.0128 - accuracy: 0.9969\n",
      "Epoch 25/50\n",
      "184/184 [==============================] - 31s 168ms/step - loss: 0.0135 - accuracy: 0.9959\n",
      "Epoch 26/50\n",
      "184/184 [==============================] - 27s 148ms/step - loss: 0.0139 - accuracy: 0.9968\n",
      "Epoch 27/50\n",
      "184/184 [==============================] - 33s 181ms/step - loss: 0.0123 - accuracy: 0.9962\n",
      "Epoch 28/50\n",
      "184/184 [==============================] - 32s 174ms/step - loss: 0.0381 - accuracy: 0.9882\n",
      "Epoch 29/50\n",
      "184/184 [==============================] - 31s 168ms/step - loss: 0.0354 - accuracy: 0.9884\n",
      "Epoch 30/50\n",
      "184/184 [==============================] - 32s 174ms/step - loss: 0.0170 - accuracy: 0.9944\n",
      "Epoch 31/50\n",
      "184/184 [==============================] - 32s 176ms/step - loss: 0.0139 - accuracy: 0.9956\n",
      "Epoch 32/50\n",
      "184/184 [==============================] - 31s 170ms/step - loss: 0.0163 - accuracy: 0.9954\n",
      "Epoch 33/50\n",
      "184/184 [==============================] - 30s 166ms/step - loss: 0.0111 - accuracy: 0.9971\n",
      "Epoch 34/50\n",
      "184/184 [==============================] - 31s 170ms/step - loss: 0.0226 - accuracy: 0.9932\n",
      "Epoch 35/50\n",
      "184/184 [==============================] - 33s 179ms/step - loss: 0.0170 - accuracy: 0.9942\n",
      "Epoch 36/50\n",
      "184/184 [==============================] - 27s 148ms/step - loss: 0.0138 - accuracy: 0.9951\n",
      "Epoch 37/50\n",
      "184/184 [==============================] - 22s 120ms/step - loss: 0.0119 - accuracy: 0.9961\n",
      "Epoch 38/50\n",
      "184/184 [==============================] - 22s 118ms/step - loss: 0.0084 - accuracy: 0.9976\n",
      "Epoch 39/50\n",
      "184/184 [==============================] - 22s 120ms/step - loss: 0.0114 - accuracy: 0.9964\n",
      "Epoch 40/50\n",
      "184/184 [==============================] - 21s 116ms/step - loss: 0.0138 - accuracy: 0.9966\n",
      "Epoch 41/50\n",
      "184/184 [==============================] - 22s 118ms/step - loss: 0.0117 - accuracy: 0.9962\n",
      "Epoch 42/50\n",
      "184/184 [==============================] - 22s 118ms/step - loss: 0.0114 - accuracy: 0.9959\n",
      "Epoch 43/50\n",
      "184/184 [==============================] - 22s 120ms/step - loss: 0.0134 - accuracy: 0.9959\n",
      "Epoch 44/50\n",
      "184/184 [==============================] - 22s 119ms/step - loss: 0.0135 - accuracy: 0.9954\n",
      "Epoch 45/50\n",
      "184/184 [==============================] - 22s 117ms/step - loss: 0.0128 - accuracy: 0.9961\n",
      "Epoch 46/50\n",
      "184/184 [==============================] - 22s 119ms/step - loss: 0.0105 - accuracy: 0.9968\n",
      "Epoch 47/50\n",
      "184/184 [==============================] - 21s 116ms/step - loss: 0.0136 - accuracy: 0.9966\n",
      "Epoch 48/50\n",
      "184/184 [==============================] - 23s 123ms/step - loss: 0.0165 - accuracy: 0.9951\n",
      "Epoch 49/50\n",
      "184/184 [==============================] - 22s 120ms/step - loss: 0.0104 - accuracy: 0.9969\n",
      "Epoch 50/50\n",
      "184/184 [==============================] - 21s 115ms/step - loss: 0.0114 - accuracy: 0.9968\n",
      "92/92 [==============================] - 2s 17ms/step\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=50, learning_rate=0.001, num_rnn_layers=1, rnn_units=64; total time=20.6min\n",
      "Epoch 1/50\n",
      "184/184 [==============================] - 22s 113ms/step - loss: 0.7031 - accuracy: 0.5597\n",
      "Epoch 2/50\n",
      "184/184 [==============================] - 21s 114ms/step - loss: 0.6465 - accuracy: 0.6269\n",
      "Epoch 3/50\n",
      "184/184 [==============================] - 18s 99ms/step - loss: 0.4436 - accuracy: 0.7933\n",
      "Epoch 4/50\n",
      "184/184 [==============================] - 20s 109ms/step - loss: 0.3192 - accuracy: 0.8701\n",
      "Epoch 5/50\n",
      "184/184 [==============================] - 20s 107ms/step - loss: 0.2491 - accuracy: 0.9011\n",
      "Epoch 6/50\n",
      "184/184 [==============================] - 20s 107ms/step - loss: 0.1959 - accuracy: 0.9253\n",
      "Epoch 7/50\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.1664 - accuracy: 0.9384\n",
      "Epoch 8/50\n",
      "184/184 [==============================] - 19s 104ms/step - loss: 0.1285 - accuracy: 0.9524\n",
      "Epoch 9/50\n",
      "184/184 [==============================] - 19s 101ms/step - loss: 0.0890 - accuracy: 0.9698\n",
      "Epoch 10/50\n",
      "184/184 [==============================] - 20s 107ms/step - loss: 0.0741 - accuracy: 0.9763\n",
      "Epoch 11/50\n",
      "184/184 [==============================] - 22s 121ms/step - loss: 0.0592 - accuracy: 0.9795\n",
      "Epoch 12/50\n",
      "184/184 [==============================] - 20s 110ms/step - loss: 0.0469 - accuracy: 0.9840\n",
      "Epoch 13/50\n",
      "184/184 [==============================] - 21s 113ms/step - loss: 0.0689 - accuracy: 0.9756\n",
      "Epoch 14/50\n",
      "184/184 [==============================] - 21s 116ms/step - loss: 0.0423 - accuracy: 0.9850\n",
      "Epoch 15/50\n",
      "184/184 [==============================] - 20s 111ms/step - loss: 0.0317 - accuracy: 0.9896\n",
      "Epoch 16/50\n",
      "184/184 [==============================] - 21s 112ms/step - loss: 0.0411 - accuracy: 0.9855\n",
      "Epoch 17/50\n",
      "184/184 [==============================] - 20s 111ms/step - loss: 0.0380 - accuracy: 0.9850\n",
      "Epoch 18/50\n",
      "184/184 [==============================] - 21s 112ms/step - loss: 0.0255 - accuracy: 0.9913\n",
      "Epoch 19/50\n",
      "184/184 [==============================] - 22s 117ms/step - loss: 0.0272 - accuracy: 0.9911\n",
      "Epoch 20/50\n",
      "184/184 [==============================] - 20s 111ms/step - loss: 0.0317 - accuracy: 0.9903\n",
      "Epoch 21/50\n",
      "184/184 [==============================] - 20s 111ms/step - loss: 0.0413 - accuracy: 0.9869\n",
      "Epoch 22/50\n",
      "184/184 [==============================] - 21s 113ms/step - loss: 0.0536 - accuracy: 0.9823\n",
      "Epoch 23/50\n",
      "184/184 [==============================] - 21s 117ms/step - loss: 0.0226 - accuracy: 0.9927\n",
      "Epoch 24/50\n",
      "184/184 [==============================] - 21s 116ms/step - loss: 0.0249 - accuracy: 0.9918\n",
      "Epoch 25/50\n",
      "184/184 [==============================] - 20s 111ms/step - loss: 0.0252 - accuracy: 0.9927\n",
      "Epoch 26/50\n",
      "184/184 [==============================] - 20s 111ms/step - loss: 0.0207 - accuracy: 0.9940\n",
      "Epoch 27/50\n",
      "184/184 [==============================] - 21s 114ms/step - loss: 0.0208 - accuracy: 0.9932\n",
      "Epoch 28/50\n",
      "184/184 [==============================] - 22s 119ms/step - loss: 0.0182 - accuracy: 0.9933\n",
      "Epoch 29/50\n",
      "184/184 [==============================] - 20s 111ms/step - loss: 0.0278 - accuracy: 0.9896\n",
      "Epoch 30/50\n",
      "184/184 [==============================] - 20s 110ms/step - loss: 0.0295 - accuracy: 0.9905\n",
      "Epoch 31/50\n",
      "184/184 [==============================] - 21s 114ms/step - loss: 0.0286 - accuracy: 0.9903\n",
      "Epoch 32/50\n",
      "184/184 [==============================] - 21s 114ms/step - loss: 0.0203 - accuracy: 0.9925\n",
      "Epoch 33/50\n",
      "184/184 [==============================] - 22s 117ms/step - loss: 0.0172 - accuracy: 0.9937\n",
      "Epoch 34/50\n",
      "184/184 [==============================] - 20s 111ms/step - loss: 0.0291 - accuracy: 0.9896\n",
      "Epoch 35/50\n",
      "184/184 [==============================] - 20s 109ms/step - loss: 0.0230 - accuracy: 0.9925\n",
      "Epoch 36/50\n",
      "184/184 [==============================] - 19s 106ms/step - loss: 0.0452 - accuracy: 0.9853\n",
      "Epoch 37/50\n",
      "184/184 [==============================] - 17s 91ms/step - loss: 0.0282 - accuracy: 0.9913\n",
      "Epoch 38/50\n",
      "184/184 [==============================] - 16s 87ms/step - loss: 0.0192 - accuracy: 0.9933\n",
      "Epoch 39/50\n",
      "184/184 [==============================] - 15s 82ms/step - loss: 0.0204 - accuracy: 0.9933\n",
      "Epoch 40/50\n",
      "184/184 [==============================] - 15s 80ms/step - loss: 0.0145 - accuracy: 0.9949\n",
      "Epoch 41/50\n",
      "184/184 [==============================] - 15s 81ms/step - loss: 0.0185 - accuracy: 0.9933\n",
      "Epoch 42/50\n",
      "184/184 [==============================] - 14s 78ms/step - loss: 0.0204 - accuracy: 0.9940\n",
      "Epoch 43/50\n",
      "184/184 [==============================] - 15s 80ms/step - loss: 0.0179 - accuracy: 0.9935\n",
      "Epoch 44/50\n",
      "184/184 [==============================] - 15s 82ms/step - loss: 0.0160 - accuracy: 0.9949\n",
      "Epoch 45/50\n",
      "184/184 [==============================] - 15s 81ms/step - loss: 0.0213 - accuracy: 0.9932\n",
      "Epoch 46/50\n",
      "184/184 [==============================] - 15s 83ms/step - loss: 0.0182 - accuracy: 0.9930\n",
      "Epoch 47/50\n",
      "184/184 [==============================] - 15s 82ms/step - loss: 0.0284 - accuracy: 0.9915\n",
      "Epoch 48/50\n",
      "184/184 [==============================] - 14s 77ms/step - loss: 0.0191 - accuracy: 0.9940\n",
      "Epoch 49/50\n",
      "184/184 [==============================] - 14s 77ms/step - loss: 0.0271 - accuracy: 0.9918\n",
      "Epoch 50/50\n",
      "184/184 [==============================] - 15s 80ms/step - loss: 0.0206 - accuracy: 0.9932\n",
      "92/92 [==============================] - 1s 10ms/step\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=50, learning_rate=0.001, num_rnn_layers=1, rnn_units=128; total time=15.8min\n",
      "Epoch 1/50\n",
      "184/184 [==============================] - 17s 86ms/step - loss: 0.7018 - accuracy: 0.5526\n",
      "Epoch 2/50\n",
      "184/184 [==============================] - 16s 86ms/step - loss: 0.6326 - accuracy: 0.6423\n",
      "Epoch 3/50\n",
      "184/184 [==============================] - 15s 81ms/step - loss: 0.4465 - accuracy: 0.7944\n",
      "Epoch 4/50\n",
      "184/184 [==============================] - 15s 81ms/step - loss: 0.3270 - accuracy: 0.8655\n",
      "Epoch 5/50\n",
      "184/184 [==============================] - 15s 79ms/step - loss: 0.2435 - accuracy: 0.9049\n",
      "Epoch 6/50\n",
      "184/184 [==============================] - 15s 83ms/step - loss: 0.2175 - accuracy: 0.9158\n",
      "Epoch 7/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.1573 - accuracy: 0.9424\n",
      "Epoch 8/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.1206 - accuracy: 0.9591\n",
      "Epoch 9/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0932 - accuracy: 0.9676\n",
      "Epoch 10/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0725 - accuracy: 0.9734\n",
      "Epoch 11/50\n",
      "184/184 [==============================] - 11s 61ms/step - loss: 0.0583 - accuracy: 0.9790\n",
      "Epoch 12/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0559 - accuracy: 0.9824\n",
      "Epoch 13/50\n",
      "184/184 [==============================] - 10s 57ms/step - loss: 0.0424 - accuracy: 0.9845\n",
      "Epoch 14/50\n",
      "184/184 [==============================] - 10s 56ms/step - loss: 0.0492 - accuracy: 0.9836\n",
      "Epoch 15/50\n",
      "184/184 [==============================] - 10s 57ms/step - loss: 0.0369 - accuracy: 0.9876\n",
      "Epoch 16/50\n",
      "184/184 [==============================] - 10s 56ms/step - loss: 0.0309 - accuracy: 0.9893\n",
      "Epoch 17/50\n",
      "184/184 [==============================] - 10s 56ms/step - loss: 0.0328 - accuracy: 0.9882\n",
      "Epoch 18/50\n",
      "184/184 [==============================] - 10s 56ms/step - loss: 0.0422 - accuracy: 0.9852\n",
      "Epoch 19/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0289 - accuracy: 0.9918\n",
      "Epoch 20/50\n",
      "184/184 [==============================] - 10s 56ms/step - loss: 0.0437 - accuracy: 0.9838\n",
      "Epoch 21/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0261 - accuracy: 0.9915\n",
      "Epoch 22/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0412 - accuracy: 0.9869\n",
      "Epoch 23/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0229 - accuracy: 0.9911\n",
      "Epoch 24/50\n",
      "184/184 [==============================] - 11s 59ms/step - loss: 0.0205 - accuracy: 0.9944\n",
      "Epoch 25/50\n",
      "184/184 [==============================] - 10s 57ms/step - loss: 0.0162 - accuracy: 0.9947\n",
      "Epoch 26/50\n",
      "184/184 [==============================] - 11s 57ms/step - loss: 0.0150 - accuracy: 0.9951\n",
      "Epoch 27/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0335 - accuracy: 0.9876\n",
      "Epoch 28/50\n",
      "184/184 [==============================] - 10s 52ms/step - loss: 0.0254 - accuracy: 0.9928\n",
      "Epoch 29/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0176 - accuracy: 0.9956\n",
      "Epoch 30/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0224 - accuracy: 0.9932\n",
      "Epoch 31/50\n",
      "184/184 [==============================] - 10s 56ms/step - loss: 0.0291 - accuracy: 0.9908\n",
      "Epoch 32/50\n",
      "184/184 [==============================] - 10s 57ms/step - loss: 0.0184 - accuracy: 0.9944\n",
      "Epoch 33/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0196 - accuracy: 0.9930\n",
      "Epoch 34/50\n",
      "184/184 [==============================] - 10s 57ms/step - loss: 0.0146 - accuracy: 0.9952\n",
      "Epoch 35/50\n",
      "184/184 [==============================] - 10s 57ms/step - loss: 0.0161 - accuracy: 0.9945\n",
      "Epoch 36/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0138 - accuracy: 0.9957\n",
      "Epoch 37/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0215 - accuracy: 0.9932\n",
      "Epoch 38/50\n",
      "184/184 [==============================] - 11s 59ms/step - loss: 0.0465 - accuracy: 0.9847\n",
      "Epoch 39/50\n",
      "184/184 [==============================] - 10s 57ms/step - loss: 0.0328 - accuracy: 0.9889\n",
      "Epoch 40/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0247 - accuracy: 0.9913\n",
      "Epoch 41/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0156 - accuracy: 0.9945\n",
      "Epoch 42/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0142 - accuracy: 0.9961\n",
      "Epoch 43/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0091 - accuracy: 0.9973\n",
      "Epoch 44/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0116 - accuracy: 0.9959\n",
      "Epoch 45/50\n",
      "184/184 [==============================] - 20s 107ms/step - loss: 0.0141 - accuracy: 0.9951\n",
      "Epoch 46/50\n",
      "184/184 [==============================] - 22s 120ms/step - loss: 0.0104 - accuracy: 0.9961\n",
      "Epoch 47/50\n",
      "184/184 [==============================] - 22s 118ms/step - loss: 0.0124 - accuracy: 0.9962\n",
      "Epoch 48/50\n",
      "184/184 [==============================] - 21s 114ms/step - loss: 0.0096 - accuracy: 0.9961\n",
      "Epoch 49/50\n",
      "184/184 [==============================] - 21s 112ms/step - loss: 0.0336 - accuracy: 0.9898\n",
      "Epoch 50/50\n",
      "184/184 [==============================] - 21s 114ms/step - loss: 0.0153 - accuracy: 0.9930\n",
      "92/92 [==============================] - 2s 17ms/step\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=50, learning_rate=0.001, num_rnn_layers=1, rnn_units=128; total time=10.1min\n",
      "Epoch 1/50\n",
      "184/184 [==============================] - 23s 118ms/step - loss: 0.7059 - accuracy: 0.5444\n",
      "Epoch 2/50\n",
      "184/184 [==============================] - 21s 114ms/step - loss: 0.6625 - accuracy: 0.6055\n",
      "Epoch 3/50\n",
      "184/184 [==============================] - 21s 115ms/step - loss: 0.4736 - accuracy: 0.7809\n",
      "Epoch 4/50\n",
      "184/184 [==============================] - 22s 119ms/step - loss: 0.3310 - accuracy: 0.8604\n",
      "Epoch 5/50\n",
      "184/184 [==============================] - 22s 118ms/step - loss: 0.2320 - accuracy: 0.9062\n",
      "Epoch 6/50\n",
      "184/184 [==============================] - 21s 116ms/step - loss: 0.1676 - accuracy: 0.9355\n",
      "Epoch 7/50\n",
      "184/184 [==============================] - 20s 108ms/step - loss: 0.1234 - accuracy: 0.9545\n",
      "Epoch 8/50\n",
      "184/184 [==============================] - 19s 105ms/step - loss: 0.1081 - accuracy: 0.9599\n",
      "Epoch 9/50\n",
      "184/184 [==============================] - 20s 109ms/step - loss: 0.0877 - accuracy: 0.9697\n",
      "Epoch 10/50\n",
      "184/184 [==============================] - 21s 114ms/step - loss: 0.0564 - accuracy: 0.9797\n",
      "Epoch 11/50\n",
      "184/184 [==============================] - 20s 111ms/step - loss: 0.0489 - accuracy: 0.9850\n",
      "Epoch 12/50\n",
      "184/184 [==============================] - 21s 113ms/step - loss: 0.0393 - accuracy: 0.9882\n",
      "Epoch 13/50\n",
      "184/184 [==============================] - 21s 113ms/step - loss: 0.0309 - accuracy: 0.9899\n",
      "Epoch 14/50\n",
      "184/184 [==============================] - 13s 73ms/step - loss: 0.0489 - accuracy: 0.9838\n",
      "Epoch 15/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0414 - accuracy: 0.9867\n",
      "Epoch 16/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0281 - accuracy: 0.9922\n",
      "Epoch 17/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0283 - accuracy: 0.9918\n",
      "Epoch 18/50\n",
      "184/184 [==============================] - 10s 57ms/step - loss: 0.0344 - accuracy: 0.9877\n",
      "Epoch 19/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0300 - accuracy: 0.9891\n",
      "Epoch 20/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0202 - accuracy: 0.9939\n",
      "Epoch 21/50\n",
      "184/184 [==============================] - 10s 56ms/step - loss: 0.0186 - accuracy: 0.9949\n",
      "Epoch 22/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0302 - accuracy: 0.9913\n",
      "Epoch 23/50\n",
      "184/184 [==============================] - 10s 56ms/step - loss: 0.0175 - accuracy: 0.9951\n",
      "Epoch 24/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0153 - accuracy: 0.9956\n",
      "Epoch 25/50\n",
      "184/184 [==============================] - 11s 57ms/step - loss: 0.0407 - accuracy: 0.9877\n",
      "Epoch 26/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.1157 - accuracy: 0.9604\n",
      "Epoch 27/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0326 - accuracy: 0.9891\n",
      "Epoch 28/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0879 - accuracy: 0.9693\n",
      "Epoch 29/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0260 - accuracy: 0.9920\n",
      "Epoch 30/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0160 - accuracy: 0.9949\n",
      "Epoch 31/50\n",
      "184/184 [==============================] - 11s 57ms/step - loss: 0.0140 - accuracy: 0.9951\n",
      "Epoch 32/50\n",
      "184/184 [==============================] - 12s 67ms/step - loss: 0.0160 - accuracy: 0.9947\n",
      "Epoch 33/50\n",
      "184/184 [==============================] - 11s 59ms/step - loss: 0.0121 - accuracy: 0.9962\n",
      "Epoch 34/50\n",
      "184/184 [==============================] - 10s 56ms/step - loss: 0.0312 - accuracy: 0.9911\n",
      "Epoch 35/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0209 - accuracy: 0.9935\n",
      "Epoch 36/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0138 - accuracy: 0.9954\n",
      "Epoch 37/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0158 - accuracy: 0.9951\n",
      "Epoch 38/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0187 - accuracy: 0.9939\n",
      "Epoch 39/50\n",
      "184/184 [==============================] - 10s 56ms/step - loss: 0.0134 - accuracy: 0.9954\n",
      "Epoch 40/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0116 - accuracy: 0.9957\n",
      "Epoch 41/50\n",
      "184/184 [==============================] - 10s 57ms/step - loss: 0.0122 - accuracy: 0.9957\n",
      "Epoch 42/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0127 - accuracy: 0.9961\n",
      "Epoch 43/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0094 - accuracy: 0.9969\n",
      "Epoch 44/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0123 - accuracy: 0.9956\n",
      "Epoch 45/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0114 - accuracy: 0.9966\n",
      "Epoch 46/50\n",
      "184/184 [==============================] - 11s 57ms/step - loss: 0.0151 - accuracy: 0.9952\n",
      "Epoch 47/50\n",
      "184/184 [==============================] - 10s 55ms/step - loss: 0.0574 - accuracy: 0.9792\n",
      "Epoch 48/50\n",
      "184/184 [==============================] - 10s 56ms/step - loss: 0.0331 - accuracy: 0.9876\n",
      "Epoch 49/50\n",
      "184/184 [==============================] - 10s 53ms/step - loss: 0.0226 - accuracy: 0.9927\n",
      "Epoch 50/50\n",
      "184/184 [==============================] - 10s 54ms/step - loss: 0.0155 - accuracy: 0.9940\n",
      "92/92 [==============================] - 1s 7ms/step\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=50, learning_rate=0.001, num_rnn_layers=1, rnn_units=128; total time=10.9min\n",
      "Epoch 1/20\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.6805 - accuracy: 0.5689\n",
      "Epoch 2/20\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.5778 - accuracy: 0.7149\n",
      "Epoch 3/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.3808 - accuracy: 0.8395\n",
      "Epoch 4/20\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.2983 - accuracy: 0.8796\n",
      "Epoch 5/20\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.2166 - accuracy: 0.9180\n",
      "Epoch 6/20\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.1642 - accuracy: 0.9393\n",
      "Epoch 7/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.1366 - accuracy: 0.9511\n",
      "Epoch 8/20\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.1084 - accuracy: 0.9633\n",
      "Epoch 9/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0819 - accuracy: 0.9742\n",
      "Epoch 10/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0656 - accuracy: 0.9795\n",
      "Epoch 11/20\n",
      "92/92 [==============================] - 5s 58ms/step - loss: 0.0531 - accuracy: 0.9829\n",
      "Epoch 12/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0472 - accuracy: 0.9864\n",
      "Epoch 13/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0537 - accuracy: 0.9823\n",
      "Epoch 14/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0431 - accuracy: 0.9852\n",
      "Epoch 15/20\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0363 - accuracy: 0.9884\n",
      "Epoch 16/20\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.0377 - accuracy: 0.9879\n",
      "Epoch 17/20\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0338 - accuracy: 0.9884\n",
      "Epoch 18/20\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0372 - accuracy: 0.9893\n",
      "Epoch 19/20\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.0250 - accuracy: 0.9925\n",
      "Epoch 20/20\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0235 - accuracy: 0.9918\n",
      "92/92 [==============================] - 1s 8ms/step\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=20, learning_rate=0.001, num_rnn_layers=1, rnn_units=64; total time= 1.7min\n",
      "Epoch 1/20\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.6762 - accuracy: 0.5659\n",
      "Epoch 2/20\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.5929 - accuracy: 0.6885\n",
      "Epoch 3/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.4012 - accuracy: 0.8346\n",
      "Epoch 4/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.2627 - accuracy: 0.8968\n",
      "Epoch 5/20\n",
      "92/92 [==============================] - 5s 51ms/step - loss: 0.1816 - accuracy: 0.9361\n",
      "Epoch 6/20\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.1197 - accuracy: 0.9601\n",
      "Epoch 7/20\n",
      "92/92 [==============================] - 5s 51ms/step - loss: 0.0858 - accuracy: 0.9729\n",
      "Epoch 8/20\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.0653 - accuracy: 0.9785\n",
      "Epoch 9/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0489 - accuracy: 0.9860\n",
      "Epoch 10/20\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.0383 - accuracy: 0.9894\n",
      "Epoch 11/20\n",
      "92/92 [==============================] - 5s 51ms/step - loss: 0.0396 - accuracy: 0.9879\n",
      "Epoch 12/20\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0331 - accuracy: 0.9894\n",
      "Epoch 13/20\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0255 - accuracy: 0.9934\n",
      "Epoch 14/20\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0250 - accuracy: 0.9934\n",
      "Epoch 15/20\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0205 - accuracy: 0.9937\n",
      "Epoch 16/20\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.0177 - accuracy: 0.9940\n",
      "Epoch 17/20\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0197 - accuracy: 0.9944\n",
      "Epoch 18/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0197 - accuracy: 0.9945\n",
      "Epoch 19/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0159 - accuracy: 0.9954\n",
      "Epoch 20/20\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.0161 - accuracy: 0.9952\n",
      "92/92 [==============================] - 1s 7ms/step\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=20, learning_rate=0.001, num_rnn_layers=1, rnn_units=64; total time= 1.6min\n",
      "Epoch 1/20\n",
      "92/92 [==============================] - 6s 54ms/step - loss: 0.6777 - accuracy: 0.5642\n",
      "Epoch 2/20\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.5933 - accuracy: 0.6899\n",
      "Epoch 3/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.3999 - accuracy: 0.8251\n",
      "Epoch 4/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.2713 - accuracy: 0.8931\n",
      "Epoch 5/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.2029 - accuracy: 0.9221\n",
      "Epoch 6/20\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.1452 - accuracy: 0.9495\n",
      "Epoch 7/20\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0974 - accuracy: 0.9661\n",
      "Epoch 8/20\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0676 - accuracy: 0.9794\n",
      "Epoch 9/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0479 - accuracy: 0.9874\n",
      "Epoch 10/20\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0529 - accuracy: 0.9850\n",
      "Epoch 11/20\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0423 - accuracy: 0.9889\n",
      "Epoch 12/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0301 - accuracy: 0.9932\n",
      "Epoch 13/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0229 - accuracy: 0.9945\n",
      "Epoch 14/20\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0183 - accuracy: 0.9951\n",
      "Epoch 15/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0208 - accuracy: 0.9945\n",
      "Epoch 16/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0188 - accuracy: 0.9954\n",
      "Epoch 17/20\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0175 - accuracy: 0.9956\n",
      "Epoch 18/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0161 - accuracy: 0.9952\n",
      "Epoch 19/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0133 - accuracy: 0.9957\n",
      "Epoch 20/20\n",
      "92/92 [==============================] - 5s 59ms/step - loss: 0.0147 - accuracy: 0.9949\n",
      "92/92 [==============================] - 1s 7ms/step\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=20, learning_rate=0.001, num_rnn_layers=1, rnn_units=64; total time= 1.7min\n",
      "Epoch 1/20\n",
      "92/92 [==============================] - 6s 57ms/step - loss: 0.6846 - accuracy: 0.5672\n",
      "Epoch 2/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.6322 - accuracy: 0.6448\n",
      "Epoch 3/20\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.4521 - accuracy: 0.7935\n",
      "Epoch 4/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.3534 - accuracy: 0.8453\n",
      "Epoch 5/20\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.2496 - accuracy: 0.8989\n",
      "Epoch 6/20\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.1859 - accuracy: 0.9301\n",
      "Epoch 7/20\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.1494 - accuracy: 0.9473\n",
      "Epoch 8/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.1149 - accuracy: 0.9572\n",
      "Epoch 9/20\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0988 - accuracy: 0.9635\n",
      "Epoch 10/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0840 - accuracy: 0.9696\n",
      "Epoch 11/20\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0863 - accuracy: 0.9696\n",
      "Epoch 12/20\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0718 - accuracy: 0.9741\n",
      "Epoch 13/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0602 - accuracy: 0.9783\n",
      "Epoch 14/20\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0527 - accuracy: 0.9821\n",
      "Epoch 15/20\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0436 - accuracy: 0.9847\n",
      "Epoch 16/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0397 - accuracy: 0.9870\n",
      "Epoch 17/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0479 - accuracy: 0.9840\n",
      "Epoch 18/20\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0384 - accuracy: 0.9872\n",
      "Epoch 19/20\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0357 - accuracy: 0.9893\n",
      "Epoch 20/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0311 - accuracy: 0.9898\n",
      "92/92 [==============================] - 1s 7ms/step\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=20, learning_rate=0.001, num_rnn_layers=1, rnn_units=128; total time= 1.7min\n",
      "Epoch 1/20\n",
      "92/92 [==============================] - 6s 54ms/step - loss: 0.6831 - accuracy: 0.5698\n",
      "Epoch 2/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.5791 - accuracy: 0.7088\n",
      "Epoch 3/20\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.3939 - accuracy: 0.8334\n",
      "Epoch 4/20\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.2806 - accuracy: 0.8863\n",
      "Epoch 5/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.2088 - accuracy: 0.9197\n",
      "Epoch 6/20\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.1710 - accuracy: 0.9376\n",
      "Epoch 7/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.1390 - accuracy: 0.9461\n",
      "Epoch 8/20\n",
      "92/92 [==============================] - 6s 60ms/step - loss: 0.1131 - accuracy: 0.9582\n",
      "Epoch 9/20\n",
      "92/92 [==============================] - 6s 61ms/step - loss: 0.0928 - accuracy: 0.9676\n",
      "Epoch 10/20\n",
      "92/92 [==============================] - 6s 61ms/step - loss: 0.0724 - accuracy: 0.9746\n",
      "Epoch 11/20\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0607 - accuracy: 0.9792\n",
      "Epoch 12/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0508 - accuracy: 0.9840\n",
      "Epoch 13/20\n",
      "92/92 [==============================] - 5s 58ms/step - loss: 0.0376 - accuracy: 0.9884\n",
      "Epoch 14/20\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.0360 - accuracy: 0.9877\n",
      "Epoch 15/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0451 - accuracy: 0.9847\n",
      "Epoch 16/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0316 - accuracy: 0.9894\n",
      "Epoch 17/20\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0478 - accuracy: 0.9840\n",
      "Epoch 18/20\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0305 - accuracy: 0.9899\n",
      "Epoch 19/20\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0442 - accuracy: 0.9855\n",
      "Epoch 20/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0270 - accuracy: 0.9911\n",
      "92/92 [==============================] - 1s 7ms/step\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=20, learning_rate=0.001, num_rnn_layers=1, rnn_units=128; total time= 1.7min\n",
      "Epoch 1/20\n",
      "92/92 [==============================] - 6s 56ms/step - loss: 0.6890 - accuracy: 0.5591\n",
      "Epoch 2/20\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.6446 - accuracy: 0.6295\n",
      "Epoch 3/20\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.4673 - accuracy: 0.7835\n",
      "Epoch 4/20\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.3119 - accuracy: 0.8696\n",
      "Epoch 5/20\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.2216 - accuracy: 0.9132\n",
      "Epoch 6/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.1649 - accuracy: 0.9386\n",
      "Epoch 7/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.1392 - accuracy: 0.9473\n",
      "Epoch 8/20\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.1188 - accuracy: 0.9574\n",
      "Epoch 9/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0851 - accuracy: 0.9710\n",
      "Epoch 10/20\n",
      "92/92 [==============================] - 5s 59ms/step - loss: 0.0577 - accuracy: 0.9811\n",
      "Epoch 11/20\n",
      "92/92 [==============================] - 5s 58ms/step - loss: 0.0599 - accuracy: 0.9799\n",
      "Epoch 12/20\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0497 - accuracy: 0.9848\n",
      "Epoch 13/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0427 - accuracy: 0.9876\n",
      "Epoch 14/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0506 - accuracy: 0.9847\n",
      "Epoch 15/20\n",
      "92/92 [==============================] - 5s 58ms/step - loss: 0.0310 - accuracy: 0.9898\n",
      "Epoch 16/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0437 - accuracy: 0.9879\n",
      "Epoch 17/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0239 - accuracy: 0.9925\n",
      "Epoch 18/20\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0263 - accuracy: 0.9923\n",
      "Epoch 19/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0239 - accuracy: 0.9928\n",
      "Epoch 20/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0180 - accuracy: 0.9944\n",
      "92/92 [==============================] - 1s 8ms/step\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=20, learning_rate=0.001, num_rnn_layers=1, rnn_units=128; total time= 1.7min\n",
      "Epoch 1/50\n",
      "92/92 [==============================] - 6s 54ms/step - loss: 0.6730 - accuracy: 0.5790\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.5683 - accuracy: 0.7103\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.3935 - accuracy: 0.8290\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.2699 - accuracy: 0.8915\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.2074 - accuracy: 0.9209\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.1461 - accuracy: 0.9471\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.1180 - accuracy: 0.9592\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0930 - accuracy: 0.9708\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0763 - accuracy: 0.9754\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0580 - accuracy: 0.9816\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0483 - accuracy: 0.9852\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0440 - accuracy: 0.9858\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.0333 - accuracy: 0.9905\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0298 - accuracy: 0.9916\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0299 - accuracy: 0.9905\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0280 - accuracy: 0.9913\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0222 - accuracy: 0.9933\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0255 - accuracy: 0.9916\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - 5s 51ms/step - loss: 0.0328 - accuracy: 0.9893\n",
      "Epoch 20/50\n",
      "92/92 [==============================] - 5s 51ms/step - loss: 0.0243 - accuracy: 0.9930\n",
      "Epoch 21/50\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.0222 - accuracy: 0.9913\n",
      "Epoch 22/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0229 - accuracy: 0.9933\n",
      "Epoch 23/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0172 - accuracy: 0.9937\n",
      "Epoch 24/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0184 - accuracy: 0.9944\n",
      "Epoch 25/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0173 - accuracy: 0.9945\n",
      "Epoch 26/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0158 - accuracy: 0.9947\n",
      "Epoch 27/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0183 - accuracy: 0.9933\n",
      "Epoch 28/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0159 - accuracy: 0.9942\n",
      "Epoch 29/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0197 - accuracy: 0.9928\n",
      "Epoch 30/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0235 - accuracy: 0.9923\n",
      "Epoch 31/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0206 - accuracy: 0.9925\n",
      "Epoch 32/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0148 - accuracy: 0.9942\n",
      "Epoch 33/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0154 - accuracy: 0.9947\n",
      "Epoch 34/50\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.0125 - accuracy: 0.9959\n",
      "Epoch 35/50\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.0121 - accuracy: 0.9959\n",
      "Epoch 36/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0164 - accuracy: 0.9930\n",
      "Epoch 37/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0192 - accuracy: 0.9930\n",
      "Epoch 38/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0155 - accuracy: 0.9945\n",
      "Epoch 39/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0149 - accuracy: 0.9947\n",
      "Epoch 40/50\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.0131 - accuracy: 0.9945\n",
      "Epoch 41/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0137 - accuracy: 0.9951\n",
      "Epoch 42/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0161 - accuracy: 0.9940\n",
      "Epoch 43/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0207 - accuracy: 0.9935\n",
      "Epoch 44/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0234 - accuracy: 0.9923\n",
      "Epoch 45/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0127 - accuracy: 0.9956\n",
      "Epoch 46/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0112 - accuracy: 0.9962\n",
      "Epoch 47/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0128 - accuracy: 0.9951\n",
      "Epoch 48/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0113 - accuracy: 0.9962\n",
      "Epoch 49/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0130 - accuracy: 0.9952\n",
      "Epoch 50/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0120 - accuracy: 0.9949\n",
      "92/92 [==============================] - 1s 7ms/step\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=50, learning_rate=0.001, num_rnn_layers=1, rnn_units=64; total time= 4.1min\n",
      "Epoch 1/50\n",
      "92/92 [==============================] - 6s 58ms/step - loss: 0.6760 - accuracy: 0.5715\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.6039 - accuracy: 0.6760\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.4124 - accuracy: 0.8222\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.2796 - accuracy: 0.8885\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.2003 - accuracy: 0.9287\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.1393 - accuracy: 0.9536\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - 5s 58ms/step - loss: 0.1143 - accuracy: 0.9630\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.1007 - accuracy: 0.9673\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0730 - accuracy: 0.9756\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0598 - accuracy: 0.9814\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0382 - accuracy: 0.9899\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0346 - accuracy: 0.9881\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0304 - accuracy: 0.9905\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0232 - accuracy: 0.9934\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - 5s 58ms/step - loss: 0.0205 - accuracy: 0.9939\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0211 - accuracy: 0.9940\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0337 - accuracy: 0.9894\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0415 - accuracy: 0.9862\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0270 - accuracy: 0.9918\n",
      "Epoch 20/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0176 - accuracy: 0.9945\n",
      "Epoch 21/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0153 - accuracy: 0.9964\n",
      "Epoch 22/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0145 - accuracy: 0.9956\n",
      "Epoch 23/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0126 - accuracy: 0.9956\n",
      "Epoch 24/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0144 - accuracy: 0.9951\n",
      "Epoch 25/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0122 - accuracy: 0.9971\n",
      "Epoch 26/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0120 - accuracy: 0.9961\n",
      "Epoch 27/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0122 - accuracy: 0.9961\n",
      "Epoch 28/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0138 - accuracy: 0.9956\n",
      "Epoch 29/50\n",
      "92/92 [==============================] - 5s 58ms/step - loss: 0.0101 - accuracy: 0.9974\n",
      "Epoch 30/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0124 - accuracy: 0.9957\n",
      "Epoch 31/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0103 - accuracy: 0.9961\n",
      "Epoch 32/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0112 - accuracy: 0.9966\n",
      "Epoch 33/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0102 - accuracy: 0.9961\n",
      "Epoch 34/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0124 - accuracy: 0.9964\n",
      "Epoch 35/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0217 - accuracy: 0.9935\n",
      "Epoch 36/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0445 - accuracy: 0.9838\n",
      "Epoch 37/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0243 - accuracy: 0.9922\n",
      "Epoch 38/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0138 - accuracy: 0.9954\n",
      "Epoch 39/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0123 - accuracy: 0.9962\n",
      "Epoch 40/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0110 - accuracy: 0.9959\n",
      "Epoch 41/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0101 - accuracy: 0.9964\n",
      "Epoch 42/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0099 - accuracy: 0.9966\n",
      "Epoch 43/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0109 - accuracy: 0.9961\n",
      "Epoch 44/50\n",
      "92/92 [==============================] - 5s 58ms/step - loss: 0.0083 - accuracy: 0.9974\n",
      "Epoch 45/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0100 - accuracy: 0.9971\n",
      "Epoch 46/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0092 - accuracy: 0.9964\n",
      "Epoch 47/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0102 - accuracy: 0.9962\n",
      "Epoch 48/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0115 - accuracy: 0.9959\n",
      "Epoch 49/50\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.0181 - accuracy: 0.9947\n",
      "Epoch 50/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0154 - accuracy: 0.9954\n",
      "92/92 [==============================] - 1s 7ms/step\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=50, learning_rate=0.001, num_rnn_layers=1, rnn_units=64; total time= 4.2min\n",
      "Epoch 1/50\n",
      "92/92 [==============================] - 6s 53ms/step - loss: 0.6797 - accuracy: 0.5616\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.6145 - accuracy: 0.6706\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.4433 - accuracy: 0.8058\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.2765 - accuracy: 0.8882\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.1791 - accuracy: 0.9342\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - 5s 59ms/step - loss: 0.1145 - accuracy: 0.9645\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0766 - accuracy: 0.9787\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0548 - accuracy: 0.9831\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0443 - accuracy: 0.9872\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0373 - accuracy: 0.9889\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0351 - accuracy: 0.9908\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0488 - accuracy: 0.9847\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0258 - accuracy: 0.9939\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0250 - accuracy: 0.9934\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0187 - accuracy: 0.9951\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0205 - accuracy: 0.9945\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0166 - accuracy: 0.9962\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0139 - accuracy: 0.9962\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0165 - accuracy: 0.9947\n",
      "Epoch 20/50\n",
      "92/92 [==============================] - 5s 58ms/step - loss: 0.0115 - accuracy: 0.9964\n",
      "Epoch 21/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0114 - accuracy: 0.9966\n",
      "Epoch 22/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0132 - accuracy: 0.9954\n",
      "Epoch 23/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0110 - accuracy: 0.9962\n",
      "Epoch 24/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0120 - accuracy: 0.9957\n",
      "Epoch 25/50\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.0109 - accuracy: 0.9968\n",
      "Epoch 26/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0114 - accuracy: 0.9962\n",
      "Epoch 27/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0099 - accuracy: 0.9968\n",
      "Epoch 28/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0112 - accuracy: 0.9969\n",
      "Epoch 29/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0097 - accuracy: 0.9971\n",
      "Epoch 30/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0102 - accuracy: 0.9962\n",
      "Epoch 31/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0097 - accuracy: 0.9969\n",
      "Epoch 32/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0086 - accuracy: 0.9962\n",
      "Epoch 33/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0087 - accuracy: 0.9962\n",
      "Epoch 34/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0084 - accuracy: 0.9971\n",
      "Epoch 35/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0090 - accuracy: 0.9968\n",
      "Epoch 36/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0106 - accuracy: 0.9962\n",
      "Epoch 37/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0722 - accuracy: 0.9772\n",
      "Epoch 38/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0393 - accuracy: 0.9855\n",
      "Epoch 39/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0194 - accuracy: 0.9947\n",
      "Epoch 40/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0133 - accuracy: 0.9961\n",
      "Epoch 41/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0096 - accuracy: 0.9974\n",
      "Epoch 42/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0094 - accuracy: 0.9957\n",
      "Epoch 43/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0095 - accuracy: 0.9971\n",
      "Epoch 44/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0084 - accuracy: 0.9969\n",
      "Epoch 45/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0086 - accuracy: 0.9969\n",
      "Epoch 46/50\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.0075 - accuracy: 0.9969\n",
      "Epoch 47/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0078 - accuracy: 0.9962\n",
      "Epoch 48/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0081 - accuracy: 0.9964\n",
      "Epoch 49/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0068 - accuracy: 0.9971\n",
      "Epoch 50/50\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.0070 - accuracy: 0.9976\n",
      "92/92 [==============================] - 1s 7ms/step\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=50, learning_rate=0.001, num_rnn_layers=1, rnn_units=64; total time= 4.2min\n",
      "Epoch 1/50\n",
      "92/92 [==============================] - 6s 54ms/step - loss: 0.6854 - accuracy: 0.5651\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.6438 - accuracy: 0.6216\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.4803 - accuracy: 0.7846\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.3130 - accuracy: 0.8748\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.2385 - accuracy: 0.9031\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.1701 - accuracy: 0.9369\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.1194 - accuracy: 0.9575\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.1129 - accuracy: 0.9601\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0810 - accuracy: 0.9705\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0639 - accuracy: 0.9765\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - 5s 59ms/step - loss: 0.0474 - accuracy: 0.9864\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0379 - accuracy: 0.9869\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0273 - accuracy: 0.9915\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0341 - accuracy: 0.9905\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0887 - accuracy: 0.9656\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0285 - accuracy: 0.9910\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - 5s 59ms/step - loss: 0.0252 - accuracy: 0.9905\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0206 - accuracy: 0.9925\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0307 - accuracy: 0.9908\n",
      "Epoch 20/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0234 - accuracy: 0.9922\n",
      "Epoch 21/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0227 - accuracy: 0.9925\n",
      "Epoch 22/50\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.0175 - accuracy: 0.9940\n",
      "Epoch 23/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0175 - accuracy: 0.9939\n",
      "Epoch 24/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0165 - accuracy: 0.9944\n",
      "Epoch 25/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0191 - accuracy: 0.9930\n",
      "Epoch 26/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0181 - accuracy: 0.9930\n",
      "Epoch 27/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0179 - accuracy: 0.9933\n",
      "Epoch 28/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0170 - accuracy: 0.9942\n",
      "Epoch 29/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0151 - accuracy: 0.9940\n",
      "Epoch 30/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0245 - accuracy: 0.9899\n",
      "Epoch 31/50\n",
      "92/92 [==============================] - 5s 59ms/step - loss: 0.0255 - accuracy: 0.9913\n",
      "Epoch 32/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0263 - accuracy: 0.9908\n",
      "Epoch 33/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0183 - accuracy: 0.9935\n",
      "Epoch 34/50\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.0184 - accuracy: 0.9933\n",
      "Epoch 35/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0145 - accuracy: 0.9952\n",
      "Epoch 36/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0149 - accuracy: 0.9945\n",
      "Epoch 37/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0157 - accuracy: 0.9945\n",
      "Epoch 38/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0126 - accuracy: 0.9949\n",
      "Epoch 39/50\n",
      "92/92 [==============================] - 5s 59ms/step - loss: 0.0122 - accuracy: 0.9949\n",
      "Epoch 40/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0108 - accuracy: 0.9954\n",
      "Epoch 41/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0129 - accuracy: 0.9951\n",
      "Epoch 42/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0116 - accuracy: 0.9954\n",
      "Epoch 43/50\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.0120 - accuracy: 0.9956\n",
      "Epoch 44/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0204 - accuracy: 0.9928\n",
      "Epoch 45/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0201 - accuracy: 0.9923\n",
      "Epoch 46/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0163 - accuracy: 0.9937\n",
      "Epoch 47/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0158 - accuracy: 0.9945\n",
      "Epoch 48/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0145 - accuracy: 0.9947\n",
      "Epoch 49/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0116 - accuracy: 0.9956\n",
      "Epoch 50/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0135 - accuracy: 0.9945\n",
      "92/92 [==============================] - 1s 7ms/step\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=50, learning_rate=0.001, num_rnn_layers=1, rnn_units=128; total time= 4.2min\n",
      "Epoch 1/50\n",
      "92/92 [==============================] - 5s 51ms/step - loss: 0.6855 - accuracy: 0.5579\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.6304 - accuracy: 0.6404\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.4504 - accuracy: 0.7991\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.3090 - accuracy: 0.8720\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.2166 - accuracy: 0.9134\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.1683 - accuracy: 0.9352\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.1355 - accuracy: 0.9511\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.1742 - accuracy: 0.9320\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.1370 - accuracy: 0.9500\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0770 - accuracy: 0.9727\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0587 - accuracy: 0.9790\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0437 - accuracy: 0.9864\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0383 - accuracy: 0.9874\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0395 - accuracy: 0.9882\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0350 - accuracy: 0.9893\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0244 - accuracy: 0.9934\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0247 - accuracy: 0.9913\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0283 - accuracy: 0.9910\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0220 - accuracy: 0.9930\n",
      "Epoch 20/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0294 - accuracy: 0.9901\n",
      "Epoch 21/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0270 - accuracy: 0.9911\n",
      "Epoch 22/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.1224 - accuracy: 0.9541\n",
      "Epoch 23/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0653 - accuracy: 0.9763\n",
      "Epoch 24/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0376 - accuracy: 0.9857\n",
      "Epoch 25/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0314 - accuracy: 0.9894\n",
      "Epoch 26/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0375 - accuracy: 0.9870\n",
      "Epoch 27/50\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.0233 - accuracy: 0.9935\n",
      "Epoch 28/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0275 - accuracy: 0.9908\n",
      "Epoch 29/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0198 - accuracy: 0.9935\n",
      "Epoch 30/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0163 - accuracy: 0.9952\n",
      "Epoch 31/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0145 - accuracy: 0.9952\n",
      "Epoch 32/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0147 - accuracy: 0.9937\n",
      "Epoch 33/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0133 - accuracy: 0.9956\n",
      "Epoch 34/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0133 - accuracy: 0.9957\n",
      "Epoch 35/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0121 - accuracy: 0.9954\n",
      "Epoch 36/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0132 - accuracy: 0.9947\n",
      "Epoch 37/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0114 - accuracy: 0.9956\n",
      "Epoch 38/50\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.0141 - accuracy: 0.9951\n",
      "Epoch 39/50\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.0118 - accuracy: 0.9968\n",
      "Epoch 40/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0122 - accuracy: 0.9962\n",
      "Epoch 41/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0108 - accuracy: 0.9966\n",
      "Epoch 42/50\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.0102 - accuracy: 0.9957\n",
      "Epoch 43/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0157 - accuracy: 0.9945\n",
      "Epoch 44/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0283 - accuracy: 0.9905\n",
      "Epoch 45/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0200 - accuracy: 0.9932\n",
      "Epoch 46/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0139 - accuracy: 0.9951\n",
      "Epoch 47/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0103 - accuracy: 0.9961\n",
      "Epoch 48/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0116 - accuracy: 0.9961\n",
      "Epoch 49/50\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.0098 - accuracy: 0.9962\n",
      "Epoch 50/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0159 - accuracy: 0.9942\n",
      "92/92 [==============================] - 1s 8ms/step\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=50, learning_rate=0.001, num_rnn_layers=1, rnn_units=128; total time= 4.2min\n",
      "Epoch 1/50\n",
      "92/92 [==============================] - 6s 55ms/step - loss: 0.6901 - accuracy: 0.5461\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.6244 - accuracy: 0.6457\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.4385 - accuracy: 0.8007\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.3080 - accuracy: 0.8675\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.2114 - accuracy: 0.9187\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.1767 - accuracy: 0.9315\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.1178 - accuracy: 0.9584\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0875 - accuracy: 0.9714\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0796 - accuracy: 0.9732\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0492 - accuracy: 0.9864\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0401 - accuracy: 0.9876\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0320 - accuracy: 0.9893\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0539 - accuracy: 0.9821\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0273 - accuracy: 0.9910\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0377 - accuracy: 0.9886\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0648 - accuracy: 0.9790\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0392 - accuracy: 0.9867\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0241 - accuracy: 0.9932\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0184 - accuracy: 0.9954\n",
      "Epoch 20/50\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.0245 - accuracy: 0.9928\n",
      "Epoch 21/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0203 - accuracy: 0.9932\n",
      "Epoch 22/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0182 - accuracy: 0.9947\n",
      "Epoch 23/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0155 - accuracy: 0.9954\n",
      "Epoch 24/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0432 - accuracy: 0.9884\n",
      "Epoch 25/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0546 - accuracy: 0.9811\n",
      "Epoch 26/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0223 - accuracy: 0.9939\n",
      "Epoch 27/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0174 - accuracy: 0.9945\n",
      "Epoch 28/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0139 - accuracy: 0.9954\n",
      "Epoch 29/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0133 - accuracy: 0.9954\n",
      "Epoch 30/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0117 - accuracy: 0.9962\n",
      "Epoch 31/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0107 - accuracy: 0.9962\n",
      "Epoch 32/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0117 - accuracy: 0.9959\n",
      "Epoch 33/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0119 - accuracy: 0.9968\n",
      "Epoch 34/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0111 - accuracy: 0.9959\n",
      "Epoch 35/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0174 - accuracy: 0.9932\n",
      "Epoch 36/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0145 - accuracy: 0.9957\n",
      "Epoch 37/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0113 - accuracy: 0.9966\n",
      "Epoch 38/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0135 - accuracy: 0.9959\n",
      "Epoch 39/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0119 - accuracy: 0.9954\n",
      "Epoch 40/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0116 - accuracy: 0.9961\n",
      "Epoch 41/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0172 - accuracy: 0.9945\n",
      "Epoch 42/50\n",
      "92/92 [==============================] - 6s 63ms/step - loss: 0.0112 - accuracy: 0.9968\n",
      "Epoch 43/50\n",
      "92/92 [==============================] - 5s 58ms/step - loss: 0.0150 - accuracy: 0.9952\n",
      "Epoch 44/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0139 - accuracy: 0.9952\n",
      "Epoch 45/50\n",
      "92/92 [==============================] - 5s 58ms/step - loss: 0.0253 - accuracy: 0.9922\n",
      "Epoch 46/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0283 - accuracy: 0.9915\n",
      "Epoch 47/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0136 - accuracy: 0.9954\n",
      "Epoch 48/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0115 - accuracy: 0.9964\n",
      "Epoch 49/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0111 - accuracy: 0.9964\n",
      "Epoch 50/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0103 - accuracy: 0.9964\n",
      "92/92 [==============================] - 1s 8ms/step\n",
      "[CV] END batch_size=64, dropout_rate=0.2, epochs=50, learning_rate=0.001, num_rnn_layers=1, rnn_units=128; total time= 4.3min\n",
      "Epoch 1/20\n",
      "92/92 [==============================] - 6s 53ms/step - loss: 0.6903 - accuracy: 0.5629\n",
      "Epoch 2/20\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.6152 - accuracy: 0.6673\n",
      "Epoch 3/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.4532 - accuracy: 0.7931\n",
      "Epoch 4/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.3216 - accuracy: 0.8658\n",
      "Epoch 5/20\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.2389 - accuracy: 0.9064\n",
      "Epoch 6/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.1806 - accuracy: 0.9333\n",
      "Epoch 7/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.1504 - accuracy: 0.9485\n",
      "Epoch 8/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.1242 - accuracy: 0.9567\n",
      "Epoch 9/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.1392 - accuracy: 0.9466\n",
      "Epoch 10/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0922 - accuracy: 0.9700\n",
      "Epoch 11/20\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0733 - accuracy: 0.9734\n",
      "Epoch 12/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0611 - accuracy: 0.9824\n",
      "Epoch 13/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0516 - accuracy: 0.9850\n",
      "Epoch 14/20\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0375 - accuracy: 0.9896\n",
      "Epoch 15/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0372 - accuracy: 0.9886\n",
      "Epoch 16/20\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0423 - accuracy: 0.9882\n",
      "Epoch 17/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0459 - accuracy: 0.9865\n",
      "Epoch 18/20\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0326 - accuracy: 0.9901\n",
      "Epoch 19/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0317 - accuracy: 0.9910\n",
      "Epoch 20/20\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0297 - accuracy: 0.9906\n",
      "92/92 [==============================] - 1s 8ms/step\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=20, learning_rate=0.001, num_rnn_layers=1, rnn_units=64; total time= 1.7min\n",
      "Epoch 1/20\n",
      "92/92 [==============================] - 6s 54ms/step - loss: 0.6995 - accuracy: 0.5581\n",
      "Epoch 2/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.6100 - accuracy: 0.6740\n",
      "Epoch 3/20\n",
      "92/92 [==============================] - 5s 51ms/step - loss: 0.4471 - accuracy: 0.7925\n",
      "Epoch 4/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.2954 - accuracy: 0.8810\n",
      "Epoch 5/20\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.2063 - accuracy: 0.9263\n",
      "Epoch 6/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.1527 - accuracy: 0.9461\n",
      "Epoch 7/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.1132 - accuracy: 0.9608\n",
      "Epoch 8/20\n",
      "92/92 [==============================] - 5s 59ms/step - loss: 0.0904 - accuracy: 0.9715\n",
      "Epoch 9/20\n",
      "92/92 [==============================] - 5s 58ms/step - loss: 0.0621 - accuracy: 0.9818\n",
      "Epoch 10/20\n",
      "92/92 [==============================] - 5s 59ms/step - loss: 0.0597 - accuracy: 0.9802\n",
      "Epoch 11/20\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0548 - accuracy: 0.9823\n",
      "Epoch 12/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0410 - accuracy: 0.9855\n",
      "Epoch 13/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0388 - accuracy: 0.9889\n",
      "Epoch 14/20\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0347 - accuracy: 0.9908\n",
      "Epoch 15/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0310 - accuracy: 0.9910\n",
      "Epoch 16/20\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.0308 - accuracy: 0.9896\n",
      "Epoch 17/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0305 - accuracy: 0.9920\n",
      "Epoch 18/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0223 - accuracy: 0.9939\n",
      "Epoch 19/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0199 - accuracy: 0.9951\n",
      "Epoch 20/20\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0208 - accuracy: 0.9947\n",
      "92/92 [==============================] - 1s 7ms/step\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=20, learning_rate=0.001, num_rnn_layers=1, rnn_units=64; total time= 1.7min\n",
      "Epoch 1/20\n",
      "92/92 [==============================] - 6s 54ms/step - loss: 0.6905 - accuracy: 0.5599\n",
      "Epoch 2/20\n",
      "92/92 [==============================] - 5s 58ms/step - loss: 0.6305 - accuracy: 0.6535\n",
      "Epoch 3/20\n",
      "92/92 [==============================] - 5s 58ms/step - loss: 0.4689 - accuracy: 0.7942\n",
      "Epoch 4/20\n",
      "92/92 [==============================] - 6s 64ms/step - loss: 0.3241 - accuracy: 0.8696\n",
      "Epoch 5/20\n",
      "92/92 [==============================] - 6s 61ms/step - loss: 0.2404 - accuracy: 0.9103\n",
      "Epoch 6/20\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.1858 - accuracy: 0.9344\n",
      "Epoch 7/20\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.1449 - accuracy: 0.9483\n",
      "Epoch 8/20\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.1269 - accuracy: 0.9594\n",
      "Epoch 9/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0932 - accuracy: 0.9703\n",
      "Epoch 10/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0773 - accuracy: 0.9744\n",
      "Epoch 11/20\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0719 - accuracy: 0.9795\n",
      "Epoch 12/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0458 - accuracy: 0.9852\n",
      "Epoch 13/20\n",
      "92/92 [==============================] - 6s 65ms/step - loss: 0.0446 - accuracy: 0.9874\n",
      "Epoch 14/20\n",
      "92/92 [==============================] - 6s 60ms/step - loss: 0.0403 - accuracy: 0.9870\n",
      "Epoch 15/20\n",
      "92/92 [==============================] - 6s 67ms/step - loss: 0.0372 - accuracy: 0.9879\n",
      "Epoch 16/20\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0309 - accuracy: 0.9916\n",
      "Epoch 17/20\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0484 - accuracy: 0.9857\n",
      "Epoch 18/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0297 - accuracy: 0.9905\n",
      "Epoch 19/20\n",
      "92/92 [==============================] - 6s 61ms/step - loss: 0.0213 - accuracy: 0.9945\n",
      "Epoch 20/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0208 - accuracy: 0.9942\n",
      "92/92 [==============================] - 1s 8ms/step\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=20, learning_rate=0.001, num_rnn_layers=1, rnn_units=64; total time= 1.8min\n",
      "Epoch 1/20\n",
      "92/92 [==============================] - 6s 60ms/step - loss: 0.7007 - accuracy: 0.5512\n",
      "Epoch 2/20\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.6556 - accuracy: 0.6221\n",
      "Epoch 3/20\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.5210 - accuracy: 0.7578\n",
      "Epoch 4/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.3734 - accuracy: 0.8424\n",
      "Epoch 5/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.2767 - accuracy: 0.8839\n",
      "Epoch 6/20\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.2101 - accuracy: 0.9233\n",
      "Epoch 7/20\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.1681 - accuracy: 0.9374\n",
      "Epoch 8/20\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.1560 - accuracy: 0.9407\n",
      "Epoch 9/20\n",
      "92/92 [==============================] - 11s 121ms/step - loss: 0.1172 - accuracy: 0.9582\n",
      "Epoch 10/20\n",
      "92/92 [==============================] - 11s 120ms/step - loss: 0.0985 - accuracy: 0.9659\n",
      "Epoch 11/20\n",
      "92/92 [==============================] - 11s 115ms/step - loss: 0.0813 - accuracy: 0.9725\n",
      "Epoch 12/20\n",
      "92/92 [==============================] - 9s 93ms/step - loss: 0.0751 - accuracy: 0.9731\n",
      "Epoch 13/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0650 - accuracy: 0.9770\n",
      "Epoch 14/20\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.0563 - accuracy: 0.9819\n",
      "Epoch 15/20\n",
      "92/92 [==============================] - 5s 51ms/step - loss: 0.0529 - accuracy: 0.9823\n",
      "Epoch 16/20\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.0485 - accuracy: 0.9836\n",
      "Epoch 17/20\n",
      "92/92 [==============================] - 5s 50ms/step - loss: 0.0430 - accuracy: 0.9836\n",
      "Epoch 18/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0375 - accuracy: 0.9872\n",
      "Epoch 19/20\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0334 - accuracy: 0.9891\n",
      "Epoch 20/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0395 - accuracy: 0.9870\n",
      "92/92 [==============================] - 1s 7ms/step\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=20, learning_rate=0.001, num_rnn_layers=1, rnn_units=128; total time= 2.0min\n",
      "Epoch 1/20\n",
      "92/92 [==============================] - 6s 55ms/step - loss: 0.6987 - accuracy: 0.5666\n",
      "Epoch 2/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.6514 - accuracy: 0.6121\n",
      "Epoch 3/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.4886 - accuracy: 0.7681\n",
      "Epoch 4/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.3318 - accuracy: 0.8617\n",
      "Epoch 5/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.2489 - accuracy: 0.9023\n",
      "Epoch 6/20\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.1998 - accuracy: 0.9238\n",
      "Epoch 7/20\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.1570 - accuracy: 0.9415\n",
      "Epoch 8/20\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.1388 - accuracy: 0.9495\n",
      "Epoch 9/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.1042 - accuracy: 0.9620\n",
      "Epoch 10/20\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.1036 - accuracy: 0.9625\n",
      "Epoch 11/20\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.1013 - accuracy: 0.9623\n",
      "Epoch 12/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0655 - accuracy: 0.9770\n",
      "Epoch 13/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0644 - accuracy: 0.9772\n",
      "Epoch 14/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0431 - accuracy: 0.9852\n",
      "Epoch 15/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0626 - accuracy: 0.9801\n",
      "Epoch 16/20\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0340 - accuracy: 0.9891\n",
      "Epoch 17/20\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0283 - accuracy: 0.9922\n",
      "Epoch 18/20\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0265 - accuracy: 0.9916\n",
      "Epoch 19/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0290 - accuracy: 0.9913\n",
      "Epoch 20/20\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0212 - accuracy: 0.9945\n",
      "92/92 [==============================] - 1s 7ms/step\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=20, learning_rate=0.001, num_rnn_layers=1, rnn_units=128; total time= 1.7min\n",
      "Epoch 1/20\n",
      "92/92 [==============================] - 6s 55ms/step - loss: 0.7056 - accuracy: 0.5488\n",
      "Epoch 2/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.6596 - accuracy: 0.6114\n",
      "Epoch 3/20\n",
      "92/92 [==============================] - 5s 51ms/step - loss: 0.4989 - accuracy: 0.7621\n",
      "Epoch 4/20\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.3517 - accuracy: 0.8505\n",
      "Epoch 5/20\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.2621 - accuracy: 0.8977\n",
      "Epoch 6/20\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.2053 - accuracy: 0.9200\n",
      "Epoch 7/20\n",
      "92/92 [==============================] - 5s 51ms/step - loss: 0.1755 - accuracy: 0.9332\n",
      "Epoch 8/20\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.2598 - accuracy: 0.9107\n",
      "Epoch 9/20\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.2123 - accuracy: 0.9161\n",
      "Epoch 10/20\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.1471 - accuracy: 0.9456\n",
      "Epoch 11/20\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.1277 - accuracy: 0.9550\n",
      "Epoch 12/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0961 - accuracy: 0.9662\n",
      "Epoch 13/20\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.0713 - accuracy: 0.9775\n",
      "Epoch 14/20\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0595 - accuracy: 0.9819\n",
      "Epoch 15/20\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0527 - accuracy: 0.9843\n",
      "Epoch 16/20\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0465 - accuracy: 0.9840\n",
      "Epoch 17/20\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0374 - accuracy: 0.9891\n",
      "Epoch 18/20\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0336 - accuracy: 0.9893\n",
      "Epoch 19/20\n",
      "92/92 [==============================] - 5s 50ms/step - loss: 0.0263 - accuracy: 0.9898\n",
      "Epoch 20/20\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0210 - accuracy: 0.9940\n",
      "92/92 [==============================] - 1s 7ms/step\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=20, learning_rate=0.001, num_rnn_layers=1, rnn_units=128; total time= 1.6min\n",
      "Epoch 1/50\n",
      "92/92 [==============================] - 6s 54ms/step - loss: 0.6929 - accuracy: 0.5563\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.6158 - accuracy: 0.6663\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.4504 - accuracy: 0.7995\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.3240 - accuracy: 0.8661\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.2450 - accuracy: 0.9064\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.1884 - accuracy: 0.9296\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.1482 - accuracy: 0.9463\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.1301 - accuracy: 0.9546\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.1015 - accuracy: 0.9654\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0766 - accuracy: 0.9751\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0644 - accuracy: 0.9794\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0579 - accuracy: 0.9823\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0529 - accuracy: 0.9836\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0538 - accuracy: 0.9823\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0390 - accuracy: 0.9891\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0403 - accuracy: 0.9881\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0476 - accuracy: 0.9847\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0402 - accuracy: 0.9886\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0330 - accuracy: 0.9903\n",
      "Epoch 20/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0524 - accuracy: 0.9826\n",
      "Epoch 21/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0334 - accuracy: 0.9887\n",
      "Epoch 22/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0331 - accuracy: 0.9905\n",
      "Epoch 23/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0243 - accuracy: 0.9928\n",
      "Epoch 24/50\n",
      "92/92 [==============================] - 6s 60ms/step - loss: 0.0243 - accuracy: 0.9920\n",
      "Epoch 25/50\n",
      "92/92 [==============================] - 5s 58ms/step - loss: 0.0210 - accuracy: 0.9925\n",
      "Epoch 26/50\n",
      "92/92 [==============================] - 5s 58ms/step - loss: 0.0228 - accuracy: 0.9937\n",
      "Epoch 27/50\n",
      "92/92 [==============================] - 5s 58ms/step - loss: 0.0234 - accuracy: 0.9930\n",
      "Epoch 28/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0596 - accuracy: 0.9778\n",
      "Epoch 29/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0268 - accuracy: 0.9923\n",
      "Epoch 30/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0234 - accuracy: 0.9916\n",
      "Epoch 31/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0206 - accuracy: 0.9930\n",
      "Epoch 32/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0206 - accuracy: 0.9935\n",
      "Epoch 33/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0206 - accuracy: 0.9930\n",
      "Epoch 34/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0177 - accuracy: 0.9947\n",
      "Epoch 35/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0172 - accuracy: 0.9939\n",
      "Epoch 36/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0315 - accuracy: 0.9903\n",
      "Epoch 37/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0228 - accuracy: 0.9923\n",
      "Epoch 38/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0195 - accuracy: 0.9940\n",
      "Epoch 39/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0217 - accuracy: 0.9935\n",
      "Epoch 40/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0177 - accuracy: 0.9944\n",
      "Epoch 41/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0142 - accuracy: 0.9956\n",
      "Epoch 42/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0167 - accuracy: 0.9939\n",
      "Epoch 43/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0146 - accuracy: 0.9947\n",
      "Epoch 44/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0144 - accuracy: 0.9956\n",
      "Epoch 45/50\n",
      "92/92 [==============================] - 5s 58ms/step - loss: 0.0184 - accuracy: 0.9942\n",
      "Epoch 46/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0197 - accuracy: 0.9918\n",
      "Epoch 47/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0164 - accuracy: 0.9945\n",
      "Epoch 48/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0175 - accuracy: 0.9947\n",
      "Epoch 49/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0153 - accuracy: 0.9951\n",
      "Epoch 50/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0177 - accuracy: 0.9940\n",
      "92/92 [==============================] - 1s 7ms/step\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=50, learning_rate=0.001, num_rnn_layers=1, rnn_units=64; total time= 4.3min\n",
      "Epoch 1/50\n",
      "92/92 [==============================] - 6s 55ms/step - loss: 0.6985 - accuracy: 0.5425\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.6444 - accuracy: 0.6348\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.4950 - accuracy: 0.7688\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.3200 - accuracy: 0.8682\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.2156 - accuracy: 0.9240\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.1528 - accuracy: 0.9475\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.1088 - accuracy: 0.9608\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0857 - accuracy: 0.9732\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0870 - accuracy: 0.9731\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0609 - accuracy: 0.9821\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0502 - accuracy: 0.9838\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0386 - accuracy: 0.9896\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0356 - accuracy: 0.9894\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0292 - accuracy: 0.9903\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - 5s 58ms/step - loss: 0.0286 - accuracy: 0.9915\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0331 - accuracy: 0.9896\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0309 - accuracy: 0.9905\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0266 - accuracy: 0.9910\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0219 - accuracy: 0.9934\n",
      "Epoch 20/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0644 - accuracy: 0.9806\n",
      "Epoch 21/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0262 - accuracy: 0.9925\n",
      "Epoch 22/50\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.0204 - accuracy: 0.9944\n",
      "Epoch 23/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0183 - accuracy: 0.9947\n",
      "Epoch 24/50\n",
      "92/92 [==============================] - 5s 51ms/step - loss: 0.0173 - accuracy: 0.9954\n",
      "Epoch 25/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0182 - accuracy: 0.9947\n",
      "Epoch 26/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0145 - accuracy: 0.9956\n",
      "Epoch 27/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0155 - accuracy: 0.9952\n",
      "Epoch 28/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0149 - accuracy: 0.9959\n",
      "Epoch 29/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0140 - accuracy: 0.9961\n",
      "Epoch 30/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0157 - accuracy: 0.9957\n",
      "Epoch 31/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0106 - accuracy: 0.9969\n",
      "Epoch 32/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0170 - accuracy: 0.9954\n",
      "Epoch 33/50\n",
      "92/92 [==============================] - 5s 58ms/step - loss: 0.0206 - accuracy: 0.9932\n",
      "Epoch 34/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0169 - accuracy: 0.9949\n",
      "Epoch 35/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0150 - accuracy: 0.9952\n",
      "Epoch 36/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0151 - accuracy: 0.9956\n",
      "Epoch 37/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0149 - accuracy: 0.9949\n",
      "Epoch 38/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0157 - accuracy: 0.9952\n",
      "Epoch 39/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0180 - accuracy: 0.9937\n",
      "Epoch 40/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0144 - accuracy: 0.9954\n",
      "Epoch 41/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0149 - accuracy: 0.9956\n",
      "Epoch 42/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0133 - accuracy: 0.9956\n",
      "Epoch 43/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0113 - accuracy: 0.9966\n",
      "Epoch 44/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0130 - accuracy: 0.9966\n",
      "Epoch 45/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0195 - accuracy: 0.9935\n",
      "Epoch 46/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0129 - accuracy: 0.9956\n",
      "Epoch 47/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0113 - accuracy: 0.9966\n",
      "Epoch 48/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0113 - accuracy: 0.9956\n",
      "Epoch 49/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0097 - accuracy: 0.9966\n",
      "Epoch 50/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0113 - accuracy: 0.9966\n",
      "92/92 [==============================] - 1s 8ms/step\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=50, learning_rate=0.001, num_rnn_layers=1, rnn_units=64; total time= 4.2min\n",
      "Epoch 1/50\n",
      "92/92 [==============================] - 6s 57ms/step - loss: 0.6914 - accuracy: 0.5633\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.6318 - accuracy: 0.6421\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.4664 - accuracy: 0.7833\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.3160 - accuracy: 0.8723\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.2250 - accuracy: 0.9144\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.1749 - accuracy: 0.9347\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.1386 - accuracy: 0.9531\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.1032 - accuracy: 0.9656\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.0755 - accuracy: 0.9766\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.0629 - accuracy: 0.9806\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0604 - accuracy: 0.9802\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.0602 - accuracy: 0.9811\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0378 - accuracy: 0.9893\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0396 - accuracy: 0.9881\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - 5s 58ms/step - loss: 0.0360 - accuracy: 0.9893\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0299 - accuracy: 0.9920\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0261 - accuracy: 0.9928\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0264 - accuracy: 0.9939\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0242 - accuracy: 0.9937\n",
      "Epoch 20/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0254 - accuracy: 0.9920\n",
      "Epoch 21/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0241 - accuracy: 0.9930\n",
      "Epoch 22/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0181 - accuracy: 0.9944\n",
      "Epoch 23/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0375 - accuracy: 0.9872\n",
      "Epoch 24/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0282 - accuracy: 0.9918\n",
      "Epoch 25/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0242 - accuracy: 0.9935\n",
      "Epoch 26/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0225 - accuracy: 0.9934\n",
      "Epoch 27/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0181 - accuracy: 0.9951\n",
      "Epoch 28/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0297 - accuracy: 0.9905\n",
      "Epoch 29/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0179 - accuracy: 0.9954\n",
      "Epoch 30/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0165 - accuracy: 0.9954\n",
      "Epoch 31/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0169 - accuracy: 0.9942\n",
      "Epoch 32/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0179 - accuracy: 0.9951\n",
      "Epoch 33/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0144 - accuracy: 0.9962\n",
      "Epoch 34/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0126 - accuracy: 0.9964\n",
      "Epoch 35/50\n",
      "92/92 [==============================] - 5s 58ms/step - loss: 0.0122 - accuracy: 0.9962\n",
      "Epoch 36/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0108 - accuracy: 0.9964\n",
      "Epoch 37/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0131 - accuracy: 0.9954\n",
      "Epoch 38/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0137 - accuracy: 0.9964\n",
      "Epoch 39/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0116 - accuracy: 0.9966\n",
      "Epoch 40/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0114 - accuracy: 0.9968\n",
      "Epoch 41/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0134 - accuracy: 0.9956\n",
      "Epoch 42/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0119 - accuracy: 0.9957\n",
      "Epoch 43/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0121 - accuracy: 0.9962\n",
      "Epoch 44/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0128 - accuracy: 0.9973\n",
      "Epoch 45/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0671 - accuracy: 0.9807\n",
      "Epoch 46/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0891 - accuracy: 0.9743\n",
      "Epoch 47/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0319 - accuracy: 0.9884\n",
      "Epoch 48/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.0189 - accuracy: 0.9945\n",
      "Epoch 49/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0135 - accuracy: 0.9957\n",
      "Epoch 50/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0115 - accuracy: 0.9966\n",
      "92/92 [==============================] - 1s 8ms/step\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=50, learning_rate=0.001, num_rnn_layers=1, rnn_units=64; total time= 4.2min\n",
      "Epoch 1/50\n",
      "92/92 [==============================] - 6s 55ms/step - loss: 0.7031 - accuracy: 0.5430\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.6657 - accuracy: 0.6090\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.5092 - accuracy: 0.7577\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.3722 - accuracy: 0.8443\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.2885 - accuracy: 0.8808\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.2163 - accuracy: 0.9178\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.1694 - accuracy: 0.9362\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.1310 - accuracy: 0.9514\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.1286 - accuracy: 0.9523\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.1101 - accuracy: 0.9592\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0914 - accuracy: 0.9685\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: 0.1112 - accuracy: 0.9598\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0965 - accuracy: 0.9652\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0597 - accuracy: 0.9806\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0538 - accuracy: 0.9824\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0496 - accuracy: 0.9853\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0433 - accuracy: 0.9860\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0374 - accuracy: 0.9887\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0282 - accuracy: 0.9906\n",
      "Epoch 20/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0286 - accuracy: 0.9905\n",
      "Epoch 21/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: 0.0260 - accuracy: 0.9908\n",
      "Epoch 22/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0287 - accuracy: 0.9910\n",
      "Epoch 23/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: 0.0315 - accuracy: 0.9899\n",
      "Epoch 24/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: 0.0311 - accuracy: 0.9893\n",
      "Epoch 25/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0314 - accuracy: 0.9901\n",
      "Epoch 26/50\n",
      "92/92 [==============================] - 11s 117ms/step - loss: 0.0338 - accuracy: 0.9889\n",
      "Epoch 27/50\n",
      "92/92 [==============================] - 11s 116ms/step - loss: 0.0274 - accuracy: 0.9903\n",
      "Epoch 28/50\n",
      "92/92 [==============================] - 11s 114ms/step - loss: 0.0264 - accuracy: 0.9903\n",
      "Epoch 29/50\n",
      "92/92 [==============================] - 11s 119ms/step - loss: 0.0162 - accuracy: 0.9937\n",
      "Epoch 30/50\n",
      "92/92 [==============================] - 11s 116ms/step - loss: 0.0207 - accuracy: 0.9923\n",
      "Epoch 31/50\n",
      "92/92 [==============================] - 11s 122ms/step - loss: 0.0415 - accuracy: 0.9840\n",
      "Epoch 32/50\n",
      "92/92 [==============================] - 11s 122ms/step - loss: 0.0263 - accuracy: 0.9903\n",
      "Epoch 33/50\n",
      "92/92 [==============================] - 11s 124ms/step - loss: 0.0384 - accuracy: 0.9857\n",
      "Epoch 34/50\n",
      "92/92 [==============================] - 11s 122ms/step - loss: 0.0330 - accuracy: 0.9884\n",
      "Epoch 35/50\n",
      "92/92 [==============================] - 11s 115ms/step - loss: 0.0252 - accuracy: 0.9913\n",
      "Epoch 36/50\n",
      "92/92 [==============================] - 11s 116ms/step - loss: 0.0315 - accuracy: 0.9891\n",
      "Epoch 37/50\n",
      "92/92 [==============================] - 11s 119ms/step - loss: 0.0258 - accuracy: 0.9916\n",
      "Epoch 38/50\n",
      "92/92 [==============================] - 11s 119ms/step - loss: 0.0201 - accuracy: 0.9928\n",
      "Epoch 39/50\n",
      "92/92 [==============================] - 11s 115ms/step - loss: 0.0141 - accuracy: 0.9949\n",
      "Epoch 40/50\n",
      "92/92 [==============================] - 11s 121ms/step - loss: 0.0169 - accuracy: 0.9940\n",
      "Epoch 41/50\n",
      "92/92 [==============================] - 11s 121ms/step - loss: 0.0146 - accuracy: 0.9949\n",
      "Epoch 42/50\n",
      "92/92 [==============================] - 11s 121ms/step - loss: 0.0167 - accuracy: 0.9937\n",
      "Epoch 43/50\n",
      "92/92 [==============================] - 11s 122ms/step - loss: 0.0148 - accuracy: 0.9944\n",
      "Epoch 44/50\n",
      "92/92 [==============================] - 10s 113ms/step - loss: 0.0241 - accuracy: 0.9928\n",
      "Epoch 45/50\n",
      "92/92 [==============================] - 11s 116ms/step - loss: 0.0241 - accuracy: 0.9918\n",
      "Epoch 46/50\n",
      "92/92 [==============================] - 11s 119ms/step - loss: 0.0174 - accuracy: 0.9947\n",
      "Epoch 47/50\n",
      "92/92 [==============================] - 11s 116ms/step - loss: 0.0313 - accuracy: 0.9898\n",
      "Epoch 48/50\n",
      "92/92 [==============================] - 11s 121ms/step - loss: 0.0294 - accuracy: 0.9891\n",
      "Epoch 49/50\n",
      "92/92 [==============================] - 11s 117ms/step - loss: 0.0290 - accuracy: 0.9911\n",
      "Epoch 50/50\n",
      "92/92 [==============================] - 12s 129ms/step - loss: 0.0158 - accuracy: 0.9949\n",
      "92/92 [==============================] - 2s 17ms/step\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=50, learning_rate=0.001, num_rnn_layers=1, rnn_units=128; total time= 6.7min\n",
      "Epoch 1/50\n",
      "92/92 [==============================] - 13s 124ms/step - loss: 0.7059 - accuracy: 0.5460\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - 11s 121ms/step - loss: 0.6638 - accuracy: 0.5974\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - 11s 117ms/step - loss: 0.5191 - accuracy: 0.7514\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - 11s 119ms/step - loss: 0.3594 - accuracy: 0.8476\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - 11s 116ms/step - loss: 0.2656 - accuracy: 0.8962\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - 11s 119ms/step - loss: 0.2051 - accuracy: 0.9214\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - 11s 123ms/step - loss: 0.1667 - accuracy: 0.9396\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - 11s 125ms/step - loss: 0.1386 - accuracy: 0.9516\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - 12s 126ms/step - loss: 0.1325 - accuracy: 0.9497\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - 11s 124ms/step - loss: 0.0938 - accuracy: 0.9668\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - 11s 122ms/step - loss: 0.0726 - accuracy: 0.9772\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - 11s 116ms/step - loss: 0.0566 - accuracy: 0.9809\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - 11s 119ms/step - loss: 0.0511 - accuracy: 0.9833\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - 11s 117ms/step - loss: 0.0583 - accuracy: 0.9806\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - 11s 119ms/step - loss: 0.0562 - accuracy: 0.9829\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - 11s 122ms/step - loss: 0.0370 - accuracy: 0.9881\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - 11s 123ms/step - loss: 0.0327 - accuracy: 0.9879\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - 11s 125ms/step - loss: 0.0439 - accuracy: 0.9845\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - 11s 120ms/step - loss: 0.0356 - accuracy: 0.9889\n",
      "Epoch 20/50\n",
      "92/92 [==============================] - 11s 118ms/step - loss: 0.0283 - accuracy: 0.9910\n",
      "Epoch 21/50\n",
      "92/92 [==============================] - 11s 122ms/step - loss: 0.0232 - accuracy: 0.9922\n",
      "Epoch 22/50\n",
      "92/92 [==============================] - 11s 122ms/step - loss: 0.0317 - accuracy: 0.9887\n",
      "Epoch 23/50\n",
      "92/92 [==============================] - 11s 123ms/step - loss: 0.0357 - accuracy: 0.9882\n",
      "Epoch 24/50\n",
      "92/92 [==============================] - 11s 117ms/step - loss: 0.0277 - accuracy: 0.9915\n",
      "Epoch 25/50\n",
      "92/92 [==============================] - 11s 122ms/step - loss: 0.0220 - accuracy: 0.9935\n",
      "Epoch 26/50\n",
      "92/92 [==============================] - 11s 124ms/step - loss: 0.0196 - accuracy: 0.9937\n",
      "Epoch 27/50\n",
      "92/92 [==============================] - 11s 118ms/step - loss: 0.0208 - accuracy: 0.9928\n",
      "Epoch 28/50\n",
      "92/92 [==============================] - 11s 119ms/step - loss: 0.0220 - accuracy: 0.9939\n",
      "Epoch 29/50\n",
      "92/92 [==============================] - 11s 118ms/step - loss: 0.0210 - accuracy: 0.9930\n",
      "Epoch 30/50\n",
      "92/92 [==============================] - 11s 120ms/step - loss: 0.0415 - accuracy: 0.9876\n",
      "Epoch 31/50\n",
      "92/92 [==============================] - 11s 117ms/step - loss: 0.0208 - accuracy: 0.9930\n",
      "Epoch 32/50\n",
      "92/92 [==============================] - 11s 124ms/step - loss: 0.0207 - accuracy: 0.9937\n",
      "Epoch 33/50\n",
      "92/92 [==============================] - 12s 126ms/step - loss: 0.0918 - accuracy: 0.9686\n",
      "Epoch 34/50\n",
      "92/92 [==============================] - 11s 124ms/step - loss: 0.0394 - accuracy: 0.9869\n",
      "Epoch 35/50\n",
      "92/92 [==============================] - 11s 123ms/step - loss: 0.0178 - accuracy: 0.9954\n",
      "Epoch 36/50\n",
      "92/92 [==============================] - 11s 117ms/step - loss: 0.0180 - accuracy: 0.9949\n",
      "Epoch 37/50\n",
      "92/92 [==============================] - 11s 119ms/step - loss: 0.0191 - accuracy: 0.9934\n",
      "Epoch 38/50\n",
      "92/92 [==============================] - 11s 123ms/step - loss: 0.0212 - accuracy: 0.9932\n",
      "Epoch 39/50\n",
      "92/92 [==============================] - 11s 121ms/step - loss: 0.0143 - accuracy: 0.9957\n",
      "Epoch 40/50\n",
      "92/92 [==============================] - 11s 122ms/step - loss: 0.0161 - accuracy: 0.9947\n",
      "Epoch 41/50\n",
      "92/92 [==============================] - 11s 120ms/step - loss: 0.0144 - accuracy: 0.9954\n",
      "Epoch 42/50\n",
      "92/92 [==============================] - 12s 126ms/step - loss: 0.0143 - accuracy: 0.9957\n",
      "Epoch 43/50\n",
      "92/92 [==============================] - 11s 124ms/step - loss: 0.0116 - accuracy: 0.9959\n",
      "Epoch 44/50\n",
      "92/92 [==============================] - 11s 118ms/step - loss: 0.0138 - accuracy: 0.9949\n",
      "Epoch 45/50\n",
      "92/92 [==============================] - 11s 122ms/step - loss: 0.0126 - accuracy: 0.9956\n",
      "Epoch 46/50\n",
      "92/92 [==============================] - 11s 120ms/step - loss: 0.0116 - accuracy: 0.9956\n",
      "Epoch 47/50\n",
      "92/92 [==============================] - 11s 120ms/step - loss: 0.1268 - accuracy: 0.9548\n",
      "Epoch 48/50\n",
      "92/92 [==============================] - 11s 117ms/step - loss: 0.0348 - accuracy: 0.9870\n",
      "Epoch 49/50\n",
      "92/92 [==============================] - 11s 117ms/step - loss: 0.0208 - accuracy: 0.9934\n",
      "Epoch 50/50\n",
      "92/92 [==============================] - 11s 125ms/step - loss: 0.0143 - accuracy: 0.9952\n",
      "92/92 [==============================] - 2s 18ms/step\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=50, learning_rate=0.001, num_rnn_layers=1, rnn_units=128; total time= 9.3min\n",
      "Epoch 1/50\n",
      "92/92 [==============================] - 12s 119ms/step - loss: 0.6996 - accuracy: 0.5432\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - 11s 116ms/step - loss: 0.6569 - accuracy: 0.6140\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - 11s 115ms/step - loss: 0.5065 - accuracy: 0.7603\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - 10s 112ms/step - loss: 0.3618 - accuracy: 0.8525\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - 11s 115ms/step - loss: 0.2669 - accuracy: 0.8934\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - 11s 115ms/step - loss: 0.2064 - accuracy: 0.9194\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - 11s 120ms/step - loss: 0.1643 - accuracy: 0.9390\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - 11s 119ms/step - loss: 0.1313 - accuracy: 0.9533\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - 11s 122ms/step - loss: 0.1160 - accuracy: 0.9584\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - 11s 121ms/step - loss: 0.0883 - accuracy: 0.9690\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - 10s 108ms/step - loss: 0.0804 - accuracy: 0.9729\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - 10s 113ms/step - loss: 0.0657 - accuracy: 0.9792\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - 11s 115ms/step - loss: 0.0536 - accuracy: 0.9831\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - 11s 114ms/step - loss: 0.0551 - accuracy: 0.9828\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - 11s 117ms/step - loss: 0.0473 - accuracy: 0.9835\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - 11s 119ms/step - loss: 0.0414 - accuracy: 0.9870\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - 11s 121ms/step - loss: 0.0385 - accuracy: 0.9898\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - 11s 119ms/step - loss: 0.0666 - accuracy: 0.9761\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - 11s 116ms/step - loss: 0.0742 - accuracy: 0.9741\n",
      "Epoch 20/50\n",
      "92/92 [==============================] - 10s 110ms/step - loss: 0.0390 - accuracy: 0.9870\n",
      "Epoch 21/50\n",
      "92/92 [==============================] - 11s 115ms/step - loss: 0.0301 - accuracy: 0.9903\n",
      "Epoch 22/50\n",
      "92/92 [==============================] - 11s 117ms/step - loss: 0.0194 - accuracy: 0.9939\n",
      "Epoch 23/50\n",
      "92/92 [==============================] - 10s 113ms/step - loss: 0.0199 - accuracy: 0.9944\n",
      "Epoch 24/50\n",
      "92/92 [==============================] - 11s 117ms/step - loss: 0.0172 - accuracy: 0.9949\n",
      "Epoch 25/50\n",
      "92/92 [==============================] - 11s 116ms/step - loss: 0.0170 - accuracy: 0.9949\n",
      "Epoch 26/50\n",
      "92/92 [==============================] - 11s 121ms/step - loss: 0.0153 - accuracy: 0.9956\n",
      "Epoch 27/50\n",
      "92/92 [==============================] - 11s 118ms/step - loss: 0.0204 - accuracy: 0.9925\n",
      "Epoch 28/50\n",
      "92/92 [==============================] - 11s 118ms/step - loss: 0.0177 - accuracy: 0.9937\n",
      "Epoch 29/50\n",
      "92/92 [==============================] - 11s 117ms/step - loss: 0.0180 - accuracy: 0.9945\n",
      "Epoch 30/50\n",
      "92/92 [==============================] - 10s 112ms/step - loss: 0.0231 - accuracy: 0.9928\n",
      "Epoch 31/50\n",
      "92/92 [==============================] - 11s 118ms/step - loss: 0.0227 - accuracy: 0.9937\n",
      "Epoch 32/50\n",
      "92/92 [==============================] - 10s 113ms/step - loss: 0.0152 - accuracy: 0.9949\n",
      "Epoch 33/50\n",
      "92/92 [==============================] - 11s 116ms/step - loss: 0.0171 - accuracy: 0.9949\n",
      "Epoch 34/50\n",
      "92/92 [==============================] - 11s 118ms/step - loss: 0.0165 - accuracy: 0.9947\n",
      "Epoch 35/50\n",
      "92/92 [==============================] - 11s 121ms/step - loss: 0.0151 - accuracy: 0.9956\n",
      "Epoch 36/50\n",
      "92/92 [==============================] - 11s 118ms/step - loss: 0.0154 - accuracy: 0.9949\n",
      "Epoch 37/50\n",
      "92/92 [==============================] - 11s 116ms/step - loss: 0.0141 - accuracy: 0.9961\n",
      "Epoch 38/50\n",
      "92/92 [==============================] - 10s 113ms/step - loss: 0.0138 - accuracy: 0.9957\n",
      "Epoch 39/50\n",
      "92/92 [==============================] - 10s 113ms/step - loss: 0.0152 - accuracy: 0.9954\n",
      "Epoch 40/50\n",
      "92/92 [==============================] - 11s 115ms/step - loss: 0.0338 - accuracy: 0.9886\n",
      "Epoch 41/50\n",
      "92/92 [==============================] - 10s 113ms/step - loss: 0.0378 - accuracy: 0.9867\n",
      "Epoch 42/50\n",
      "92/92 [==============================] - 11s 120ms/step - loss: 0.0201 - accuracy: 0.9930\n",
      "Epoch 43/50\n",
      "92/92 [==============================] - 11s 118ms/step - loss: 0.0288 - accuracy: 0.9905\n",
      "Epoch 44/50\n",
      "92/92 [==============================] - 11s 125ms/step - loss: 0.0311 - accuracy: 0.9886\n",
      "Epoch 45/50\n",
      "92/92 [==============================] - 11s 118ms/step - loss: 0.0236 - accuracy: 0.9925\n",
      "Epoch 46/50\n",
      "92/92 [==============================] - 10s 112ms/step - loss: 0.0223 - accuracy: 0.9925\n",
      "Epoch 47/50\n",
      "92/92 [==============================] - 10s 112ms/step - loss: 0.0225 - accuracy: 0.9937\n",
      "Epoch 48/50\n",
      "92/92 [==============================] - 11s 117ms/step - loss: 0.0267 - accuracy: 0.9915\n",
      "Epoch 49/50\n",
      "92/92 [==============================] - 11s 116ms/step - loss: 0.0293 - accuracy: 0.9899\n",
      "Epoch 50/50\n",
      "92/92 [==============================] - 10s 113ms/step - loss: 0.0190 - accuracy: 0.9928\n",
      "92/92 [==============================] - 2s 18ms/step\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=50, learning_rate=0.001, num_rnn_layers=1, rnn_units=128; total time= 9.0min\n",
      "Epoch 1/20\n",
      "138/138 [==============================] - 18s 120ms/step - loss: 0.6764 - accuracy: 0.5659\n",
      "Epoch 2/20\n",
      "138/138 [==============================] - 17s 123ms/step - loss: 0.5008 - accuracy: 0.7642\n",
      "Epoch 3/20\n",
      "138/138 [==============================] - 16s 120ms/step - loss: 0.3428 - accuracy: 0.8592\n",
      "Epoch 4/20\n",
      "138/138 [==============================] - 16s 114ms/step - loss: 0.2625 - accuracy: 0.8969\n",
      "Epoch 5/20\n",
      "138/138 [==============================] - 16s 119ms/step - loss: 0.2107 - accuracy: 0.9188\n",
      "Epoch 6/20\n",
      "138/138 [==============================] - 16s 119ms/step - loss: 0.1696 - accuracy: 0.9371\n",
      "Epoch 7/20\n",
      "138/138 [==============================] - 16s 114ms/step - loss: 0.1155 - accuracy: 0.9599\n",
      "Epoch 8/20\n",
      "138/138 [==============================] - 17s 122ms/step - loss: 0.0890 - accuracy: 0.9709\n",
      "Epoch 9/20\n",
      "138/138 [==============================] - 16s 117ms/step - loss: 0.0667 - accuracy: 0.9775\n",
      "Epoch 10/20\n",
      "138/138 [==============================] - 16s 120ms/step - loss: 0.0631 - accuracy: 0.9803\n",
      "Epoch 11/20\n",
      "138/138 [==============================] - 16s 119ms/step - loss: 0.0448 - accuracy: 0.9861\n",
      "Epoch 12/20\n",
      "138/138 [==============================] - 16s 119ms/step - loss: 0.0418 - accuracy: 0.9873\n",
      "Epoch 13/20\n",
      "138/138 [==============================] - 16s 118ms/step - loss: 0.0318 - accuracy: 0.9903\n",
      "Epoch 14/20\n",
      "138/138 [==============================] - 17s 120ms/step - loss: 0.0300 - accuracy: 0.9903\n",
      "Epoch 15/20\n",
      "138/138 [==============================] - 16s 119ms/step - loss: 0.0289 - accuracy: 0.9924\n",
      "Epoch 16/20\n",
      "138/138 [==============================] - 16s 118ms/step - loss: 0.0245 - accuracy: 0.9928\n",
      "Epoch 17/20\n",
      "138/138 [==============================] - 16s 115ms/step - loss: 0.0202 - accuracy: 0.9941\n",
      "Epoch 18/20\n",
      "138/138 [==============================] - 16s 119ms/step - loss: 0.0221 - accuracy: 0.9941\n",
      "Epoch 19/20\n",
      "138/138 [==============================] - 17s 123ms/step - loss: 0.0196 - accuracy: 0.9939\n",
      "Epoch 20/20\n",
      "138/138 [==============================] - 16s 118ms/step - loss: 0.0262 - accuracy: 0.9916\n"
     ]
    }
   ],
   "source": [
    "grid_result_rnn = grid_rnn.fit(X_train, Y_train, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c2baf631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏆 Mejores parámetros: {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 20, 'learning_rate': 0.001, 'num_rnn_layers': 1, 'rnn_units': 64}\n",
      "✅ Mejor accuracy en CV: 0.7503702516734584\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "params",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "mean_test_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "std_test_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rank_test_score",
         "rawType": "int32",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "694f2171-5484-4026-8a21-4380a4a0e53f",
       "rows": [
        [
         "8",
         "{'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 20, 'learning_rate': 0.001, 'num_rnn_layers': 1, 'rnn_units': 64}",
         "0.7503702516734584",
         "0.009392712514640965",
         "1"
        ],
        [
         "7",
         "{'batch_size': 32, 'dropout_rate': 0.5, 'epochs': 50, 'learning_rate': 0.001, 'num_rnn_layers': 1, 'rnn_units': 128}",
         "0.7459361467809114",
         "0.007104004664656638",
         "2"
        ],
        [
         "5",
         "{'batch_size': 32, 'dropout_rate': 0.5, 'epochs': 20, 'learning_rate': 0.001, 'num_rnn_layers': 1, 'rnn_units': 128}",
         "0.7458221098856731",
         "0.007124068703897788",
         "3"
        ],
        [
         "13",
         "{'batch_size': 64, 'dropout_rate': 0.5, 'epochs': 20, 'learning_rate': 0.001, 'num_rnn_layers': 1, 'rnn_units': 128}",
         "0.7452549488213887",
         "0.012800843549401066",
         "4"
        ],
        [
         "0",
         "{'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 20, 'learning_rate': 0.001, 'num_rnn_layers': 1, 'rnn_units': 64}",
         "0.7451416096365905",
         "0.008735265070299595",
         "5"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'batch_size': 64, 'dropout_rate': 0.2, 'epoch...</td>\n",
       "      <td>0.750370</td>\n",
       "      <td>0.009393</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'batch_size': 32, 'dropout_rate': 0.5, 'epoch...</td>\n",
       "      <td>0.745936</td>\n",
       "      <td>0.007104</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'batch_size': 32, 'dropout_rate': 0.5, 'epoch...</td>\n",
       "      <td>0.745822</td>\n",
       "      <td>0.007124</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'batch_size': 64, 'dropout_rate': 0.5, 'epoch...</td>\n",
       "      <td>0.745255</td>\n",
       "      <td>0.012801</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'batch_size': 32, 'dropout_rate': 0.2, 'epoch...</td>\n",
       "      <td>0.745142</td>\n",
       "      <td>0.008735</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               params  mean_test_score  \\\n",
       "8   {'batch_size': 64, 'dropout_rate': 0.2, 'epoch...         0.750370   \n",
       "7   {'batch_size': 32, 'dropout_rate': 0.5, 'epoch...         0.745936   \n",
       "5   {'batch_size': 32, 'dropout_rate': 0.5, 'epoch...         0.745822   \n",
       "13  {'batch_size': 64, 'dropout_rate': 0.5, 'epoch...         0.745255   \n",
       "0   {'batch_size': 32, 'dropout_rate': 0.2, 'epoch...         0.745142   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "8         0.009393                1  \n",
       "7         0.007104                2  \n",
       "5         0.007124                3  \n",
       "13        0.012801                4  \n",
       "0         0.008735                5  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"🏆 Mejores parámetros:\", grid_result_rnn.best_params_)\n",
    "print(\"✅ Mejor accuracy en CV:\", grid_result_rnn.best_score_)\n",
    "\n",
    "results = pd.DataFrame(grid_result_rnn.cv_results_)\n",
    "results.to_csv('data/processed/resultados_rnn.csv')\n",
    "results[['params', 'mean_test_score', 'std_test_score', 'rank_test_score']].sort_values('rank_test_score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bce8e9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 1s 17ms/step\n"
     ]
    }
   ],
   "source": [
    "yhat_probs = grid_result_rnn.predict(X_test)\n",
    "df_pred = pd.DataFrame(yhat_probs, columns=['prediccion'])\n",
    "df_pred.to_csv('data/processed/predicciones_rnn.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122f7cb7",
   "metadata": {},
   "source": [
    "### **Resultados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8c4fed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcAAAAHWCAYAAADgqln1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABKtElEQVR4nO3deVxU5fs38M8My7A5gyAM4AK4Qy6YJo57iZKiYW6RZrinoamoFd9ccSFpUXHfEjW11LLUTEVMrURE3BB3RdEUEBRxA1nO84cP83MEdEYHUO/Pu9d5Jefc55zrDMs11zX3mZFJkiSBiIhIMPLyDoCIiKg8MAESEZGQmACJiEhITIBERCQkJkAiIhISEyAREQmJCZCIiITEBEhEREJiAiQiIiExAb5GZDIZJk+eXG7nb9u2Ldq2bauzLjU1FT169IC9vT1kMhlmz56NPXv2QCaTYc+ePWUeo5ubG/r161fm530ZnDt3Dh06dIBKpYJMJsNvv/1m1ONfunQJMpkMkZGRRj3uq6y43wl6eQiZACMjIyGTybSLqakpKleujH79+uG///4rMr5t27aQyWTo0qVLkW2Fv/Tffvutdl3hH3iZTIb4+Pgi+/Tr1w82NjZ6x3v06FF89NFHqFq1KhQKBezs7ODj44MVK1YgPz9f7+OUh9GjR2PHjh0ICQnB6tWr8e6775b6Offv34/JkycjMzOz1M9lqAsXLuCTTz5B9erVYWFhAaVSiRYtWmDOnDl48OBBqZ47MDAQCQkJmD59OlavXo0mTZqU6vnKUr9+/SCTyaBUKot9HM+dO6f9nXz8d1Vf165dw+TJk3H06FEjREsvC9PyDqA8hYaGwt3dHdnZ2Thw4AAiIyPxzz//4MSJE7CwsCgyfuvWrYiPj0fjxo31PsfkyZOxZcuW545x2bJlGDp0KNRqNfr27YtatWrhzp07iI6OxsCBA3H9+nX873//e+7jG9POnTuLrNu9ezf8/f0xduxY7bratWvjwYMHMDc3L5U49u/fjylTpqBfv36wtbXV2XbmzBnI5eXzvO+PP/5Az549oVAo8PHHH6NevXp4+PAh/vnnH4wbNw6JiYlYsmRJqZz7wYMHiImJwVdffYXhw4eXyjlcXV3x4MEDmJmZlcrxn8XU1BT379/Hli1b0KtXL51ta9asgYWFBbKzs5/r2NeuXcOUKVPg5uYGLy8vvfcr7neCXh5CJ8COHTtqnwUPGjQIlSpVwsyZM7F58+Yiv0DVqlXDnTt3MGXKFGzevFmv43t5eWHr1q04fPgw3nzzTYPjO3DgAIYOHQqNRoNt27ahQoUK2m2jRo3CoUOHcOLECYOPW1qKS2hpaWlFkpBcLi/2CUZZUCgU5XLepKQkBAQEwNXVFbt374azs7N2W1BQEM6fP48//vij1M5/48YNACjyvTAmmUxWbt9X4NH3tkWLFli3bl2R39+1a9fCz88Pv/zyS5nEcv/+fVhZWZXakzwyDiFboCVp1aoVgEdtqidVqFABo0ePxpYtW3D48GG9jjdixAhUrFjxuV+XmzJlCmQyGdasWaOT/Ao1adLkqa9nXb58GZ9++inq1KkDS0tL2Nvbo2fPnrh06ZLOuNzcXEyZMgW1atWChYUF7O3t0bJlS0RFRWnHpKSkoH///qhSpQoUCgWcnZ3h7++vc6zHX+8obDNLkoT58+dr208ASnwNMDY2Fp06dULFihVhbW2NBg0aYM6cOdrtx48fR79+/bTtQycnJwwYMAAZGRnaMZMnT8a4ceMAAO7u7trzFsZZ3GuAFy9eRM+ePWFnZwcrKys0a9asSDIqjHn9+vWYPn06qlSpAgsLC7Rr1w7nz58v8XtQKDw8HHfv3sXy5ct1kl+hmjVrYuTIkdqv8/LyMHXqVNSoUQMKhQJubm743//+h5ycHJ393Nzc0LlzZ/zzzz9o2rQpLCwsUL16daxatUrnMXF1dQUAjBs3DjKZDG5ubgAetQ4L//24yZMna79fhaKiotCyZUvY2trCxsYGderU0ek+lPQa4O7du9GqVStYW1vD1tYW/v7+OHXqVLHnO3/+vLZyV6lU6N+/P+7fv1/yA/uE3r17488//9Rpf8fFxeHcuXPo3bt3kfE3b97E2LFjUb9+fdjY2ECpVKJjx444duyYdsyePXvw1ltvAQD69++v/ZkqvM62bduiXr16iI+PR+vWrWFlZaV9XJ58DTAwMBAWFhZFrt/X1xcVK1bEtWvX9L5WenFCV4BPKvwjWbFixWK3jxw5ErNmzcLkyZP1qgKVSiVGjx6NiRMnGlwF3r9/H9HR0WjdujWqVaum936Pi4uLw/79+xEQEIAqVarg0qVLWLhwIdq2bYuTJ0/CysoKwKM/PmFhYRg0aBCaNm2KrKwsHDp0CIcPH0b79u0BAN27d0diYiJGjBgBNzc3pKWlISoqCsnJycX+AW3dujVWr16Nvn37on379vj444+fGmtUVBQ6d+4MZ2dnjBw5Ek5OTjh16hS2bt2qTQxRUVG4ePEi+vfvDycnJ23LMDExEQcOHIBMJkO3bt1w9uxZrFu3DrNmzUKlSpUAAA4ODsWeNzU1Fc2bN8f9+/fx2Wefwd7eHitXrsR7772HjRs34v3339cZ//XXX0Mul2Ps2LG4ffs2wsPD0adPH8TGxj71+rZs2YLq1aujefPmTx1XaNCgQVi5ciV69OiBMWPGIDY2FmFhYTh16hQ2bdqkM/b8+fPo0aMHBg4ciMDAQPzwww/o168fGjdujDfeeAPdunWDra0tRo8ejQ8//BCdOnUy6DVoAEhMTETnzp3RoEEDhIaGQqFQ4Pz58/j333+fut+uXbvQsWNHVK9eHZMnT8aDBw8wd+5ctGjRAocPHy7ys9OrVy+4u7sjLCwMhw8fxrJly+Do6IiZM2fqFWe3bt0wdOhQ/PrrrxgwYACAR9Vf3bp1i/39u3jxIn777Tf07NkT7u7uSE1NxeLFi9GmTRucPHkSLi4u8PDwQGhoKCZOnIghQ4Zonyg//r3MyMhAx44dERAQgI8++ghqtbrY+ObMmYPdu3cjMDAQMTExMDExweLFi7Fz506sXr0aLi4uel0nGYkkoBUrVkgApF27dkk3btyQrly5Im3cuFFycHCQFAqFdOXKFZ3xbdq0kd544w1JkiRpypQpEgApPj5ekiRJSkpKkgBI33zzjXb8X3/9JQGQNmzYIGVmZkoVK1aU3nvvPe32wMBAydra+qkxHjt2TAIgjRw5Uu/rAiBNmjRJ+/X9+/eLjImJiZEASKtWrdKua9iwoeTn51ficW/dulXkGovTpk0bqU2bNkViCgoK0llX+Pj89ddfkiRJUl5enuTu7i65urpKt27d0hlbUFDw1OtZt26dBEDat2+fdt0333wjAZCSkpKKjHd1dZUCAwO1X48aNUoCIP3999/adXfu3JHc3d0lNzc3KT8/XydmDw8PKScnRzt2zpw5EgApISGh2MdEkiTp9u3bEgDJ39+/xDGPO3r0qARAGjRokM76sWPHSgCk3bt361zPk9eflpYmKRQKacyYMdp1xf2cStKjn0VXV9ciMUyaNEl6/M/DrFmzJADSjRs3Soy78BwrVqzQrvPy8pIcHR2ljIwM7bpjx45Jcrlc+vjjj4ucb8CAATrHfP/99yV7e/sSz/n4dRT+TvXo0UNq166dJEmSlJ+fLzk5OUlTpkwp9jHIzs7Wfo8fvw6FQiGFhoZq18XFxRW5tkJt2rSRAEiLFi0qdtuTvxM7duyQAEjTpk2TLl68KNnY2Ehdu3Z95jWS8QndAvXx8YGDgwOqVq2KHj16wNraGps3b0aVKlVK3GfkyJGoWLEipkyZotc5VCoVRo0ahc2bN+PIkSN6x5aVlQUAxbY+9WVpaan9d25uLjIyMlCzZk3Y2trqtHFtbW2RmJiIc+fOlXgcc3Nz7NmzB7du3XrueEpy5MgRJCUlYdSoUUVeo3q8Dff49WRnZyM9PR3NmjUDAL3b0k/atm0bmjZtipYtW2rX2djYYMiQIbh06RJOnjypM75///46r+sUVgMXL14s8RyGfi+3bdsGAAgODtZZP2bMGAAo0p719PTUxgE8qnbr1Knz1JgMVfh9+f3331FQUKDXPtevX8fRo0fRr18/2NnZadc3aNAA7du3117n44YOHarzdatWrZCRkaF9DPXRu3dv7NmzBykpKdi9ezdSUlKKbX8Cj143LJwUlZ+fj4yMDG1715CfKYVCgf79++s1tkOHDvjkk08QGhqKbt26wcLCAosXL9b7XGQ8QifA+fPnIyoqChs3bkSnTp2Qnp7+zEkSz5PQRo4cCVtbW4NeC1QqlQCAO3fu6L3Pkx48eICJEydqb5+oVKkSHBwckJmZidu3b2vHhYaGIjMzE7Vr10b9+vUxbtw4HD9+XLtdoVBg5syZ+PPPP6FWq9G6dWuEh4cjJSXluWN7XOFrrvXq1XvquJs3b2LkyJFQq9WwtLSEg4MD3N3dAUDnegxx+fJl1KlTp8h6Dw8P7fbHPdmOLmyXP+2JgaHfy8uXL0Mul6NmzZo6652cnGBra/vMmArjMuaTlQ8++AAtWrTAoEGDoFarERAQgPXr1z81GRbGWdLjm56ejnv37umsf57H90mdOnVChQoV8PPPP2PNmjV46623ijyWhQoKCjBr1izUqlVL53fk+PHjBv1MVa5c2aAJL99++y3s7Oxw9OhRREREwNHRUe99yXiEToBNmzaFj48Punfvjs2bN6NevXro3bs37t69+9T9ChNaaVaBNWvWhKmpKRISEvQaX5wRI0Zg+vTp6NWrF9avX4+dO3ciKioK9vb2On+4WrdujQsXLuCHH35AvXr1sGzZMrz55ptYtmyZdsyoUaNw9uxZhIWFwcLCAhMmTICHh4dBVe2L6tWrF5YuXap9jWfnzp3Yvn07AOhdlbwoExOTYtdLklTiPkqlEi4uLgbP2H1yEooxY3rWOZ68v9TS0hL79u3Drl270LdvXxw/fhwffPAB2rdvb9R7UV/kWgopFAp069YNK1euxKZNm0qs/gBgxowZCA4ORuvWrfHjjz9ix44diIqKwhtvvGHQz9Tj3Ql9HDlyBGlpaQDwQr/j9GKEToCPMzExQVhYGK5du4Z58+Y9dWxhQvv999/1TgCF7T19k6aVlRXeeecd7Nu3D1euXNFrnydt3LgRgYGB+O6779CjRw+0b98eLVu2LPYGcTs7O/Tv3x/r1q3DlStX0KBBgyIVa40aNTBmzBjs3LkTJ06cwMOHD/Hdd989V2xPHhfAUxPErVu3EB0djS+//BJTpkzB+++/j/bt26N69epFxuqbOIBH966dOXOmyPrTp09rtxtD586dceHCBcTExOgVU0FBQZGWdGpqKjIzM40WE/Cowiru5+HJKhN4dPtKu3bt8P333+PkyZOYPn06du/ejb/++qvYYxfGWdLjW6lSJVhbW7/YBZSgd+/eOHLkCO7cuYOAgIASx23cuBFvv/02li9fjoCAAHTo0AE+Pj5FHhNDfqae5d69e+jfvz88PT0xZMgQhIeHIy4uzmjHJ/0xAT6mbdu2aNq0KWbPnv3MG2YLE1poaKhex348aer7bhKTJk2CJEno27dvsVVpfHw8Vq5cWeL+JiYmRZ45z507t8gz9sdvIwAevQZWs2ZN7ZT7+/fvF3k8atSogQoVKhSZlv883nzzTbi7u2P27NlF/vAUxl9YGTx5PbNnzy5yvMI/qvq8E0ynTp1w8OBBncR07949LFmyBG5ubvD09DTgSkr2+eefw9raGoMGDUJqamqR7RcuXNDe8tGpUycARa/t+++/BwD4+fkZJSbg0ffx9u3bOi3v69evF5lpevPmzSL7Ft4QXtLPgLOzM7y8vLBy5Uqd78WJEyewc+dO7XWWhrfffhtTp07FvHnz4OTkVOK44n5HNmzYUOQdoQz5mXqWL774AsnJyVi5ciW+//57uLm5ITAw0Ci/S2QY3gbxhHHjxqFnz56IjIws8oL841QqFUaOHKl3RQf8320Ux44d0+uZb/PmzTF//nx8+umnqFu3rs47wezZswebN2/GtGnTSty/c+fOWL16NVQqFTw9PRETE4Ndu3bB3t5eZ5ynpyfatm2Lxo0bw87ODocOHcLGjRu17xhy9uxZtGvXDr169YKnpydMTU2xadMmpKamPvXZtb7kcjkWLlyILl26wMvLC/3794ezszNOnz6NxMRE7NixA0qlUvvaY25uLipXroydO3ciKSmpyPEK36nnq6++QkBAAMzMzNClS5diH/Mvv/wS69atQ8eOHfHZZ5/Bzs4OK1euRFJSEn755RejvWtMjRo1sHbtWnzwwQfw8PDQeSeY/fv3Y8OGDdr7Exs2bIjAwEAsWbIEmZmZaNOmDQ4ePIiVK1eia9euePvtt40SEwAEBATgiy++wPvvv4/PPvsM9+/fx8KFC1G7dm2dSSChoaHYt28f/Pz84OrqirS0NCxYsABVqlTRmUD0pG+++QYdO3aERqPBwIEDtbdBqFSqUn3fWrlcjvHjxz9zXOfOnREaGor+/fujefPmSEhIwJo1a4p0FmrUqAFbW1ssWrQIFSpUgLW1Nby9vbWvQetr9+7dWLBgASZNmqS9LWPFihVo27YtJkyYgPDwcIOORy+o/Caglp/C2yDi4uKKbMvPz5dq1Kgh1ahRQ8rLy5MkSfc2iMfdunVLUqlUT70N4kmF072fdRvE4+Lj46XevXtLLi4ukpmZmVSxYkWpXbt20sqVK3WmcOOJ2yBu3bol9e/fX6pUqZJkY2Mj+fr6SqdPny5yK8C0adOkpk2bSra2tpKlpaVUt25dafr06dLDhw8lSZKk9PR0KSgoSKpbt65kbW0tqVQqydvbW1q/fr1OnM97G0Shf/75R2rfvr1UoUIFydraWmrQoIE0d+5c7farV69K77//vmRrayupVCqpZ8+e0rVr14pctyRJ0tSpU6XKlStLcrlc55aIJ69dkiTpwoULUo8ePSRbW1vJwsJCatq0qbR169ZiY37ye1rc1P+nOXv2rDR48GDJzc1NMjc3lypUqCC1aNFCmjt3rpSdna0dl5ubK02ZMkVyd3eXzMzMpKpVq0ohISE6Ywqvp7hbWJ78XpR0G4QkSdLOnTulevXqSebm5lKdOnWkH3/8schtENHR0ZK/v7/k4uIimZubSy4uLtKHH34onT179pmPxa5du6QWLVpIlpaWklKplLp06SKdPHlSZ0zh+Z68zaLwd7W4W1oep8+tRSXdBjFmzBjJ2dlZsrS0lFq0aCHFxMQU+7P8+++/S56enpKpqanOdZb096FwW+FxsrKyJFdXV+nNN9+UcnNzdcaNHj1aksvlUkxMzFOvgYxLJkkGvLpMRET0muBrgEREJCQmQCIiEhITIBERCYkJkIiIhMQESEREQmICJCIiITEBEhGRkF7Ld4Ix3rv2ERG9HIx9w7Zlo+FGO9aDI09//+SX1WuZAAGgStDv5R0CCeDqfH9cTH/6+8YSGUUlC+MeT8YGIB8BIiIS0mtbARIR0VMY8SOeXlWsAImIRCSTG28x0J07dzBq1Ci4urrC0tISzZs31/lMREmSMHHiRDg7O8PS0hI+Pj5FPh/z5s2b6NOnD5RKJWxtbTFw4MBnfpj5k5gAiYioTA0aNAhRUVFYvXo1EhIStB9EXPg5jOHh4YiIiMCiRYsQGxsLa2tr+Pr66nwuaZ8+fZCYmIioqChs3boV+/btw5AhQwyK47X8NAgZOAmGygYnwVBZcTfyJBjLt4KNdqwHcd/rP/bBA1SoUAG///67zoc7N27cGB07dsTUqVPh4uKCMWPGYOzYsQCA27dvQ61WIzIyEgEBATh16hQ8PT0RFxeHJk2aAAC2b9+OTp064erVq3BxcdErFlaAREQiMmILNCcnB1lZWTpLSZ9wn5eXh/z8fFhY6CZ0S0tL/PPPP0hKSkJKSgp8fHy021QqFby9vRETEwMAiImJga2trTb5AYCPjw/kcjliY2P1fgiYAImI6IWEhYVBpVLpLGFhYcWOrVChAjQaDaZOnYpr164hPz8fP/74I2JiYnD9+nWkpKQAANRqtc5+arVauy0lJQWOjo46201NTWFnZ6cdow8mQCIiEclkRltCQkJw+/ZtnSUkJKTEU69evRqSJKFy5cpQKBSIiIjAhx9+CLm8bFMSEyARkYiM2AJVKBRQKpU6i0KhKPHUNWrUwN69e3H37l1cuXIFBw8eRG5uLqpXrw4nJycAQGpqqs4+qamp2m1OTk5IS0vT2Z6Xl4ebN29qx+iDCZCIiMqFtbU1nJ2dcevWLezYsQP+/v5wd3eHk5MToqOjteOysrIQGxsLjUYDANBoNMjMzER8fLx2zO7du1FQUABvb2+9z88b4YmIRFSON8Lv2LEDkiShTp06OH/+PMaNG4e6deuif//+kMlkGDVqFKZNm4ZatWrB3d0dEyZMgIuLC7p27QoA8PDwwLvvvovBgwdj0aJFyM3NxfDhwxEQEKD3DFCACZCISEzl+F6gha8RXr16FXZ2dujevTumT58OMzMzAMDnn3+Oe/fuYciQIcjMzETLli2xfft2nZmja9aswfDhw9GuXTvI5XJ0794dERERBsXB+wCJXgDvA6SyYvT7AJv/z2jHerB/htGOVZZYARIRiYjvBcoESEQkJH4cEmeBEhGRmFgBEhGJiC1QJkAiIiGxBcoWKBERiYkVIBGRiFgBMgESEQlJztcA+RSAiIiExAqQiEhEbIEyARIRCYm3QbAFSkREYmIFSEQkIrZAmQCJiITEFihboEREJCZWgEREImILlAmQiEhIbIGyBUpERGJiBUhEJCK2QJkAiYiExBYoW6BERCQmVoBERCJiC5QJkIhISGyBsgVKRERiYgVIRCQitkCZAImIhMQEyBYoERGJiRUgEZGIOAmGCZCISEhsgbIFSkREYmIFSEQkIrZAmQCJiITEFihboEREJCZWgEREImILlAmQiEhEMiZAtkCJiEhMrACJiATECpAJkIhITMx/bIESEZGYWAESEQmILVAmQCIiITEBsgVKRESCYgVIRCQgVoBMgEREQmICZAuUiIjKUH5+PiZMmAB3d3dYWlqiRo0amDp1KiRJ0o6RJAkTJ06Es7MzLC0t4ePjg3Pnzukc5+bNm+jTpw+USiVsbW0xcOBA3L1716BYmACJiEQkM+JigJkzZ2LhwoWYN28eTp06hZkzZyI8PBxz587VjgkPD0dERAQWLVqE2NhYWFtbw9fXF9nZ2doxffr0QWJiIqKiorB161bs27cPQ4YMMSgWtkCJiARUXi3Q/fv3w9/fH35+fgAANzc3rFu3DgcPHgTwqPqbPXs2xo8fD39/fwDAqlWroFar8dtvvyEgIACnTp3C9u3bERcXhyZNmgAA5s6di06dOuHbb7+Fi4uLXrGwAiQioheSk5ODrKwsnSUnJ6fYsc2bN0d0dDTOnj0LADh27Bj++ecfdOzYEQCQlJSElJQU+Pj4aPdRqVTw9vZGTEwMACAmJga2trba5AcAPj4+kMvliI2N1TtuJkAiIgHJZDKjLWFhYVCpVDpLWFhYsef98ssvERAQgLp168LMzAyNGjXCqFGj0KdPHwBASkoKAECtVuvsp1artdtSUlLg6Oios93U1BR2dnbaMfpgC5SISEDGbIGGhIQgODhYZ51CoSh27Pr167FmzRqsXbsWb7zxBo4ePYpRo0bBxcUFgYGBRotJH0yARET0QhQKRYkJ70njxo3TVoEAUL9+fVy+fBlhYWEIDAyEk5MTACA1NRXOzs7a/VJTU+Hl5QUAcHJyQlpams5x8/LycPPmTe3++mALlIhIQMZsgRri/v37kMt1U4+JiQkKCgoAAO7u7nByckJ0dLR2e1ZWFmJjY6HRaAAAGo0GmZmZiI+P147ZvXs3CgoK4O3trXcsrACJiERUTvfBd+nSBdOnT0e1atXwxhtv4MiRI/j+++8xYMCAR2HJZBg1ahSmTZuGWrVqwd3dHRMmTICLiwu6du0KAPDw8MC7776LwYMHY9GiRcjNzcXw4cMREBCg9wxQgAmQiIjK0Ny5czFhwgR8+umnSEtLg4uLCz755BNMnDhRO+bzzz/HvXv3MGTIEGRmZqJly5bYvn07LCwstGPWrFmD4cOHo127dpDL5ejevTsiIiIMikUmPX77/WtCBqBK0O/lHQYJ4Op8f1xMz372QKIX5F7J4tmDDFCp309GO1Z6ZIDRjlWWWAESEQmI7wXKSTBERCQoVoBERAJiBcgESEQkJuY/tkCJiEhMrACJiATEFigTIBGRkJgA2QIlIiJBsQIkIhIQK0AmQCIiITEBsgVKRESCYgVIRCQiFoBMgEREImILlC1QIiISFCtAIiIBsQJkAiQiEhITIFugREQkKFaAREQiYgHIBEhEJCK2QNkCJSIiQbECJCISECtAJsDX2v7Q9qhqb1Vk/cq9SRi//jgA4E33ivi8iwcauVVEfoGEk//dxkfzYpCdWwAAsLUyQ2iv+vCp54QCCfjz6DVM2piA+zn5ZXot9HLbumk9tm5aj7Tr1wAA1dxroE//T/CWpiUA4GFODpbM+w57d21Hbu5DNG7aHMPHfoWKdvY6x9n5x+/49efV+O/KZVhZWaPVOx0wfMz/yvx6RMAEyAT4Wuscvhcm8v/7Ia/jrMS6z5pj65H/ADxKfquDNJi/4xwmbkhAXr4EzypKFEj/d4yIfo3hqLJA73kxMDOR4buPGmHmh14YERlf1pdDL7FKDo4YMHQkKletBkmSsOvPLZjy5UjMW/Ez3KrXxOKIb3Aw5m98Ne0bWFtXwPzvwzD1f8H4ftFK7TF++WkVfl23CoOCglHHsz6ysx8g9f8nVKLSwAT4Grt596HO15+2V+PSjbs4cC4DADCpez2s2HMRC6LOacdcTLur/XdNtQ3efkMNv5l7cTw5EwAwcUMCVg5rhmmbEpF6O7v0L4JeCc1attX5ut8nI7B103qcTjwOB0c1dmzdhC8mfw2vxt4AgDFfhWJw7644deI4POo1wJ2sLKxaMh+TwyPQqIm39jjVa9Yuy8sQCivAck6A6enp+OGHHxATE4OUlBQAgJOTE5o3b45+/frBwcGhPMN7rZiZyNCtaRUs3X0BAGBvY4433e2wKe4qNo1pBddKVriQehfhW04h7sJNAEDj6nbIvP9Qm/wA4O/TN1AgSWjkVhHbj10vj0uhl1x+fj7+/msncrIfwKNeQ5w7cxJ5eXk6ia2qqzsc1c44deIYPOo1wJG4GBRIBci4kYbBvbviwf178KjvhSHDx8BB7VSOV/MaY/4rv1mgcXFxqF27NiIiIqBSqdC6dWu0bt0aKpUKERERqFu3Lg4dOvTM4+Tk5CArK0tnQU5OGVzBq8W3oTOUlmbYcOAKAKBaJWsAQHCnulj372X0nX8AJ67cxroRzeHm8Gibg1KBjDu6VWR+gYTM+7lwUCrK9gLopZd04Ry6+jRDl7ffwtxvpmPCjFlwda+BWxkZMDMzg00Fpc54Wzs73LqZDgC4fu0qpIIC/LRqGT4ZOQ5fTfsOd7JuI2TUJ8jNzS2PyyEBlFsFOGLECPTs2ROLFi0qUopLkoShQ4dixIgRiImJeepxwsLCMGXKFN2VkyYBaGTkiF9tARpX/HUyTdu2LHxpcM2/l7D+QDIAIPHqbbSoUwkfaKph5uZT5RUqvaKqVHPDgsj1uHf3Lv7+KwrfTZ+A8HnL9dpXKpCQl5eHYaO+QGPv5gCALyd/jd7vtcOxwwfRxLtFaYYuJLZAyzEBHjt2DJGRkcV+E2QyGUaPHo1GjZ6dxEJCQhAcHKyzTqVQAMHbjRbrq66ynSVa1nXAkKUHtevSsh5VyWev39EZez7lLirbWQIAbmTlwL6Cuc52E7kMtlZmuJHFKpt0mZmZwaVKNQBArbqeOHs6Eb9tWIM27XyRm5uLu3eydKrAzJs3UdGuEgDArtKj/1dzr6HdblvRDkqVLW6kppThVYiDCbAcW6BOTk44ePBgidsPHjwItVr9zOMoFAoolUqdBQq25x7Xq1k1pN/JQfSJVO26Kxn3kZL5ADXUNjpj3R2t8d/NBwCA+Is3YWtljvpVVdrtLWpXglwmw5FLt8omeHplSQUFyH2Yi1p1PGFqaoqjh/7v9/3K5UtIS70Oj3oNAQCe9b0AAFeTL2nH3Mm6jazbmXBUO5dl2CSQcqsAx44diyFDhiA+Ph7t2rXTJrvU1FRER0dj6dKl+Pbbb8srvNeGTAb00lTDxtgryH/8/gYAi3adR7BfXZz87zZOXs1CD++qqKmugKHL4gAA51Pv4q/EVMzs7YX//XQMpiZyTO3VAJvj/+MMUNLxw8I5eEvTEg5qJzy4fx9/7dyG40cOYfr3C2FtUwG+nd/HkrnfooJSCStrGyyY9TU86jWER70GAB61TzWt3sai2TMx8ouJsLK2xopFEahSzQ0NG79Vzlf3emIBWI4JMCgoCJUqVcKsWbOwYMEC5Oc/urHaxMQEjRs3RmRkJHr16lVe4b02WtVxQBU7K/wcc7nItuV/XYTC1ASTuteHrZUZTv6Xhd7z9uNy+n3tmM8i4zG1VwOs+6wFCiQJfx69hokbEsryEugVkJl5E99MHY9bGTdgZW0D95q1Mf37hXizqQYA8Mln4yCTyzH1qzE6N8I/buyEaVgc8Q0mjhsOmUyO+l6NMf37hTA1NSuPS3rtsQUKyCRJkp49rHTl5uYiPf3RbLBKlSrBzOzFfuBlAKoE/W6EyIie7up8f1xMZzVMpc+9koVRj1drnPHmSZz75l2jHassvRQ3wpuZmcHZmX1+IqKywgLwJUmARERUttgC5cchERGRoFgBEhEJiAUgEyARkZDkcmZAtkCJiEhIrACJiATEFigrQCIiEhQrQCIiAfE2CCZAIiIhMf+xBUpERIJiBUhEJCC2QJkAiYiExATIFigREZUhNzc3yGSyIktQUBAAIDs7G0FBQbC3t4eNjQ26d++O1NRUnWMkJyfDz88PVlZWcHR0xLhx45CXl2dwLKwAiYgEVF4FYFxcnPbzXwHgxIkTaN++PXr27AkAGD16NP744w9s2LABKpUKw4cPR7du3fDvv/8CAPLz8+Hn5wcnJyfs378f169fx8cffwwzMzPMmDHDoFiYAImIBFReLVAHBwedr7/++mvUqFEDbdq0we3bt7F8+XKsXbsW77zzDgBgxYoV8PDwwIEDB9CsWTPs3LkTJ0+exK5du6BWq+Hl5YWpU6fiiy++wOTJk2Fubq53LGyBEhHRC8nJyUFWVpbOkpOT88z9Hj58iB9//BEDBgyATCZDfHw8cnNz4ePjox1Tt25dVKtWDTExMQCAmJgY1K9fH2q1WjvG19cXWVlZSExMNChuJkAiIgHJZMZbwsLCoFKpdJawsLBnxvDbb78hMzMT/fr1AwCkpKTA3Nwctra2OuPUajVSUlK0Yx5PfoXbC7cZgi1QIiIBGbMFGhISguDgYJ11CoXimfstX74cHTt2hIuLi9FiMQQTIBERvRCFQqFXwnvc5cuXsWvXLvz666/adU5OTnj48CEyMzN1qsDU1FQ4OTlpxxw8eFDnWIWzRAvH6IstUCIiARmzBfo8VqxYAUdHR/j5+WnXNW7cGGZmZoiOjtauO3PmDJKTk6HRaAAAGo0GCQkJSEtL046JioqCUqmEp6enQTGwAiQiElB53ghfUFCAFStWIDAwEKam/5eGVCoVBg4ciODgYNjZ2UGpVGLEiBHQaDRo1qwZAKBDhw7w9PRE3759ER4ejpSUFIwfPx5BQUEGV6FMgEREVKZ27dqF5ORkDBgwoMi2WbNmQS6Xo3v37sjJyYGvry8WLFig3W5iYoKtW7di2LBh0Gg0sLa2RmBgIEJDQw2OQyZJkvRCV/ISkgGoEvR7eYdBArg63x8X07PLOwwSgHslC6Mer+mMPUY71sH/tTXascoSK0AiIgHxvUA5CYaIiATFCpCISEAsAJkAiYiExBYoW6BERCQoVoBERAJiAcgESEQkJLZA2QIlIiJBsQIkIhIQC0AmQCIiIbEFyhYoEREJihUgEZGAWAEyARIRCYn5jy1QIiISFCtAIiIBsQXKBEhEJCTmP7ZAiYhIUKwAiYgExBYoEyARkZCY/9gCJSIiQbECJCISkJwlIBMgEZGImP/YAiUiIkGxAiQiEhBngTIBEhEJSc78xxYoERGJiRUgEZGA2AJlAiQiEhLzH1ugREQkKFaAREQCkoElIBMgEZGAOAuULVAiIhIUK0AiIgFxFigTIBGRkJj/2AIlIiJBsQIkIhIQPw6JCZCISEjMf2yBEhGRoFgBEhEJiLNAmQCJiITE/McWKBERCYoVIBGRgDgLlAmQiEhITH9sgRIRkaCYAImIBCSTyYy2GOq///7DRx99BHt7e1haWqJ+/fo4dOiQdrskSZg4cSKcnZ1haWkJHx8fnDt3TucYN2/eRJ8+faBUKmFra4uBAwfi7t27BsXBBEhEJCC5zHiLIW7duoUWLVrAzMwMf/75J06ePInvvvsOFStW1I4JDw9HREQEFi1ahNjYWFhbW8PX1xfZ2dnaMX369EFiYiKioqKwdetW7Nu3D0OGDDEoFr4GSEREZWbmzJmoWrUqVqxYoV3n7u6u/bckSZg9ezbGjx8Pf39/AMCqVaugVqvx22+/ISAgAKdOncL27dsRFxeHJk2aAADmzp2LTp064dtvv4WLi4tesbACJCISkDFboDk5OcjKytJZcnJyij3v5s2b0aRJE/Ts2ROOjo5o1KgRli5dqt2elJSElJQU+Pj4aNepVCp4e3sjJiYGABATEwNbW1tt8gMAHx8fyOVyxMbG6v0YMAESEQlIJjPeEhYWBpVKpbOEhYUVe96LFy9i4cKFqFWrFnbs2IFhw4bhs88+w8qVKwEAKSkpAAC1Wq2zn1qt1m5LSUmBo6OjznZTU1PY2dlpx+jD4BaoiYkJrl+/XuTkGRkZcHR0RH5+vqGHJCKiV1hISAiCg4N11ikUimLHFhQUoEmTJpgxYwYAoFGjRjhx4gQWLVqEwMDAUo/1cQZXgJIkFbs+JycH5ubmLxwQERGVPmO2QBUKBZRKpc5SUgJ0dnaGp6enzjoPDw8kJycDAJycnAAAqampOmNSU1O125ycnJCWlqazPS8vDzdv3tSO0YfeFWBERASARw/asmXLYGNjo92Wn5+Pffv2oW7dunqfmIiIyo+hszeNpUWLFjhz5ozOurNnz8LV1RXAowkxTk5OiI6OhpeXFwAgKysLsbGxGDZsGABAo9EgMzMT8fHxaNy4MQBg9+7dKCgogLe3t96x6J0AZ82aBeBRBbho0SKYmJhot5mbm8PNzQ2LFi3S+8RERCSe0aNHo3nz5pgxYwZ69eqFgwcPYsmSJViyZAmAR0XWqFGjMG3aNNSqVQvu7u6YMGECXFxc0LVrVwCPKsZ3330XgwcPxqJFi5Cbm4vhw4cjICBA7xmggAEJMCkpCQDw9ttv49dff9W5Z4OIiF4t5fVxSG+99RY2bdqEkJAQhIaGwt3dHbNnz0afPn20Yz7//HPcu3cPQ4YMQWZmJlq2bInt27fDwsJCO2bNmjUYPnw42rVrB7lcju7du2s7lfqSSSW9qKen/Px8JCQkwNXV9aVJijIAVYJ+L+8wSABX5/vjYnr2swcSvSD3ShbPHmSAAT8lGO1YPwTUN9qxypLBk2BGjRqF5cuXA3iU/Fq3bo0333wTVatWxZ49e4wdHxERUakwOAFu2LABDRs2BABs2bIFly5dwunTpzF69Gh89dVXRg+QiIiMTy6TGW15VRmcADMyMrTTTLdt24aePXuidu3aGDBgABISjFdSExFR6THmjfCvKoMToFqtxsmTJ5Gfn4/t27ejffv2AID79+/rzAwlIiJ6mRn8TjD9+/dHr1694OzsDJlMpn2/ttjYWN4HSET0iiivWaAvE4MT4OTJk1GvXj1cuXIFPXv21N7tb2Jigi+//NLoARIRkfEx/z3nxyH16NEDAHQ+m6ms38ONiIjoRRj8GmB+fj6mTp2KypUrw8bGBhcvXgQATJgwQXt7BBERvdw4C/Q5EuD06dMRGRmJ8PBwnTe/rlevHpYtW2bU4IiIqHRwFuhzJMBVq1ZhyZIl6NOnj86sz4YNG+L06dNGDY6IiKi0GPwa4H///YeaNWsWWV9QUIDc3FyjBEVERKWLs0CfIwF6enri77//1n50RaGNGzeiUaNGRgvsRV2d71/eIZAgqhv5PRqJivNCb9pcDIPbf68hgxPgxIkTERgYiP/++w8FBQX49ddfcebMGaxatQpbt24tjRify4O88o6ARGBpClg0Gl7eYZAIjswr7wheOwY/CfD398eWLVuwa9cuWFtbY+LEiTh16hS2bNmifVcYIiJ6uRnzE+FfVc91H2CrVq0QFRVl7FiIiKiMlNcnwr9MDK4Aq1evjoyMjCLrMzMzUb16daMERUREVNoMrgAvXbqE/Pz8IutzcnLw33//GSUoIiIqXawADUiAmzdv1v57x44dUKlU2q/z8/MRHR0NNzc3owZHRESl41V+7c5Y9E6AXbt2BfDoQXvyfT/NzMzg5uaG7777zqjBERERlRa9E2BBQQEAwN3dHXFxcahUqVKpBUVERKWLLdDneA0wKSmpNOIgIqIyxA4o3wyAiIgE9Vz3ARIR0avtVf4YI2PRuwK8du1aacZBRERlSG7E5VWld+xvvPEG1q5dW5qxEBERlRm9E+D06dPxySefoGfPnrh582ZpxkRERKWMH4hrQAL89NNPcfz4cWRkZMDT0xNbtmwpzbiIiKgUyWUyoy2vKoMmwbi7u2P37t2YN28eunXrBg8PD5ia6h7i8OHDRg2QiIioNBg8C/Ty5cv49ddfUbFiRfj7+xdJgERE9PJ7hQs3ozEoey1duhRjxoyBj48PEhMT4eDgUFpxERFRKeI7wRiQAN99910cPHgQ8+bNw8cff1yaMREREZU6vRNgfn4+jh8/jipVqpRmPEREVAZe5ckrxqJ3AuQnwBMRvT6Y/17tm/iJiIieG6dwEhEJiJNgmACJiIQkAzMgW6BERCQkVoBERAJiC5QJkIhISEyAbIESEZGgWAESEQlIxhsBmQCJiETEFihboEREJChWgEREAmIHlBUgEZGQyusT4SdPngyZTKaz1K1bV7s9OzsbQUFBsLe3h42NDbp3747U1FSdYyQnJ8PPzw9WVlZwdHTEuHHjkJeXZ/BjwAqQiIjK1BtvvIFdu3Zpv378g9VHjx6NP/74Axs2bIBKpcLw4cPRrVs3/PvvvwAefTKRn58fnJycsH//fly/fh0ff/wxzMzMMGPGDIPiYAIkIhJQeU6CMTU1hZOTU5H1t2/fxvLly7F27Vq88847AIAVK1bAw8MDBw4cQLNmzbBz506cPHkSu3btglqthpeXF6ZOnYovvvgCkydPhrm5ud5xsAVKRCQgmcx4S05ODrKysnSWnJycEs997tw5uLi4oHr16ujTpw+Sk5MBAPHx8cjNzYWPj492bN26dVGtWjXExMQAAGJiYlC/fn2o1WrtGF9fX2RlZSExMdGgx4AJkIiIXkhYWBhUKpXOEhYWVuxYb29vREZGYvv27Vi4cCGSkpLQqlUr3LlzBykpKTA3N4etra3OPmq1GikpKQCAlJQUneRXuL1wmyHYAiUiEpDciJ8GERISguDgYJ11CoWi2LEdO3bU/rtBgwbw9vaGq6sr1q9fD0tLS6PFpA9WgEREAjJmC1ShUECpVOosJSXAJ9na2qJ27do4f/48nJyc8PDhQ2RmZuqMSU1N1b5m6OTkVGRWaOHXxb2u+DRMgEREVG7u3r2LCxcuwNnZGY0bN4aZmRmio6O128+cOYPk5GRoNBoAgEajQUJCAtLS0rRjoqKioFQq4enpadC52QIlIhJQec0CHTt2LLp06QJXV1dcu3YNkyZNgomJCT788EOoVCoMHDgQwcHBsLOzg1KpxIgRI6DRaNCsWTMAQIcOHeDp6Ym+ffsiPDwcKSkpGD9+PIKCgvSuOgsxARIRCcjQG9iN5erVq/jwww+RkZEBBwcHtGzZEgcOHICDgwMAYNasWZDL5ejevTtycnLg6+uLBQsWaPc3MTHB1q1bMWzYMGg0GlhbWyMwMBChoaEGxyKTJEky2pW9JGQAHhj+pgBEBrM0BSwaDS/vMEgAD47MM+rxlhy4bLRjDWnmarRjlSVWgEREAuJ7gTIBEhEJqbxaoC8TzgIlIiIhsQIkIhIQC0AmQCIiIbH9x8eAiIgExQqQiEhAMvZAmQCJiETE9McWKBERCYoVIBGRgHgfIBMgEZGQmP7YAiUiIkGxAiQiEhA7oEyARERC4m0QbIESEZGgWAESEQmI1Q8TIBGRkNgC5ZMAIiISFCtAIiIBsf5jAiQiEhJboGyBEhGRoFgBEhEJiNUPEyARkZDYAuWTACIiEhQrQCIiAbH+YwIkIhISO6BsgRIRkaBYARIRCUjOJigTIBGRiNgCZQuUiIgExQqQiEhAMrZAmQCJiETEFihboEREJChWgEREAuIsUCZAIiIhsQXKFigREQmKFSARkYBYATIBEhEJibdBsAVKRESCYgVIRCQgOQtAJkAiIhGxBcoWKBERCYoVIBGRgDgLlAmQiEhIbIGyBUpERIJiAiQiEpBcZrzleX399deQyWQYNWqUdl12djaCgoJgb28PGxsbdO/eHampqTr7JScnw8/PD1ZWVnB0dMS4ceOQl5dn+GPw/KETEdGrSmbE/55HXFwcFi9ejAYNGuisHz16NLZs2YINGzZg7969uHbtGrp166bdnp+fDz8/Pzx8+BD79+/HypUrERkZiYkTJxocA18DfI0tX7oY0VE7kZR0EQoLC3h5NcKo4LFwc6+uHbNx/c/4c9tWnDqZiHv37uHvmDgolUqd45w6mYjZ33+LxBMJkMtN4NO+A8Z+/iWsrK3L+pLoJWVjpcCkTzvjvXcawqGiDY6duYqx4RsRfzIZAOD/TkMM6tESjTyqwd7WGt4fhOH42f90jrFj6Ui0blJLZ93Sjf/gs+k/ldl1UNm4e/cu+vTpg6VLl2LatGna9bdv38by5cuxdu1avPPOOwCAFStWwMPDAwcOHECzZs2wc+dOnDx5Ert27YJarYaXlxemTp2KL774ApMnT4a5ubnecbACfI0dijuIDz7sg9Xr1mPx0hXIy8vD0MEDcf/+fe2Y7OwHaN6iFQYOHlrsMdLSUjFkYH9UrVYNP65bjwWLl+LC+XOY8FVIWV0GvQIWTuyNd5rVxYDxK9Gk1wzsijmNPxaNgIuDCgBgZWmO/UcvYHzEb089zvJf/oWbT4h2+Wr208fT85PJjLfk5OQgKytLZ8nJySnx3EFBQfDz84OPj4/O+vj4eOTm5uqsr1u3LqpVq4aYmBgAQExMDOrXrw+1Wq0d4+vri6ysLCQmJhr0GLACfI0tXLJc5+vQ6V/j7VYanDqZiMZN3gIAfPRxPwBA3MHYYo+xb88emJqZ4n/jJ0Euf/R8afykKejx/ntIvnwZ1VxdS+8C6JVgoTBD13Ze6Dl6Cf49fAEAMH3xNnRqXQ+De7bClAVbse6POABANWe7px7rQfZDpGbcKfWYCUadAxoWFoYpU6borJs0aRImT55cZOxPP/2Ew4cPIy4ursi2lJQUmJubw9bWVme9Wq1GSkqKdszjya9we+E2QzABCuTunUd/WJQqld77PMx9CDMzM23yAwCFwgIAcORwPBMgwdREDlNTE2Q/zNVZn52Ti+aNahh0rA86NUFAp7eQmpGFbftOIGzpn3iQnfvsHalchYSEIDg4WGedQqEoMu7KlSsYOXIkoqKiYGFhUVbhleiVb4EWV3rjKaW3qAoKChA+cwa8Gr2JWrVq671fU+9myEhPR+QPy5D78CGybt/GnFnfAQDS02+UVrj0Crl7PwcHjl1EyOCOcHZQQS6XIaDTW/Bu4A6nSspnH+D/+/nPQxjw1Sq8OyQC3/6wE7393sKKaYGlGLnY5DKZ0RaFQgGlUqmzFJcA4+PjkZaWhjfffBOmpqYwNTXF3r17ERERAVNTU6jVajx8+BCZmZk6+6WmpsLJyQkA4OTkVGRWaOHXhWP0fgwMGl3Grly5ggEDBjx1TFhYGFQqlc6CsLAyivDVMWPaFFw4dw7h384yaL+aNWth6vSvsSpyBbybeOGdNi1QuUpl2NtXgoxvJUH/34DxqyCTARd3Tsft2NkI+rAN1m8/hIICSe9j/PDrv9gVcwqJ56/hpz8PYeCE1fBv5wX3KpVKMXJxyYy46Ktdu3ZISEjA0aNHtUuTJk3Qp08f7b/NzMwQHR2t3efMmTNITk6GRqMBAGg0GiQkJCAtLU07JioqCkqlEp6engY9Bi91C/TmzZtYuXIlfvjhhxLHFFd6q4p55iGyGdNCsW/vHvyw8keoDXyGBACdOndBp85dkJGeDktLS0Amw+qVkahStWopREuvoqSr6egwaA6sLMyhtLFASnoWVn/dH0n/pT/3MeMSLgEAalR1QNLV5z8OvTwqVKiAevXq6ayztraGvb29dv3AgQMRHBwMOzs7KJVKjBgxAhqNBs2aNQMAdOjQAZ6enujbty/Cw8ORkpKC8ePHIygoqNiq82nKNQFu3rz5qdsvXrz4zGMoFIriL9rweyJfO5IkIWz6VOyOjsLyyNWoUuXFEpZ9pUfPxDf9uhHmCgWaaVoYI0x6jdzPfoj72Q9hW8ESPs098NXs35/7WA3rVAEApKTfNlZ49LiXtIEza9YsyOVydO/eHTk5OfD19cWCBQu0201MTLB161YMGzYMGo0G1tbWCAwMRGhoqMHnKtcE2LVrV8hkMkhSyW0Sttme34ypU/Dntq2YPXcBrK2skX7j0Wt2NhUqaF+ATr9xA+np6biS/Oh+rfPnzsLKyhrOzs5Q/f+ZWOvW/AivRo1gaWWFA/v3Y9Z34fhs9Jgi9wuSuHw0HpDJgLOX0lCjqgNmjO6Ks0mpWLX50dT1ikorVHWqCGfHRxOwars9mrWXmpGF1Iw7cK9SCR90bIId/yQiI/Me6teujPAx3fB3/DmcOHet3K7rdfayvBfonj17dL62sLDA/PnzMX/+/BL3cXV1xbZt21743DLpadmnlFWuXBkLFiyAv79/sduPHj2Kxo0bIz8/36DjygA8YAWIhm/UKXZ96LQw+L//6J0VFs6fi0UL5j11zFchn+PvvXtx//49uLtXx8f9B6DLe11LLe5XiaUpYNFoeHmHUe66t2+E0BHvobLaFjdv38fv0Ucxaf4WZN3NBgB81MUbS0P7Ftlv2qJtmL54G6qobfHD9EB41nCBtaU5rqbewubdx/D1sh24cy+7rC/npfTgSNHf0xcRe8F4lbV3Df1nlr9MyjUBvvfee/Dy8iqxdD127BgaNWqEgoICg47LBEhlhQmQyoqxE+DBi8ZLgE2rv5oJsFxboOPGjcO9e/dK3F6zZk389ddfZRgREZEYXo4GaPkq1wTYqlWrp263trZGmzZtyigaIiISyUt9GwQREZUSloBMgEREInpZZoGWp5f6nWCIiIhKCytAIiIB8RZrVoBERCQoVoBERAJiAcgESEQkJmZAtkCJiEhMrACJiATE2yCYAImIhMRZoGyBEhGRoFgBEhEJiAUgEyARkZiYAdkCJSIiMbECJCISEGeBMgESEQmJs0DZAiUiIkGxAiQiEhALQCZAIiIxMQOyBUpERGJiBUhEJCDOAmUCJCISEmeBsgVKRESCYgVIRCQgFoBMgEREYmIGZAuUiIjExAqQiEhAnAXKBEhEJCTOAmULlIiIBMUKkIhIQCwAmQCJiMTEDMgWKBERiYkVIBGRgDgLlAmQiEhInAXKFigREQmKFSARkYBYADIBEhGJiRmQLVAiIhITK0AiIgFxFigTIBGRkDgLlC1QIiIqQwsXLkSDBg2gVCqhVCqh0Wjw559/ardnZ2cjKCgI9vb2sLGxQffu3ZGamqpzjOTkZPj5+cHKygqOjo4YN24c8vLyDI6FCZCISEAyIy6GqFKlCr7++mvEx8fj0KFDeOedd+Dv74/ExEQAwOjRo7FlyxZs2LABe/fuxbVr19CtWzft/vn5+fDz88PDhw+xf/9+rFy5EpGRkZg4caLhj4EkSZLBe73kZAAeGP5kgMhglqaARaPh5R0GCeDBkXlGPd6ljGyjHcvN3uKF9rezs8M333yDHj16wMHBAWvXrkWPHj0AAKdPn4aHhwdiYmLQrFkz/Pnnn+jcuTOuXbsGtVoNAFi0aBG++OIL3LhxA+bm5nqflxUgERG9kJycHGRlZeksOTk5z9wvPz8fP/30E+7duweNRoP4+Hjk5ubCx8dHO6Zu3bqoVq0aYmJiAAAxMTGoX7++NvkBgK+vL7KysrRVpL6YAImIBCQz4n9hYWFQqVQ6S1hYWInnTkhIgI2NDRQKBYYOHYpNmzbB09MTKSkpMDc3h62trc54tVqNlJQUAEBKSopO8ivcXrjNEJwFSkQkIGPOAg0JCUFwcLDOOoVCUeL4OnXq4OjRo7h9+zY2btyIwMBA7N2713gB6YkJkIiIXohCoXhqwnuSubk5atasCQBo3Lgx4uLiMGfOHHzwwQd4+PAhMjMzdarA1NRUODk5AQCcnJxw8OBBneMVzhItHKMvtkCJiARUXrNAi1NQUICcnBw0btwYZmZmiI6O1m47c+YMkpOTodFoAAAajQYJCQlIS0vTjomKioJSqYSnp6dB52UFSEQkoPK6ET4kJAQdO3ZEtWrVcOfOHaxduxZ79uzBjh07oFKpMHDgQAQHB8POzg5KpRIjRoyARqNBs2bNAAAdOnSAp6cn+vbti/DwcKSkpGD8+PEICgoyqAoFmACJiKgMpaWl4eOPP8b169ehUqnQoEED7NixA+3btwcAzJo1C3K5HN27d0dOTg58fX2xYMEC7f4mJibYunUrhg0bBo1GA2trawQGBiI0NNTgWHgfINEL4H2AVFaMfR/g1VsPjXasKhX1v/fuZcIKkIhIQHwvUE6CISIiQbECJCISEAtAJkAiIiGxBcoWKBERCYoVIBGRgPiJ8EyARERiYv5jC5SIiMTECpCISEAsAJkAiYiExFmgbIESEZGgWAESEQmIs0CZAImIxMT8xxYoERGJiRUgEZGAWAAyARIRCYmzQNkCJSIiQbECJCISEGeBMgESEQmJLVC2QImISFBMgEREJCS2QImIBMQWKCtAIiISFCtAIiIBcRYoEyARkZDYAmULlIiIBMUKkIhIQCwAmQCJiMTEDMgWKBERiYkVIBGRgDgLlAmQiEhInAXKFigREQmKFSARkYBYADIBEhGJiRmQLVAiIhITK0AiIgFxFigTIBGRkDgLlC1QIiISlEySJKm8g6Dyl5OTg7CwMISEhEChUJR3OPQa488avSyYAAkAkJWVBZVKhdu3b0OpVJZ3OPQa488avSzYAiUiIiExARIRkZCYAImISEhMgAQAUCgUmDRpEiclUKnjzxq9LDgJhoiIhMQKkIiIhMQESEREQmICJCIiITEBEhGRkJgACfPnz4ebmxssLCzg7e2NgwcPlndI9Brat28funTpAhcXF8hkMvz222/lHRIJjglQcD///DOCg4MxadIkHD58GA0bNoSvry/S0tLKOzR6zdy7dw8NGzbE/PnzyzsUIgC8DUJ43t7eeOuttzBv3jwAQEFBAapWrYoRI0bgyy+/LOfo6HUlk8mwadMmdO3atbxDIYGxAhTYw4cPER8fDx8fH+06uVwOHx8fxMTElGNkRESljwlQYOnp6cjPz4dardZZr1arkZKSUk5RERGVDSZAIiISEhOgwCpVqgQTExOkpqbqrE9NTYWTk1M5RUVEVDaYAAVmbm6Oxo0bIzo6WruuoKAA0dHR0Gg05RgZEVHpMy3vAKh8BQcHIzAwEE2aNEHTpk0xe/Zs3Lt3D/379y/v0Og1c/fuXZw/f177dVJSEo4ePQo7OztUq1atHCMjUfE2CMK8efPwzTffICUlBV5eXoiIiIC3t3d5h0WvmT179uDtt98usj4wMBCRkZFlHxAJjwmQiIiExNcAiYhISEyAREQkJCZAIiISEhMgEREJiQmQiIiExARIRERCYgIkIiIhMQESEZGQmACJysClS5cgk8lw9OhRAI/eFUUmkyEzM7Nc4yISGRMgvfIkSYKPjw98fX2LbFuwYAFsbW1x9erVcoisZM2bN8f169ehUqn0Gt+2bVuMGjWqdIMiEgwTIL3yZDIZVqxYgdjYWCxevFi7PikpCZ9//jnmzp2LKlWqGOVcubm5RjmOubk5nJycIJPJjHI8IjIcEyC9FqpWrYo5c+Zg7NixSEpKgiRJGDhwIDp06IC+ffsWu49MJsPChQvRsWNHWFpaonr16ti4caN2e2Hb8ueff0abNm1gYWGBNWvWAACWLVsGDw8PWFhYoG7duliwYIHOsQ8ePIhGjRrBwsICTZo0wZEjR3S2F9cC/ffff9G2bVtYWVmhYsWK8PX1xa1bt9CvXz/s3bsXc+bMgUwmg0wmw6VLl4zzwBGJTCJ6jfj7+0tt27aVIiIiJAcHByktLa3EsQAke3t7aenSpdKZM2ek8ePHSyYmJtLJkyclSZKkpKQkCYDk5uYm/fLLL9LFixela9euST/++KPk7OysXffLL79IdnZ2UmRkpCRJknTnzh3JwcFB6t27t3TixAlpy5YtUvXq1SUA0pEjRyRJkqS//vpLAiDdunVLkiRJOnLkiKRQKKRhw4ZJR48elU6cOCHNnTtXunHjhpSZmSlpNBpp8ODB0vXr16Xr169LeXl5pfo4EomACZBeK6mpqVKlSpUkuVwubdq06aljAUhDhw7VWeft7S0NGzZMkqT/S4CzZ8/WGVOjRg1p7dq1OuumTp0qaTQaSZIkafHixZK9vb304MED7faFCxc+NQF++OGHUosWLUqMtU2bNtLIkSOfej1EZBh+IC69VhwdHfHJJ5/gt99+Q9euXZ85XvPEJ99rNBrtTM1CTZo00f773r17uHDhAgYOHIjBgwdr1+fl5WkntJw6dQoNGjSAhYVFied50tGjR9GzZ89nxktExsMESK8dU1NTmJoa70fb2tpa+++7d+8CAJYuXVrkQ4NNTEye+xyWlpbPvS8RPR9OgiGhHThwoMjXHh4eJY5Xq9VwcXHBxYsXUbNmTZ3F3d0dAODh4YHjx48jOzu7xPM8qUGDBoiOji5xu7m5OfLz8/W5JCLSExMgCW3Dhg344YcfcPbsWUyaNAkHDx7E8OHDn7rPlClTEBYWhoiICJw9exYJCQlYsWIFvv/+ewBA7969IZPJMHjwYJw8eRLbtm3Dt99++9RjhoSEIC4uDp9++imOHz+O06dPY+HChUhPTwcAuLm5ITY2FpcuXUJ6ejoKCgqM8wAQCYwJkIQ2ZcoU/PTTT2jQoAFWrVqFdevWwdPT86n7DBo0CMuWLcOKFStQv359tGnTBpGRkdoK0MbGBlu2bEFCQgIaNWqEr776CjNnznzqMWvXro2dO3fi2LFjaNq0KTQaDX7//XdtK3fs2LEwMTGBp6cnHBwckJycbJwHgEhgMkmSpPIOgqg8yGQybNq0Sa/JMkT0+mEFSEREQmICJCIiIfE2CBIWu/9EYmMFSEREQmICJCIiITEBEhGRkJgAiYhISEyAREQkJCZAIiISEhMgEREJiQmQiIiE9P8ASsAIWx01w/0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lstm_val = confusion_matrix(Y_test, yhat_probs)\n",
    "f, ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(lstm_val, annot=True, linewidth=0.7, linecolor='cyan', fmt='g', ax=ax, cmap=\"Blues\")\n",
    "plt.title('RNN Classification Confusion Matrix')\n",
    "plt.xlabel('Y predict')\n",
    "plt.ylabel('Y test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb18c257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Modelo",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Recall",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F1 Score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Accuracy",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "98f720a6-f7aa-4e21-853a-a6ff16715bab",
       "rows": [
        [
         "0",
         "RNN",
         "0.7494",
         "0.8069",
         "0.7771",
         "0.7614"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.7494</td>\n",
       "      <td>0.8069</td>\n",
       "      <td>0.7771</td>\n",
       "      <td>0.7614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Modelo  Precision  Recall  F1 Score  Accuracy\n",
       "0    RNN     0.7494  0.8069    0.7771    0.7614"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_rnn=[]\n",
    "precision = precision_score(Y_test, yhat_probs)\n",
    "recall = recall_score(Y_test, yhat_probs)\n",
    "f1 = f1_score(Y_test, yhat_probs)\n",
    "accuracy = accuracy_score(Y_test, yhat_probs)\n",
    "\n",
    "metrics_rnn = [{\n",
    "    'Modelo': 'RNN',\n",
    "    'Precision': round(precision, 4),\n",
    "    'Recall': round(recall, 4),\n",
    "    'F1 Score': round(f1, 4),\n",
    "    'Accuracy': round(accuracy, 4)\n",
    "}]\n",
    "\n",
    "# Convertir en DataFrame y mostrarlo\n",
    "df_metrics = pd.DataFrame(metrics_rnn)\n",
    "df_metrics\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
